# EvalVault Offline Environment Template (vLLM)
# Copy to .env.offline and fill required values.
#
# Usage:
#   cp .env.offline.vllm.example .env.offline
#   # Edit .env.offline with your air-gapped network settings
#   docker compose -f docker-compose.offline.yml --env-file .env.offline up -d --no-build --pull never

# ================================================
# Profile (vLLM)
# ================================================
EVALVAULT_PROFILE=vllm

# ================================================
# PostgreSQL (core stack)
# ================================================
POSTGRES_IMAGE=pgvector/pgvector:0.8.0-pg16
POSTGRES_USER=evalvault
POSTGRES_PASSWORD=evalvault
POSTGRES_DB=evalvault

# ================================================
# Storage (SQLite paths for local file-based storage)
# ================================================
EVALVAULT_DB_PATH=data/db/evalvault.db
EVALVAULT_MEMORY_DB_PATH=data/db/evalvault_memory.db

# ================================================
# API / CORS
# ================================================
CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# ================================================
# Docker Base Images (online build only)
# ================================================
EVALVAULT_PYTHON_IMAGE=python:3.12.6-slim
EVALVAULT_UV_IMAGE=ghcr.io/astral-sh/uv:0.4.28
EVALVAULT_NODE_IMAGE=node:20.19-alpine
EVALVAULT_NGINX_IMAGE=nginx:1.27.3-alpine

# API_AUTH_TOKENS=
# KNOWLEDGE_READ_TOKENS=
# KNOWLEDGE_WRITE_TOKENS=

# ================================================
# vLLM server (air-gapped network - internal models)
# ================================================
# IMPORTANT: Model weights are NOT shipped with EvalVault.
# You must provide the URL to your air-gapped vLLM server.

# VLLM_BASE_URL=http://vllm-server:8000/v1
# VLLM_API_KEY=
# VLLM_MODEL=Qwen/Qwen2.5-7B-Instruct
# VLLM_EMBEDDING_MODEL=BAAI/bge-m3
# VLLM_EMBEDDING_BASE_URL=http://vllm-embedding:8000/v1

# ================================================
# Closed-source models (requires network proxy)
# ================================================
# If your air-gapped network has proxy access to external APIs,
# you can use closed-source models via API keys.

# OpenAI
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic
# ANTHROPIC_API_KEY=sk-ant-...
# ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Azure OpenAI
# AZURE_OPENAI_API_KEY=
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini
# AZURE_OPENAI_API_VERSION=2024-02-15-preview

# ================================================
# Faithfulness fallback (optional)
# ================================================
# Use a more capable model for faithfulness metric if needed
# FAITHFULNESS_FALLBACK_PROVIDER=openai
# FAITHFULNESS_FALLBACK_MODEL=gpt-4o
