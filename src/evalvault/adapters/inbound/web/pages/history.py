"""History page renderer for the EvalVault Streamlit app."""

from __future__ import annotations


def render_history_page(adapter, session):
    """ì´ë ¥ ì¡°íšŒ í˜ì´ì§€ ë Œë”ë§."""
    from datetime import datetime, time, timedelta

    import streamlit as st

    from evalvault.adapters.inbound.web.components import (
        HistoryExporter,
        RunFilter,
        RunSearch,
        RunTable,
    )
    from evalvault.adapters.inbound.web.components.projects import (
        ALL_PROJECTS_TOKEN,
        UNASSIGNED_PROJECT_TOKEN,
        build_project_options,
        filter_runs_by_projects,
    )
    from evalvault.adapters.inbound.web.components.prompt_panel import render_prompt_panel
    from evalvault.domain.services.prompt_status import format_prompt_summary_label

    st.header("ğŸ“‹ History")
    st.markdown("ì´ì „ í‰ê°€ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")

    # ë°ì´í„° ë¡œë“œ
    all_runs = adapter.list_runs(limit=100)

    # ê²€ìƒ‰ ë° í•„í„° ì„¹ì…˜
    search_col, filter_col = st.columns([2, 1])

    with search_col:
        search_query = st.text_input(
            "ğŸ” ê²€ìƒ‰",
            placeholder="ë°ì´í„°ì…‹ ë˜ëŠ” ëª¨ë¸ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰...",
            key="history_search",
        )

    with filter_col, st.popover("ğŸ”§ í•„í„°"):
        # ëª¨ë¸ í•„í„°
        model_options = ["All"] + sorted({r.model_name for r in all_runs})
        selected_model = st.selectbox("ëª¨ë¸", options=model_options, index=0)

        project_options = build_project_options(all_runs)

        def project_label(option: str) -> str:
            if option == ALL_PROJECTS_TOKEN:
                return "ì „ì²´"
            if option == UNASSIGNED_PROJECT_TOKEN:
                return "ë¯¸ë¶„ë¥˜"
            return option

        selected_projects = st.multiselect(
            "í”„ë¡œì íŠ¸",
            options=project_options,
            default=[ALL_PROJECTS_TOKEN],
            format_func=project_label,
        )

        mode_values = sorted({r.run_mode for r in all_runs if r.run_mode})
        mode_options = ["All"] + mode_values
        selected_mode = st.selectbox(
            "ì‹¤í–‰ ëª¨ë“œ",
            options=mode_options,
            format_func=lambda x: "ì „ì²´" if x == "All" else x.capitalize(),
            index=0,
        )

        # í†µê³¼ìœ¨ í•„í„°
        min_pass_rate = st.slider("ìµœì†Œ í†µê³¼ìœ¨", 0.0, 1.0, 0.0, 0.1)

        use_date_filter = st.checkbox("ë‚ ì§œ ë²”ìœ„ í•„í„°", value=False)

        date_from = None
        date_to = None
        if use_date_filter:
            today = datetime.now().date()
            date_range = st.date_input(
                "ë‚ ì§œ ë²”ìœ„",
                value=(today - timedelta(days=30), today),
                help="ì„ íƒí•œ ê¸°ê°„ì˜ í‰ê°€ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.",
            )
            if isinstance(date_range, tuple) and len(date_range) == 2:
                date_from = datetime.combine(date_range[0], time.min)
                date_to = datetime.combine(date_range[1], time.max)

    # ê²€ìƒ‰ ì ìš©
    search = RunSearch(query=search_query)
    runs = search.search(all_runs)

    # í”„ë¡œì íŠ¸ í•„í„° ì ìš©
    runs = filter_runs_by_projects(runs, selected_projects)

    # í•„í„° ì ìš©
    run_filter = RunFilter(
        model_name=selected_model if selected_model != "All" else None,
        min_pass_rate=min_pass_rate if min_pass_rate > 0 else None,
        run_mode=selected_mode if selected_mode != "All" else None,
        date_from=date_from,
        date_to=date_to,
    )
    runs = run_filter.apply(runs)

    # ê²°ê³¼ ìš”ì•½
    st.divider()
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total Runs", len(runs))
    with col2:
        avg_rate = sum(r.pass_rate for r in runs) / len(runs) if runs else 0
        st.metric("Avg Pass Rate", f"{avg_rate * 100:.1f}%")
    with col3:
        total_cases = sum(r.total_test_cases for r in runs)
        st.metric("Total Test Cases", f"{total_cases:,}")

    # í…Œì´ë¸” ë° ì •ë ¬
    st.divider()

    if runs:
        # ì •ë ¬ ì˜µì…˜
        sort_col, export_col = st.columns([3, 1])
        with sort_col:
            sort_by = st.selectbox(
                "ì •ë ¬ ê¸°ì¤€",
                options=["date", "pass_rate", "dataset", "model"],
                format_func=lambda x: {
                    "date": "ğŸ“… ë‚ ì§œ",
                    "pass_rate": "ğŸ“Š í†µê³¼ìœ¨",
                    "dataset": "ğŸ“ ë°ì´í„°ì…‹",
                    "model": "ğŸ¤– ëª¨ë¸",
                }.get(x, x),
                index=0,
            )
        with export_col:
            exporter = HistoryExporter(runs=runs)
            st.download_button(
                "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                data=exporter.to_csv(),
                file_name="evaluation_history.csv",
                mime="text/csv",
            )

        # í…Œì´ë¸” ìƒì„±
        table = RunTable(runs=runs, page_size=10)
        table.sort_by(sort_by, ascending=sort_by == "dataset")

        show_phoenix_column = any(
            r.phoenix_precision is not None or r.phoenix_drift is not None for r in runs
        )
        column_config = [3, 2, 1, 2, 2, 1, 1]
        if show_phoenix_column:
            column_config.append(1)
        column_config.append(1)

        header_labels = [
            "Dataset",
            "Project",
            "Mode",
            "Model",
            "Metrics",
            "Pass Rate",
            "Date",
        ]
        if show_phoenix_column:
            header_labels.append("Phoenix")
        header_labels.append("Actions")

        header_cols = st.columns(column_config)
        for col, label in zip(header_cols, header_labels, strict=True):
            col.markdown(f"**{label}**")

        for run in table.get_current_page_runs():
            row_cols = st.columns(column_config)
            idx = 0
            dataset_col = row_cols[idx]
            dataset_col.text(run.dataset_name)
            prompt_summary = format_prompt_summary_label(run.phoenix_prompts)
            if prompt_summary:
                dataset_col.caption(f"Prompt: {prompt_summary}")
            idx += 1
            row_cols[idx].text(run.project_name or "ë¯¸ë¶„ë¥˜")
            idx += 1
            row_cols[idx].text((run.run_mode or "-").capitalize())
            idx += 1
            row_cols[idx].text(run.model_name)
            idx += 1
            row_cols[idx].text(
                ", ".join(run.metrics_evaluated[:2])
                + ("..." if len(run.metrics_evaluated) > 2 else "")
            )
            idx += 1

            pass_rate_pct = run.pass_rate * 100
            if pass_rate_pct >= 70:
                row_cols[idx].success(f"{pass_rate_pct:.0f}%")
            elif pass_rate_pct >= 50:
                row_cols[idx].warning(f"{pass_rate_pct:.0f}%")
            else:
                row_cols[idx].error(f"{pass_rate_pct:.0f}%")
            idx += 1

            row_cols[idx].text(run.started_at.strftime("%m/%d"))
            idx += 1

            if show_phoenix_column:
                phoenix_bits: list[str] = []
                if run.phoenix_precision is not None:
                    phoenix_bits.append(f"P@K {run.phoenix_precision:.2f}")
                if run.phoenix_drift is not None:
                    phoenix_bits.append(f"Drift {run.phoenix_drift:.2f}")
                if run.phoenix_experiment_url:
                    phoenix_bits.append(f"[Open]({run.phoenix_experiment_url})")
                if phoenix_bits:
                    row_cols[idx].markdown(" | ".join(phoenix_bits))
                else:
                    row_cols[idx].text("-")
                idx += 1

            if row_cols[-1].button("ğŸ‘", key=f"view_{run.run_id}", help="ìƒì„¸ ë³´ê¸°"):
                session.current_run_id = run.run_id

        # í˜ì´ì§€ë„¤ì´ì…˜
        if table.total_pages > 1:
            st.divider()
            page_cols = st.columns([1, 3, 1])
            with page_cols[1]:
                st.caption(f"Page {table.page} of {table.total_pages}")

        selected_run = None
        if session.current_run_id:
            selected_run = next((r for r in runs if r.run_id == session.current_run_id), None)
        if selected_run is None and runs:
            selected_run = runs[0]
        if selected_run:
            st.divider()
            st.subheader("Prompt ìƒíƒœ")
            entries = list(selected_run.phoenix_prompts or [])
            summary = format_prompt_summary_label(entries)
            render_prompt_panel(
                st,
                entries=entries,
                run_id=selected_run.run_id,
                summary_label=summary,
            )
    else:
        st.info("í‰ê°€ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
