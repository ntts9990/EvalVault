# 00. Overview

> 내부용 본편(상세). 외부 공개 요약은 `docs/handbook/EXTERNAL.md`에 별도 작성.

---

## 미션(1문장)

RAG 시스템의 변경이 **진짜 개선인지**를 데이터셋·메트릭·(선택)트레이싱 관점에서 **재현 가능하게** 검증하고, 왜/어디서 깨지는지까지 설명 가능한 워크플로를 제공한다.

## 대상 사용자(3)

1) RAG를 운영하는 ML/플랫폼/백엔드 엔지니어
2) 품질/회귀를 책임지는 QA/PM
3) 반복 평가/벤치마크가 필요한 외부 사용자(컨설팅/솔루션/고객사 PoC)

## 핵심 가치(3)

1) 재현성: run 단위로 평가/분석/아티팩트/트레이스를 묶고 비교할 수 있다.
2) 진단 가능성: 점수 변화의 원인을 모듈/스테이지/메트릭 레벨로 추적할 수 있다.
3) 운영 옵션화: Phoenix/Langfuse/MLflow 같은 관측은 필요할 때만 켠다.

## Non-goals(3)

1) RAG 시스템 자체를 대신 구현/호스팅하지 않는다.
2) 단일 점수 하나로 모든 품질을 대체하지 않는다(다중 메트릭/근거 기반).
3) 특정 벤더/모델에 종속되지 않는다(OpenAI/Ollama/vLLM 등 옵션화).

## 근거 링크(3+)

- 프로젝트 정의/핵심 개념: `../../README.md`
- 상태/제약: `../STATUS.md`
- 로드맵: `../ROADMAP.md`
- 내부 백서(개요): `../new_whitepaper/01_overview.md`
- 문서 운영 원칙: `../INDEX.md`
