# í•œêµ­ì–´ RAG ìµœì í™” ê¸°ëŠ¥ì˜ EvalVault í†µí•© ì „ëµ

> **ë¬¸ì„œ ë²„ì „**: 2.0.0
> **ì‘ì„±ì¼**: 2025-12-30
> **ëª©ì **: í•œêµ­ì–´ RAG ìµœì í™” ê¸°ëŠ¥ë“¤ì´ EvalVaultì˜ ë‹¤ë¥¸ ê¸°ëŠ¥ë“¤ê³¼ ì„ ìˆœí™˜ì„ ì´ë£¨ëŠ” í†µí•© ë°©ì•ˆ
> **Phase 9 Status**: 9.1 âœ… | 9.2 âœ… | 9.3 ğŸ”„ In Progress

---

## í•µì‹¬ ì¸ì‚¬ì´íŠ¸

**EvalVaultëŠ” RAG í‰ê°€ ë„êµ¬ì´ì§€, ì‹¤ì œ RAG ì‹œìŠ¤í…œì´ ì•„ë‹™ë‹ˆë‹¤.**
í•˜ì§€ë§Œ í‰ê°€ë¥¼ ìœ„í•´ **í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±**, **ê²°ê³¼ ë¶„ì„**, **íŒ¨í„´ í•™ìŠµ**ì´ í•„ìš”í•˜ë©°, ì´ ê³¼ì •ì—ì„œ í•œêµ­ì–´ ìµœì í™” ê¸°ëŠ¥ë“¤ì´ í•µì‹¬ ì—­í• ì„ í•©ë‹ˆë‹¤.

**í•µì‹¬ ê°€ì¹˜ ì¬ì •ì˜:**
- âŒ "ê²€ìƒ‰ ê¸°ëŠ¥" (EvalVaultì—ëŠ” ë¶ˆí•„ìš”)
- âœ… **"í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì „ì²˜ë¦¬"** (ëª¨ë“  í…ìŠ¤íŠ¸ ì²˜ë¦¬ì— í™œìš©)
- âœ… **"ì˜ë¯¸ ë‹¨ìœ„ ì²­í‚¹"** (í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± í’ˆì§ˆ í–¥ìƒ)
- âœ… **"ì •í™•í•œ ì—”í‹°í‹°/í‚¤ì›Œë“œ ì¶”ì¶œ"** (KG ìƒì„±, NLP ë¶„ì„ ê°œì„ )

---

## í†µí•© ì „ëµ: ì„ ìˆœí™˜ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              í•œêµ­ì–´ ìµœì í™” ê¸°ëŠ¥ (Phase 9)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ KiwiTokenizerâ”‚  â”‚KoreanChunker â”‚  â”‚í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜â”‚    â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚ì—”í‹°í‹° ì¶”ì¶œ     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                 â”‚                 â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                 â”‚
          â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EvalVault í•µì‹¬ ê¸°ëŠ¥ë“¤                           â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±  â”‚  â”‚  NLP Analysis â”‚  â”‚  KG ìƒì„±     â”‚   â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚   â”‚
â”‚  â”‚ âœ… ë” ë‚˜ì€    â”‚  â”‚ âœ… ë” ì •í™•í•œ  â”‚  â”‚ âœ… ë” ì •í™•í•œ  â”‚   â”‚
â”‚  â”‚    ì²­í‚¹      â”‚  â”‚    í‚¤ì›Œë“œ     â”‚  â”‚    ì—”í‹°í‹°     â”‚   â”‚
â”‚  â”‚ âœ… ì˜ë¯¸ ë³´ì¡´  â”‚  â”‚ âœ… ì§ˆë¬¸ ë¶„ë¥˜   â”‚  â”‚ âœ… ê´€ê³„ ì¶”ì¶œ   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                 â”‚                 â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                           â”‚                               â”‚
â”‚                           â–¼                               â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â”‚   í‰ê°€ ì‹¤í–‰ ë° ë¶„ì„   â”‚                    â”‚
â”‚              â”‚   (RagasEvaluator)   â”‚                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                           â”‚                               â”‚
â”‚                           â–¼                               â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â”‚   Domain Memory      â”‚                    â”‚
â”‚              â”‚   (íŒ¨í„´ í•™ìŠµ)         â”‚                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                           â”‚                               â”‚
â”‚                           â–¼                               â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â”‚   ë‹¤ìŒ í‰ê°€ì— ë°˜ì˜    â”‚                    â”‚
â”‚              â”‚   (ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ì…‹)  â”‚                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## í†µí•© í¬ì¸íŠ¸ 1: í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± (Testset Generation)

### 1.1 í˜„ì¬ ë¬¸ì œì 

**ê¸°ì¡´ `DocumentChunker`ì˜ í•œê³„:**
```python
# í˜„ì¬: ë¬¸ì ê¸°ë°˜ ì²­í‚¹
chunker = DocumentChunker(chunk_size=500, overlap=50)
chunks = chunker.chunk(document)

# ë¬¸ì œ:
# - ë¬¸ì¥ ì¤‘ê°„ì— ëŠê¹€
# - í•œêµ­ì–´ ê³µë°± ì ìŒ â†’ í† í° ìˆ˜ ì˜ˆì¸¡ ë¶ˆê°€
# - ì˜ë¯¸ ë‹¨ìœ„ ë¬´ì‹œ
```

**ê¸°ì¡´ `BasicTestsetGenerator`ì˜ í•œê³„:**
```python
# í˜„ì¬: ê³µë°± ê¸°ë°˜ ì²­í‚¹
chunks = self._chunk_documents(documents, config)
# â†’ ì˜ë¯¸ê°€ ëŠê¸´ ì²­í¬ë¡œ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±
# â†’ ë‚®ì€ í’ˆì§ˆì˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
```

### 1.2 í†µí•© ë°©ì•ˆ

#### ë°©ì•ˆ 1: KoreanDocumentChunker í†µí•©

```python
# src/evalvault/domain/services/testset_generator.py

class BasicTestsetGenerator:
    def __init__(
        self,
        use_korean_chunker: bool = False,
        korean_tokenizer: KiwiTokenizer | None = None,
    ):
        self.use_korean_chunker = use_korean_chunker
        self.korean_tokenizer = korean_tokenizer

    def _chunk_documents(
        self,
        documents: list[str],
        config: GenerationConfig
    ) -> list[str]:
        """ë¬¸ì„œ ì²­í‚¹ (í•œêµ­ì–´ ìµœì í™” ì˜µì…˜ í¬í•¨)."""
        if self.use_korean_chunker and self.korean_tokenizer:
            # í•œêµ­ì–´ ìµœì í™” ì²­í‚¹
            chunker = KoreanDocumentChunker(
                tokenizer=self.korean_tokenizer,
                chunk_size=config.chunk_size,  # í† í° ìˆ˜ ê¸°ì¤€
                overlap_tokens=config.chunk_overlap,
            )
            all_chunks = []
            for doc in documents:
                chunks = chunker.chunk(doc)
                all_chunks.extend([c.text for c in chunks])
            return all_chunks
        else:
            # ê¸°ì¡´ ë°©ì‹ (í•˜ìœ„ í˜¸í™˜)
            chunker = DocumentChunker(
                chunk_size=config.chunk_size,
                overlap=config.chunk_overlap,
            )
            all_chunks = []
            for doc in documents:
                chunks = chunker.chunk(doc)
                all_chunks.extend(chunks)
            return all_chunks
```

**íš¨ê³¼:**
- âœ… ì™„ì „í•œ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì²­í‚¹ â†’ ë” ë‚˜ì€ ì»¨í…ìŠ¤íŠ¸
- âœ… í† í° ìˆ˜ ê¸°ì¤€ ì •í™•í•œ ì²­í‚¹ â†’ LLM í† í° ì œí•œ ì¤€ìˆ˜
- âœ… ì˜ë¯¸ ë¬´ê²°ì„± ë³´ì¥ â†’ ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

#### ë°©ì•ˆ 2: KG ê¸°ë°˜ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ê°œì„ 

```python
# src/evalvault/domain/services/kg_generator.py

class KnowledgeGraphGenerator:
    def __init__(
        self,
        korean_tokenizer: KiwiTokenizer | None = None,
        ...
    ):
        self.korean_tokenizer = korean_tokenizer
        # EntityExtractorì— í˜•íƒœì†Œ ë¶„ì„ ì „ë‹¬
        self._extractor = EntityExtractor(
            korean_tokenizer=korean_tokenizer
        )
```

**íš¨ê³¼:**
- âœ… í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œ â†’ ë” ì •í™•í•œ KG
- âœ… ë” ì •í™•í•œ KG â†’ ë” ë‚˜ì€ ì§ˆë¬¸ ìƒì„±
- âœ… ë” ë‚˜ì€ ì§ˆë¬¸ â†’ ë” ë‚˜ì€ í‰ê°€

### 1.3 ì„ ìˆœí™˜ êµ¬ì¡°

```
í•œêµ­ì–´ ìµœì í™” ì²­í‚¹
    â†“
ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±
    â†“
ë” ë‚˜ì€ í‰ê°€ ê²°ê³¼
    â†“
Domain Memoryì— íŒ¨í„´ í•™ìŠµ
    â†“
ë‹¤ìŒ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±ì— ë°˜ì˜ (ë” ì •í™•í•œ ì—”í‹°í‹° ì¶”ì¶œ)
```

---

## í†µí•© í¬ì¸íŠ¸ 2: NLP Analysis

### 2.1 í˜„ì¬ ë¬¸ì œì 

**ê¸°ì¡´ `NLPAnalysisAdapter.extract_keywords()`ì˜ í•œê³„:**
```python
# í˜„ì¬: ê³µë°± ê¸°ë°˜ TF-IDF
def _extract_keywords_tfidf(self, documents: list[str], top_k: int):
    # ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬
    vectorizer = TfidfVectorizer()
    # â†’ "ë³´í—˜ë£Œê°€", "ì–¼ë§ˆì¸ê°€ìš”" ê°™ì€ ì˜ë¯¸ ì—†ëŠ” í‚¤ì›Œë“œ
```

### 2.2 í†µí•© ë°©ì•ˆ

#### ë°©ì•ˆ: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ

```python
# src/evalvault/adapters/outbound/analysis/nlp_adapter.py

class NLPAnalysisAdapter:
    def __init__(
        self,
        llm: LLMPort | None = None,
        korean_tokenizer: KiwiTokenizer | None = None,  # ì¶”ê°€
    ):
        self._llm_adapter = llm
        self.korean_tokenizer = korean_tokenizer

    def _extract_keywords_tfidf(
        self,
        documents: list[str],
        top_k: int
    ) -> list[KeywordInfo]:
        """TF-IDF ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ (í•œêµ­ì–´ ìµœì í™” ì˜µì…˜)."""
        if self.korean_tokenizer:
            # í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
            tokenized_docs = [
                ' '.join(self.korean_tokenizer.extract_keywords(doc))
                for doc in documents
            ]
        else:
            # ê¸°ì¡´ ë°©ì‹ (ê³µë°± ê¸°ë°˜)
            tokenized_docs = documents

        vectorizer = TfidfVectorizer(max_features=100)
        tfidf_matrix = vectorizer.fit_transform(tokenized_docs)
        # ... ë‚˜ë¨¸ì§€ ë¡œì§
```

**íš¨ê³¼:**
- âœ… ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë§Œ ì¶”ì¶œ: "ë³´í—˜ë£Œ", "ë³´ì¥", "ê°€ì…" (ì¡°ì‚¬/ì–´ë¯¸ ì œê±°)
- âœ… í‚¤ì›Œë“œ ì •í™•ë„ 60% â†’ 85%+ í–¥ìƒ
- âœ… ë” ì •í™•í•œ ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜

### 2.3 ì„ ìˆœí™˜ êµ¬ì¡°

```
í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
    â†“
ë” ì •í™•í•œ NLP Analysis
    â†“
ë” ë‚˜ì€ ì¸ì‚¬ì´íŠ¸ (ì–´ë–¤ í‚¤ì›Œë“œê°€ ë‚®ì€ ì ìˆ˜ì™€ ì—°ê´€?)
    â†“
Causal Analysisì— ë°˜ì˜
    â†“
ê°œì„  ì œì•ˆ ìƒì„±
```

---

## í†µí•© í¬ì¸íŠ¸ 3: Knowledge Graph ìƒì„±

### 3.1 í˜„ì¬ ë¬¸ì œì 

**ê¸°ì¡´ `EntityExtractor`ì˜ í•œê³„:**
```python
# í˜„ì¬: ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜
# "ì‚¼ì„±ìƒëª…ì˜ ì¢…ì‹ ë³´í—˜" â†’ ["ì‚¼ì„±ìƒëª…ì˜", "ì¢…ì‹ ë³´í—˜"] (ë¶€ì •í™•)
# "ë³´í—˜ë£Œê°€ ì¸ìƒë˜ì—ˆìŠµë‹ˆë‹¤" â†’ ì—”í‹°í‹° ì¶”ì¶œ ì‹¤íŒ¨ (ì¡°ì‚¬ í¬í•¨)
```

### 3.2 í†µí•© ë°©ì•ˆ

#### ë°©ì•ˆ: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œ

```python
# src/evalvault/domain/services/entity_extractor.py

class EntityExtractor:
    def __init__(
        self,
        korean_tokenizer: KiwiTokenizer | None = None,
    ):
        self.korean_tokenizer = korean_tokenizer
        # ê¸°ì¡´ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜)
        self._org_pattern = re.compile("|".join(self.ORGANIZATION_PATTERNS))
        # ...

    def extract_entities(self, text: str) -> list[Entity]:
        """ì—”í‹°í‹° ì¶”ì¶œ (í˜•íƒœì†Œ ë¶„ì„ ë³´ê°•)."""
        entities = []

        # 1. ê¸°ì¡´ ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ ì¶”ì¶œ
        entities.extend(self._extract_by_regex(text))

        # 2. í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ë³´ê°• (í•œêµ­ì–´ì¸ ê²½ìš°)
        if self.korean_tokenizer:
            entities.extend(self._extract_by_morphology(text))

        return self._deduplicate_entities(entities)

    def _extract_by_morphology(self, text: str) -> list[Entity]:
        """í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œ."""
        entities = []

        # ëª…ì‚¬ ì¶”ì¶œ
        nouns = self.korean_tokenizer.extract_nouns(text)

        # ë³´í—˜ ë„ë©”ì¸ íŒ¨í„´ ë§¤ì¹­
        for noun in nouns:
            if self._is_insurance_product(noun):
                entities.append(Entity(
                    name=noun,
                    entity_type="product",
                    confidence=0.9,
                    provenance="morphology"
                ))
            elif self._is_organization(noun):
                entities.append(Entity(
                    name=noun,
                    entity_type="organization",
                    confidence=0.95,
                    provenance="morphology"
                ))

        return entities
```

**íš¨ê³¼:**
- âœ… ì¡°ì‚¬/ì–´ë¯¸ ì œê±° í›„ ì—”í‹°í‹° ì¶”ì¶œ: "ë³´í—˜ë£Œê°€" â†’ "ë³´í—˜ë£Œ"
- âœ… ë³µí•©ëª…ì‚¬ ì •í™• ë¶„í•´: "ì¬í•´ì‚¬ë§ë³´í—˜ê¸ˆ" â†’ ["ì¬í•´", "ì‚¬ë§", "ë³´í—˜ê¸ˆ"]
- âœ… ë” ì •í™•í•œ KG â†’ ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±

### 3.3 ì„ ìˆœí™˜ êµ¬ì¡°

```
í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œ
    â†“
ë” ì •í™•í•œ KG ìƒì„±
    â†“
ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± (KG ê¸°ë°˜)
    â†“
ë” ì •í™•í•œ í‰ê°€
    â†“
Domain Memoryì— íŒ¨í„´ í•™ìŠµ
    â†“
ë‹¤ìŒ KG ìƒì„±ì— ë°˜ì˜ (í•™ìŠµëœ ì—”í‹°í‹° ì‹ ë¢°ë„ ì ìš©)
```

---

## í†µí•© í¬ì¸íŠ¸ 4: Domain Memory

### 4.1 í˜„ì¬ ë¬¸ì œì 

**ê¸°ì¡´ `DomainLearningHook.extract_facts()`ì˜ í•œê³„:**
```python
# í˜„ì¬: í‰ê°€ ê²°ê³¼ì—ì„œ ì‚¬ì‹¤ ì¶”ì¶œ
# "ë³´í—˜ë£ŒëŠ” 30ë§Œì›ì…ë‹ˆë‹¤" â†’ SPO íŠ¸ë¦¬í”Œ ì¶”ì¶œ
# ë¬¸ì œ: ì¡°ì‚¬/ì–´ë¯¸ ë³€í˜•ìœ¼ë¡œ ì¸í•œ ì¤‘ë³µ ì‚¬ì‹¤
```

### 4.2 í†µí•© ë°©ì•ˆ

#### ë°©ì•ˆ: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì‚¬ì‹¤ ì •ê·œí™”

```python
# src/evalvault/domain/services/domain_learning_hook.py

class DomainLearningHook:
    def __init__(
        self,
        memory_port: DomainMemoryPort,
        korean_tokenizer: KiwiTokenizer | None = None,
    ):
        self.memory_port = memory_port
        self.korean_tokenizer = korean_tokenizer

    def extract_and_save_facts(
        self,
        run: EvaluationRun,
    ) -> int:
        """ì‚¬ì‹¤ ì¶”ì¶œ ë° ì €ì¥ (í˜•íƒœì†Œ ë¶„ì„ ì •ê·œí™”)."""
        facts = []

        for result in run.results:
            if result.faithfulness_score and result.faithfulness_score >= 0.7:
                # ë‹µë³€ì—ì„œ ì‚¬ì‹¤ ì¶”ì¶œ
                claims = self._extract_claims(result.answer)

                for claim in claims:
                    # í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ ì •ê·œí™”
                    if self.korean_tokenizer:
                        normalized = self._normalize_claim(claim)
                    else:
                        normalized = claim

                    fact = FactualFact(
                        subject=normalized.subject,
                        predicate=normalized.predicate,
                        object=normalized.object,
                        # ...
                    )
                    facts.append(fact)

        # ì¤‘ë³µ ì œê±° (ì •ê·œí™”ëœ ì‚¬ì‹¤ ê¸°ì¤€)
        return self.memory_port.save_facts(facts)

    def _normalize_claim(self, claim: str) -> str:
        """í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ ì‚¬ì‹¤ ì •ê·œí™”."""
        # "ë³´í—˜ë£ŒëŠ” 30ë§Œì›ì…ë‹ˆë‹¤" â†’ "ë³´í—˜ë£Œ 30ë§Œì›"
        tokens = self.korean_tokenizer.extract_keywords(claim)
        return ' '.join(tokens)
```

**íš¨ê³¼:**
- âœ… ì¤‘ë³µ ì‚¬ì‹¤ ì œê±°: "ë³´í—˜ë£ŒëŠ”", "ë³´í—˜ë£Œë¥¼", "ë³´í—˜ë£Œê°€" â†’ "ë³´í—˜ë£Œ"
- âœ… ë” ì •í™•í•œ íŒ¨í„´ í•™ìŠµ
- âœ… ë” ë‚˜ì€ ì‚¬ì‹¤ ê²€ìƒ‰

### 4.3 ì„ ìˆœí™˜ êµ¬ì¡°

```
í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì‚¬ì‹¤ ì •ê·œí™”
    â†“
ë” ì •í™•í•œ Domain Memory
    â†“
ë” ë‚˜ì€ íŒ¨í„´ í•™ìŠµ
    â†“
EntityExtractorì— ì‹ ë¢°ë„ ì ìˆ˜ ì ìš©
    â†“
ë” ì •í™•í•œ ì—”í‹°í‹° ì¶”ì¶œ
    â†“
ë” ë‚˜ì€ KG â†’ ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ì…‹
```

---

## í†µí•© í¬ì¸íŠ¸ 5: í‰ê°€ í’ˆì§ˆ ê°œì„  (Faithfulness)

### 5.1 í˜„ì¬ ë¬¸ì œì 

**Ragasì˜ Faithfulness ë©”íŠ¸ë¦­ í•œê³„:**
- í•œêµ­ì–´ ì¡°ì‚¬/ì–´ë¯¸ ë³€í˜•ìœ¼ë¡œ ì¸í•œ ë§¤ì¹­ ì‹¤íŒ¨
- ì˜ˆ: "ë³´í—˜ë£Œê°€ ì¸ìƒë˜ì—ˆìŠµë‹ˆë‹¤" vs "ë³´í—˜ë£ŒëŠ” 30ë§Œì›ì…ë‹ˆë‹¤" â†’ ë§¤ì¹­ ì‹¤íŒ¨

### 5.2 í†µí•© ë°©ì•ˆ

#### ë°©ì•ˆ: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ Faithfulness ê²€ì¦ ë³´ì¡°

```python
# í‰ê°€ í›„ ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ í™œìš©

class KoreanFaithfulnessEnhancer:
    """í•œêµ­ì–´ Faithfulness ê²€ì¦ ë³´ì¡° ë„êµ¬."""

    def __init__(self, tokenizer: KiwiTokenizer):
        self.tokenizer = tokenizer

    def verify_claims_against_context(
        self,
        claims: list[str],
        context: str
    ) -> list[tuple[str, bool, float]]:
        """ì»¨í…ìŠ¤íŠ¸ ëŒ€ë¹„ ì£¼ì¥ ê²€ì¦ (í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜)."""
        context_tokens = set(self.tokenizer.tokenize(context))

        results = []
        for claim in claims:
            claim_tokens = set(self.tokenizer.tokenize(claim))

            # í† í° ê²¹ì¹¨ ê³„ì‚° (ì¡°ì‚¬/ì–´ë¯¸ ë¬´ì‹œ)
            overlap = len(claim_tokens & context_tokens)
            coverage = overlap / len(claim_tokens) if claim_tokens else 0

            is_faithful = coverage >= 0.5
            results.append((claim, is_faithful, coverage))

        return results
```

**íš¨ê³¼:**
- âœ… ì¡°ì‚¬/ì–´ë¯¸ ë³€í˜• ë¬´ì‹œí•˜ì—¬ ë” ì •í™•í•œ ê²€ì¦
- âœ… Faithfulness ì ìˆ˜ í–¥ìƒ (+5-10%)
- âœ… ë” ë‚˜ì€ í‰ê°€ í’ˆì§ˆ

---

## í†µí•© ë¡œë“œë§µ

### Phase 1: ê¸°ë³¸ í†µí•© (Week 1-2)

- [ ] `BasicTestsetGenerator`ì— `KoreanDocumentChunker` ì˜µì…˜ ì¶”ê°€
- [ ] `NLPAnalysisAdapter`ì— `KiwiTokenizer` í†µí•©
- [ ] CLIì— `--korean` ì˜µì…˜ ì¶”ê°€

### Phase 2: ê³ ê¸‰ í†µí•© (Week 3-4)

- [ ] `EntityExtractor`ì— í˜•íƒœì†Œ ë¶„ì„ ë³´ê°•
- [ ] `DomainLearningHook`ì— ì‚¬ì‹¤ ì •ê·œí™” ì¶”ê°€
- [ ] `KnowledgeGraphGenerator`ì— í•œêµ­ì–´ ìµœì í™” ì ìš©

### Phase 3: ì„ ìˆœí™˜ ì™„ì„± (Week 5-6)

- [ ] Domain Memoryì˜ í•™ìŠµëœ íŒ¨í„´ì„ EntityExtractorì— ì ìš©
- [ ] í‰ê°€ ê²°ê³¼ ë¶„ì„ ë¦¬í¬íŠ¸ì— í•œêµ­ì–´ ìµœì í™” íš¨ê³¼ í‘œì‹œ
- [ ] ë²¤ì¹˜ë§ˆí¬ ë° ì„±ëŠ¥ ì¸¡ì •

---

## ì˜ˆìƒ íš¨ê³¼ (í†µí•© í›„)

### ì •ëŸ‰ì  ê°œì„ 

| ê¸°ëŠ¥ | Before | After | ê°œì„ ìœ¨ |
|------|--------|-------|--------|
| **í…ŒìŠ¤íŠ¸ì…‹ í’ˆì§ˆ** | Baseline | +15-20% | ì»¨í…ìŠ¤íŠ¸ ë¬´ê²°ì„± |
| **í‚¤ì›Œë“œ ì¶”ì¶œ ì •í™•ë„** | ~60% | 85%+ | **+25%** |
| **ì—”í‹°í‹° ì¶”ì¶œ ì •í™•ë„** | ~70% | 90%+ | **+20%** |
| **KG í’ˆì§ˆ** | Baseline | +20-30% | ë” ì •í™•í•œ ì—”í‹°í‹°/ê´€ê³„ |
| **Domain Memory ì •í™•ë„** | Baseline | +10-15% | ì¤‘ë³µ ì œê±°, ì •ê·œí™” |

### ì„ ìˆœí™˜ íš¨ê³¼

```
1ì°¨ ì‚¬ì´í´:
  í•œêµ­ì–´ ìµœì í™” â†’ ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ì…‹ â†’ ë” ë‚˜ì€ í‰ê°€ â†’ íŒ¨í„´ í•™ìŠµ

2ì°¨ ì‚¬ì´í´:
  í•™ìŠµëœ íŒ¨í„´ â†’ ë” ì •í™•í•œ ì—”í‹°í‹° ì¶”ì¶œ â†’ ë” ë‚˜ì€ KG â†’ ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ì…‹

3ì°¨ ì‚¬ì´í´:
  ëˆ„ì ëœ í•™ìŠµ â†’ ë” ì •í™•í•œ í‰ê°€ â†’ ë” ì •í™•í•œ ì¸ì‚¬ì´íŠ¸
```

---

## ê²°ë¡ 

í•œêµ­ì–´ RAG ìµœì í™” ê¸°ëŠ¥ë“¤ì€ **"ê²€ìƒ‰ ê¸°ëŠ¥"ì´ ì•„ë‹ˆë¼ "í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì¸í”„ë¼"**ë¡œ í†µí•©ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:

1. **í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±**: ì˜ë¯¸ ë‹¨ìœ„ ì²­í‚¹ìœ¼ë¡œ í’ˆì§ˆ í–¥ìƒ
2. **NLP Analysis**: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œë¡œ ì •í™•ë„ í–¥ìƒ
3. **KG ìƒì„±**: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œë¡œ ì •í™•ë„ í–¥ìƒ
4. **Domain Memory**: ì‚¬ì‹¤ ì •ê·œí™”ë¡œ ì¤‘ë³µ ì œê±° ë° ì •í™•ë„ í–¥ìƒ
5. **í‰ê°€ í’ˆì§ˆ**: Faithfulness ê²€ì¦ ë³´ì¡°ë¡œ ì ìˆ˜ í–¥ìƒ

ì´ëŸ¬í•œ í†µí•©ì„ í†µí•´ **ì„ ìˆœí™˜ êµ¬ì¡°**ê°€ ì™„ì„±ë˜ì–´, ì‚¬ìš©í• ìˆ˜ë¡ ì •í™•ë„ê°€ í–¥ìƒë˜ëŠ” ì‹œìŠ¤í…œì´ ë©ë‹ˆë‹¤.

---

## í†µí•© í¬ì¸íŠ¸ 6: Dense Embedding (Phase 9.3)

### 6.1 Dense Embedding ê°œìš”

**ì„ ì • ëª¨ë¸**: `dragonkue/BGE-m3-ko` (AutoRAG ë²¤ì¹˜ë§ˆí¬ 1ìœ„)

| íŠ¹ì„± | ê°’ |
|------|-----|
| ì°¨ì› | 1024 |
| Max Tokens | 8192 |
| AutoRAG Top-k 1 | **0.7456** (+39.4% vs bge-m3-korean) |
| MIRACL NDCG@10 | 0.6833 |
| ë¼ì´ì„ ìŠ¤ | Apache 2.0 |

### 6.2 Quantized ëª¨ë¸ ì§€ì›

> **ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­**: "local LLM ëª¨ë¸ì€ ëŒ€ë¶€ë¶„ í€€íƒ€ì´ì¦ˆëœ ëª¨ë¸ì„ ì“¸ ê±°ì•¼"

```python
class KoreanDenseRetriever:
    """í•œêµ­ì–´ Dense ê²€ìƒ‰ê¸° (Quantized ëª¨ë¸ ì§€ì›)."""

    def __init__(
        self,
        model_name: str = "upskyy/bge-m3-korean",
        use_fp16: bool = True,  # ë©”ëª¨ë¦¬ ì ˆì•½ (FP16 ì–‘ìí™”)
        device: str = "auto",   # auto, cuda, cpu, mps
    ):
        self._model = self._load_model(model_name, use_fp16, device)

    def encode(
        self,
        texts: list[str],
        return_dense: bool = True,
        return_sparse: bool = False,
    ) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±."""
        return self._model.encode(
            texts,
            return_dense=return_dense,
            return_sparse=return_sparse,
        )
```

### 6.3 HybridRetriever í†µí•©

Phase 9.2ì—ì„œ êµ¬í˜„ëœ `KoreanHybridRetriever`ì— Dense ê²€ìƒ‰ ì—°ê²°:

```python
from evalvault.adapters.outbound.nlp.korean import KoreanHybridRetriever

# Dense ì„ë² ë”© í•¨ìˆ˜ ì£¼ì…
def embedding_func(texts: list[str]) -> list[list[float]]:
    return dense_retriever.encode(texts).tolist()

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„±
retriever = KoreanHybridRetriever(
    tokenizer=tokenizer,
    embedding_func=embedding_func,  # Dense ì—°ê²°
    bm25_weight=0.4,
    dense_weight=0.6,
    fusion_method=FusionMethod.RRF,
)

# ì¸ë±ì‹± (BM25 + Dense ë™ì‹œ)
retriever.index(documents, compute_embeddings=True)

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
results = retriever.search(query, top_k=5)
```

### 6.4 í†µí•© í¬ì¸íŠ¸

| í†µí•© ëŒ€ìƒ | í†µí•© ë°©ë²• | íš¨ê³¼ |
|-----------|-----------|------|
| **Context Retrieval** | í‰ê°€ ì „ ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ê°œì„  | Context Precision/Recall í–¥ìƒ |
| **Semantic Similarity** | í˜•íƒœì†Œ ì „ì²˜ë¦¬ + Dense ìœ ì‚¬ë„ | ë” ì •í™•í•œ ì˜ë¯¸ ë¹„êµ |
| **Topic Clustering** | ì„ë² ë”© ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ | ë” ë‚˜ì€ í† í”½ ë¶„ë¦¬ |
| **Domain Memory** | Semantic search ë³´ì¡° | ì˜ë¯¸ ê¸°ë°˜ ì§€ì‹ ê²€ìƒ‰ |

### 6.5 Phase 9.3 êµ¬í˜„ ê³„íš

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Phase 9.3 Implementation Plan                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  1. KoreanDenseRetriever êµ¬í˜„                                        â”‚
â”‚     - BGE-M3-Korean ëª¨ë¸ ë¡œë”©                                        â”‚
â”‚     - FP16 / Quantized ëª¨ë¸ ì§€ì›                                     â”‚
â”‚     - CPU / CUDA / MPS ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ                             â”‚
â”‚                                                                      â”‚
â”‚  2. Embedding Port ì¸í„°í˜ì´ìŠ¤                                         â”‚
â”‚     - EmbeddingPort ì •ì˜                                             â”‚
â”‚     - BGE-M3 ì–´ëŒ‘í„° êµ¬í˜„                                              â”‚
â”‚     - Fallback ì–´ëŒ‘í„° (sentence-transformers)                        â”‚
â”‚                                                                      â”‚
â”‚  3. HybridRetriever Dense í†µí•©                                       â”‚
â”‚     - KoreanHybridRetrieverì— Dense ê²€ìƒ‰ ì—°ê²°                         â”‚
â”‚     - RRF / Weighted ìœµí•© í…ŒìŠ¤íŠ¸                                      â”‚
â”‚                                                                      â”‚
â”‚  4. í…ŒìŠ¤íŠ¸ ë° ë²¤ì¹˜ë§ˆí¬                                                â”‚
â”‚     - ê²€ìƒ‰ ì •í™•ë„ í…ŒìŠ¤íŠ¸                                              â”‚
â”‚     - ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (CPU vs GPU)                                      â”‚
â”‚     - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸                                            â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ì¢…í•© ì„ ìˆœí™˜ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EvalVault + Korean RAG ìµœì í™” ì„ ìˆœí™˜                          â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Phase 9.1      â”‚â”€â”€â”€â”€â–¶â”‚  Phase 9.2      â”‚â”€â”€â”€â”€â–¶â”‚  Phase 9.3      â”‚           â”‚
â”‚  â”‚  KiwiTokenizer  â”‚     â”‚  BM25 + Chunker â”‚     â”‚  Dense Embed    â”‚           â”‚
â”‚  â”‚  í˜•íƒœì†Œ ë¶„ì„     â”‚     â”‚  Hybrid Search  â”‚     â”‚  BGE-M3-Korean  â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚           â”‚                       â”‚                       â”‚                     â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                   â”‚                                             â”‚
â”‚                                   â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                        í†µí•© íš¨ê³¼ (Synergy)                                â”‚  â”‚
â”‚  â”‚                                                                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚
â”‚  â”‚  â”‚ NLP ë¶„ì„   â”‚  â”‚ Causal ë¶„ì„â”‚  â”‚ Testset    â”‚  â”‚ Domain     â”‚         â”‚  â”‚
â”‚  â”‚  â”‚ í‚¤ì›Œë“œ +25%â”‚  â”‚ ì •í™•ë„ +20%â”‚  â”‚ í’ˆì§ˆ +20%  â”‚  â”‚ Memory +15%â”‚         â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚
â”‚  â”‚                                                                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                   â”‚                                             â”‚
â”‚                                   â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                        í‰ê°€ í’ˆì§ˆ í–¥ìƒ                                      â”‚  â”‚
â”‚  â”‚                                                                           â”‚  â”‚
â”‚  â”‚  â€¢ Faithfulness: ì¡°ì‚¬/ì–´ë¯¸ ë¬´ì‹œ ê²€ì¦ â†’ ì •í™•ë„ í–¥ìƒ                        â”‚  â”‚
â”‚  â”‚  â€¢ Semantic Similarity: í˜•íƒœì†Œ ì „ì²˜ë¦¬ â†’ ì˜ë¯¸ ì¤‘ì‹¬ ë¹„êµ                    â”‚  â”‚
â”‚  â”‚  â€¢ Context Precision/Recall: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ í–¥ìƒ         â”‚  â”‚
â”‚  â”‚                                                                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                   â”‚                                             â”‚
â”‚                                   â–¼                                             â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                    â”‚   ë” ë‚˜ì€ ì¸ì‚¬ì´íŠ¸ ìƒì„±      â”‚                              â”‚
â”‚                    â”‚   â†’ ë‹¤ìŒ í‰ê°€ì— ë°˜ì˜         â”‚                              â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ê²°ë¡ 

í•œêµ­ì–´ RAG ìµœì í™” ê¸°ëŠ¥ë“¤ì€ **"ê²€ìƒ‰ ê¸°ëŠ¥"ì´ ì•„ë‹ˆë¼ "í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì¸í”„ë¼"**ë¡œ í†µí•©ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:

1. **í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±**: ì˜ë¯¸ ë‹¨ìœ„ ì²­í‚¹ìœ¼ë¡œ í’ˆì§ˆ í–¥ìƒ
2. **NLP Analysis**: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œë¡œ ì •í™•ë„ í–¥ìƒ
3. **KG ìƒì„±**: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œë¡œ ì •í™•ë„ í–¥ìƒ
4. **Domain Memory**: ì‚¬ì‹¤ ì •ê·œí™”ë¡œ ì¤‘ë³µ ì œê±° ë° ì •í™•ë„ í–¥ìƒ
5. **í‰ê°€ í’ˆì§ˆ**: Faithfulness ê²€ì¦ ë³´ì¡°ë¡œ ì ìˆ˜ í–¥ìƒ
6. **Dense Embedding**: BGE-M3-Koreanìœ¼ë¡œ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ì¶”ê°€

ì´ëŸ¬í•œ í†µí•©ì„ í†µí•´ **ì„ ìˆœí™˜ êµ¬ì¡°**ê°€ ì™„ì„±ë˜ì–´, ì‚¬ìš©í• ìˆ˜ë¡ ì •í™•ë„ê°€ í–¥ìƒë˜ëŠ” ì‹œìŠ¤í…œì´ ë©ë‹ˆë‹¤.

---

**ë¬¸ì„œ ë**
