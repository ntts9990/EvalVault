# EvalVault Development Roadmap

> Last Updated: 2026-01-07
> Current Version: 1.5.0
> Status: Phase 1-14 Complete âœ… | Focusing on Improvement & Future Features

---

## ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ì™„ë£Œëœ ì‘ì—… (Phase 1-14)](#ì™„ë£Œëœ-ì‘ì—…-phase-1-14)
3. [í˜„ì¬ ì§„í–‰ ì¤‘ (2026 Q1)](#í˜„ì¬-ì§„í–‰-ì¤‘-2026-q1)
4. [í–¥í›„ ê³„íš (2026 Q2-Q4)](#í–¥í›„-ê³„íš-2026-q2-q4)
5. [Enterprise Track](#enterprise-track)
6. [ë¯¸ë˜ ì—°êµ¬ (2027+)](#ë¯¸ë˜-ì—°êµ¬-2027)

---

## ê°œìš”

EvalVaultëŠ” RAG (Retrieval-Augmented Generation) í‰ê°€ ì‹œìŠ¤í…œìœ¼ë¡œ, Phase 1-14ë¥¼ ì™„ë£Œí•˜ì—¬ ì•ˆì •ì ì¸ ê¸°ë°˜ì„ ê°–ì¶”ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì½”ë“œ í’ˆì§ˆ ê°œì„ ê³¼ ìƒˆë¡œìš´ ê°€ì¹˜ ì°½ì¶œì— ì§‘ì¤‘í•©ë‹ˆë‹¤.

### í˜„ì¬ ìƒíƒœ ìš”ì•½

| ì§€í‘œ | ê°’ |
|------|-----|
| Version | 1.5.0 |
| Tests | 1,671 tests collected (`pytest --collect-only`) |
| Coverage | 89% |
| LOC | ~59,000 |
| Phases Completed | 14/14 (100%) |
| PyPI | âœ… Published |
| CI/CD | âœ… Cross-platform |

### ë¬¸ì„œ êµ¬ì¡°

| ë¬¸ì„œ | ì—­í•  | ì„¤ëª… |
|------|------|------|
| **[ROADMAP.md](./ROADMAP.md)** (ì´ ë¬¸ì„œ) | ì „ì²´ ë¡œë“œë§µ | í˜„ì¬ ìƒíƒœ ìš”ì•½ + í–¥í›„ ê°œë°œ ê³„íš |
| [STATUS.md](./STATUS.md) | í˜„ì¬ ìƒíƒœ | ë²„ì „, í…ŒìŠ¤íŠ¸ ìˆ˜, ì™„ë£Œ í•­ëª© ìš”ì•½ |
| [README.md](./README.md) | ë¬¸ì„œ ì¸ë±ìŠ¤ | ì „ì²´ ë¬¸ì„œ êµ¬ì¡° ë° íƒìƒ‰ ê°€ì´ë“œ |
| [internal/DEVELOPMENT_GUIDE.md](./internal/DEVELOPMENT_GUIDE.md) | ê°œë°œ ê°€ì´ë“œ | ê°œë°œ í™˜ê²½, ì½”ë“œ í’ˆì§ˆ, ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ |

> **ì°¸ê³ **: ì™„ë£Œëœ ì‘ì—… ì¶”ì  ë¬¸ì„œë“¤ì€ `internal/archive/`ë¡œ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤.

---

## ì™„ë£Œëœ ì‘ì—… (Phase 1-14)

> ìƒì„¸ ë‚´ìš©ì€ [internal/archive/COMPLETED.md](./internal/archive/COMPLETED.md) ì°¸ì¡°

### ì™„ë£Œ í˜„í™©

| Phase | Description | Status | Tests |
|-------|-------------|--------|-------|
| Phase 1-3 | Core System | âœ… Complete | 118 |
| Phase 4 | Foundation Enhancement | âœ… Complete | +60 |
| Phase 5 | Storage & Domain | âœ… Complete | +42 |
| Phase 6 | Advanced Features | âœ… Complete | +160 |
| Phase 7 | Production Ready | âœ… Complete | +10 |
| Phase 2 NLP | NLP Analysis | âœ… Complete | +97 |
| Phase 3 Causal | Causal Analysis | âœ… Complete | +27 |
| Phase 8 | Domain Memory Layering | âœ… Complete | +113 |
| Phase 9 | Korean RAG Optimization | âœ… Complete | +24 |
| Phase 10-13 | Streamlit Web UI | âœ… Complete | +138 |
| Phase 14 | Query-Based DAG Analysis Pipeline | âœ… Complete | +153 |
| **Total** | | **âœ… 100%** | **1,671** |

### ì£¼ìš” ë‹¬ì„± ì‚¬í•­

#### ì•„í‚¤í…ì²˜
- âœ… Hexagonal Architecture (Port/Adapter íŒ¨í„´)
- âœ… Domain-Driven Design
- âœ… í™•ì¥ ê°€ëŠ¥í•œ í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ

#### ê¸°ëŠ¥
- âœ… Multi-LLM (OpenAI, Azure, Anthropic, Ollama)
- âœ… Multi-DB (SQLite, PostgreSQL)
- âœ… Multi-Tracker (Langfuse, MLflow)
- âœ… 6 Ragas Metrics + 1 Custom Metric
- âœ… Korean NLP (í˜•íƒœì†Œ ë¶„ì„, BM25, Dense, Hybrid)
- âœ… Web UI (Streamlit ê¸°ë°˜)
- âœ… DAG Analysis Pipeline

#### ê°œë°œ ì¸í”„ë¼
- âœ… 1,671 tests collected (89% coverage)
- âœ… CI/CD (Ubuntu, macOS, Windows)
- âœ… PyPI ìë™ ë°°í¬
- âœ… Semantic Versioning

---

## í˜„ì¬ ì§„í–‰ ì¤‘ (2026 Q1)

> **Focus**: ì½”ë“œ í’ˆì§ˆ ê°œì„  ë° ì‚¬ìš©ì„± í–¥ìƒ
>
> **ê°œë°œ ìë™í™”**: AI ì—ì´ì „íŠ¸ ê¸°ë°˜ ë³‘ë ¬ ê°œë°œ ì›Œí¬í”Œë¡œìš° ë„ì…

### ì§„í–‰ ì¤‘ì¸ ê°œì„  ì‘ì—… (ë³‘ë ¬)

| ID | ì‘ì—… | ìƒíƒœ | ì°¸ê³  |
|----|------|------|------|
| P2.2 | Web UI ì¬êµ¬ì¡°í™” | ğŸš§ ì§„í–‰ ì¤‘ | `docs/internal/PARALLEL_WORK_PLAN.md` |
| P3 | ì„±ëŠ¥ ìµœì í™” | ğŸš§ ì§„í–‰ ì¤‘ | `docs/internal/PARALLEL_WORK_PLAN.md` |
| P4.1 | CLI UX ê°œì„  | ğŸš§ ì§„í–‰ ì¤‘ | `docs/internal/PARALLEL_WORK_PLAN.md` |
| P5 | í…ŒìŠ¤íŠ¸ ê°œì„  | ğŸš§ ì§„í–‰ ì¤‘ | `docs/internal/PARALLEL_WORK_PLAN.md` |
| P6 | ë¬¸ì„œí™” ê°œì„  | ğŸš§ ì§„í–‰ ì¤‘ | `docs/internal/PARALLEL_WORK_PLAN.md` |

ìƒì„¸ ë²”ìœ„ì™€ ì¼ì •ì€ `docs/internal/PARALLEL_WORK_PLAN.md`ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤.

### ê°œë°œ ìë™í™” ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ

Claude Agent SDK ê¸°ë°˜ ììœ¨ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œìœ¼ë¡œ ê°œì„  ì‘ì—…ì„ ë³‘ë ¬í™”í•©ë‹ˆë‹¤.

**ì—ì´ì „íŠ¸ êµ¬ì„±**:
| Agent | ì—­í•  | ë‹´ë‹¹ P-Level |
|-------|------|-------------|
| `architecture` | ì½”ë“œ êµ¬ì¡°, í—¥ì‚¬ê³ ë‚  ì•„í‚¤í…ì²˜ | P0, P1, P2 |
| `observability` | Phoenix í†µí•©, OpenTelemetry | P7 |
| `rag-data` | RAG ë°ì´í„° ìˆ˜ì§‘, ë©”íŠ¸ë¦­ | P7 |
| `performance` | ìºì‹±, ë°°ì¹˜ ì²˜ë¦¬ | P3 |
| `testing` | í…ŒìŠ¤íŠ¸ ìµœì í™”, ì»¤ë²„ë¦¬ì§€ | P5 |
| `documentation` | íŠœí† ë¦¬ì–¼, API ë¬¸ì„œ | P6 |
| `coordinator` | ë³‘ë ¬ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ | All |

**ë³‘ë ¬ ì‹¤í–‰ ê·¸ë£¹**:
- **Group A (ë…ë¦½)**: performance, testing, documentation - ë™ì‹œ ì‹¤í–‰ ê°€ëŠ¥
- **Group B (ìˆœì°¨)**: observability â†’ rag-data (ì˜ì¡´ì„±)
- **Group C (ë‚´ë¶€ ìˆœì„œ)**: architecture (P0 â†’ P1 â†’ P2)

**ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ**: `agent/memory/`ì— ì—ì´ì „íŠ¸ë³„ ì„¸ì…˜ ë¡œê·¸, ê³µìœ  ê²°ì •ì‚¬í•­, ì˜ì¡´ì„± ì¶”ì 

**ì°¸ì¡°**: [agent/README.md](../agent/README.md), [internal/DEVELOPMENT_GUIDE.md](./internal/DEVELOPMENT_GUIDE.md)

---

### P1: ì½”ë“œ í†µí•© ë° ì¤‘ë³µ ì œê±° (Week 1-2)

**ëª©í‘œ**: ì½”ë“œ ì¤‘ë³µ 30% ê°ì†Œ

#### 1.1 LLM Adapter í†µí•© âœ… ì™„ë£Œ
- [x] `BaseLLMAdapter` ìƒì„±
- [x] í† í° ì¶”ì  ê³µí†µí™”
- [x] ì—ëŸ¬ í•¸ë“¤ë§ ê³µí†µí™”
- [x] ê¸°ì¡´ ì–´ëŒ‘í„° ë¦¬íŒ©í† ë§

**ì˜ˆìƒ íš¨ê³¼**:
- ì½”ë“œ ì¤‘ë³µ: -300 LOC
- ìƒˆ LLM ì¶”ê°€ ì‹œê°„: 2ì‹œê°„ â†’ 30ë¶„

#### 1.2 Storage Adapter í†µí•© âœ… ì™„ë£Œ
- [x] `SQLQueries` í´ë˜ìŠ¤ ìƒì„±
- [x] `BaseSQLAdapter` ìƒì„±
- [x] ìŠ¤í‚¤ë§ˆ ê´€ë¦¬ í†µí•©

**ì˜ˆìƒ íš¨ê³¼**:
- ì½”ë“œ ì¤‘ë³µ: -400 LOC
- ìƒˆ DB ì§€ì›: 4ì‹œê°„ â†’ 1ì‹œê°„

#### 1.3 Analysis Adapter í†µí•© âœ… ì™„ë£Œ
- [x] `AnalysisDataProcessor` ìƒì„±
- [x] `BaseAnalysisAdapter` ìƒì„±
- [x] ë°ì´í„° ì²˜ë¦¬ ë¡œì§ í†µí•©

**ì˜ˆìƒ íš¨ê³¼**:
- ì½”ë“œ ì¤‘ë³µ: -200 LOC

---

### P2: ëª¨ë“ˆ ë¶„ë¦¬ (Week 3-4)

**ëª©í‘œ**: ëª¨ë“ˆ ë³µì¡ë„ 50% ê°ì†Œ

#### 2.1 CLI ëª¨ë“ˆ ë¶„ë¦¬ âœ… ì™„ë£Œ
- [x] CLI ëª…ë ¹ì–´ë³„ íŒŒì¼ ë¶„ë¦¬
- [x] ê³µí†µ ìœ í‹¸ë¦¬í‹° ì¶”ì¶œ
- [x] ëª…ë ¹ì–´ ë¼ìš°íŒ… ê°œì„ 

**êµ¬ì¡°**:
```
src/evalvault/adapters/inbound/cli/
â”œâ”€â”€ app.py
â”œâ”€â”€ commands/
â”‚   â”œâ”€â”€ run.py
â”‚   â”œâ”€â”€ analyze.py
â”‚   â”œâ”€â”€ history.py
â”‚   â”œâ”€â”€ generate.py
â”‚   â”œâ”€â”€ domain.py
â”‚   â”œâ”€â”€ gate.py
â”‚   â”œâ”€â”€ web.py
â”‚   â””â”€â”€ pipeline.py
â””â”€â”€ utils/
    â”œâ”€â”€ formatters.py
    â”œâ”€â”€ validators.py
    â””â”€â”€ errors.py
```

**ì˜ˆìƒ íš¨ê³¼**:
- íŒŒì¼ë‹¹ LOC: 1,500 â†’ 150
- ëª…ë ¹ì–´ ì¶”ê°€ ì‹œê°„: 50% ê°ì†Œ

---

### P4: ì‚¬ìš©ì„± ê°œì„  (Week 5-6)

**ëª©í‘œ**: ì‹ ê·œ ì‚¬ìš©ì ì˜¨ë³´ë”© ì‹œê°„ 50% ë‹¨ì¶•

#### 4.1 CLI UX ê°œì„  ğŸ”¥ High Priority

**ëª…ë ¹ì–´ ë³„ì¹­**:
```bash
# í˜„ì¬
evalvault run data.csv --metrics faithfulness,answer_relevancy

# ê°œì„ 
evalvault run data.csv -m faithfulness answer_relevancy
```

**í”„ë¦¬ì…‹ ì§€ì›**:
```bash
evalvault run data.csv --preset production
# production = faithfulness + answer_relevancy + context_precision + context_recall
```

**ì‘ì—… í•­ëª©**:
- [ ] ëª…ë ¹ì–´ ì˜µì…˜ ì¬ì„¤ê³„
- [ ] ì§§ì€ ë³„ì¹­ ì¶”ê°€
- [ ] í”„ë¦¬ì…‹ ì‹œìŠ¤í…œ êµ¬í˜„
- [ ] ë„ì›€ë§ ë©”ì‹œì§€ ê°œì„ 

#### 4.2 ì—ëŸ¬ ë©”ì‹œì§€ ê°œì„  ğŸ”¥ High Priority

**í˜„ì¬**:
```
Error: The api_key client option must be set
```

**ê°œì„ **:
```
âŒ Error: OpenAI API key not found

ğŸ“ How to fix:
   1. Create a .env file
   2. Add: OPENAI_API_KEY=your-key
   3. Or: export OPENAI_API_KEY=your-key

ğŸ’¡ Get key: https://platform.openai.com/api-keys
```

**ì‘ì—… í•­ëª©**:
- [ ] ì—ëŸ¬ ë©”ì‹œì§€ í…œí”Œë¦¿ ì‹œìŠ¤í…œ
- [ ] ëª¨ë“  ì—ëŸ¬ ì¼€ì´ìŠ¤ ì¬ì‘ì„±
- [ ] í•´ê²° ë°©ë²• ë¬¸ì„œí™”

#### 4.3 Progress Indicator âš¡ Quick Win

```python
from rich.progress import track

for test_case in track(dataset, description="Evaluating..."):
    result = evaluate(test_case)
```

**ì‘ì—… í•­ëª©**:
- [ ] Rich ë¼ì´ë¸ŒëŸ¬ë¦¬ í†µí•©
- [ ] Progress bar êµ¬í˜„
- [ ] ETA í‘œì‹œ ì¶”ê°€

---

### Quick Wins (ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥)

> **Duration**: 1-2ì¼

#### QW1: ì—ëŸ¬ ë©”ì‹œì§€ ê°œì„  (1ì¼) âœ…
```python
class UserFriendlyError:
    @staticmethod
    def missing_api_key(provider: str) -> str:
        return f"""
âŒ Error: {provider} API key not found
ğŸ“ Fix: Add {provider.upper()}_API_KEY to .env
ğŸ’¡ Get key: {PROVIDER_URLS[provider]}
"""
```

#### QW2: Progress Bar ì¶”ê°€ (0.5ì¼) âš¡
```bash
pip install rich
```

#### QW3: ëª…ë ¹ì–´ ë³„ì¹­ (0.5ì¼) âš¡
```python
@app.command()
def run(
    metrics: str = typer.Option(..., "-m", "--metrics"),
    llm: str = typer.Option("openai", "-l", "--llm"),
):
    ...
```

#### QW4: ì„¤ì • ê²€ì¦ (1ì¼) âœ…
```python
class ConfigValidator:
    def validate(self) -> list[str]:
        issues = []
        if not os.getenv("OPENAI_API_KEY"):
            issues.append("OPENAI_API_KEY not set")
        return issues
```

---

## í–¥í›„ ê³„íš (2026 Q2-Q4)

### 2026 Q2 (4-6ì›”): ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë“ˆí™”

P2.2, P3ëŠ” ë³‘ë ¬ ì‘ì—…ìœ¼ë¡œ ì„ í–‰ ì§„í–‰ ì¤‘ì´ë©° ìƒì„¸ ë²”ìœ„ëŠ”
`docs/internal/PARALLEL_WORK_PLAN.md`ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤.

#### P3: ì„±ëŠ¥ ìµœì í™”

**3.1 í‰ê°€ íŒŒì´í”„ë¼ì¸ ìµœì í™”**
- [ ] ë°°ì¹˜ ì²˜ë¦¬ ë¡œì§ ê°œì„ 
- [ ] ë¹„ë™ê¸° í‰ê°€ íŒŒì´í”„ë¼ì¸
- [ ] ìºì‹± ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€

**ëª©í‘œ**: 1000 TC í‰ê°€ ì‹œê°„ 30ë¶„ â†’ 10ë¶„

**3.2 ë°ì´í„° ë¡œë”© ìµœì í™”**
- [ ] ìŠ¤íŠ¸ë¦¬ë° ë¡œë” êµ¬í˜„
- [ ] ëŒ€ìš©ëŸ‰ íŒŒì¼ ì§€ì›

**ëª©í‘œ**: 10MB íŒŒì¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 100MB â†’ 10MB

**3.3 ìºì‹± ê°œì„ **
- [ ] LRU + TTL í•˜ì´ë¸Œë¦¬ë“œ ìºì‹œ
- [ ] ìºì‹œ hit rate ì¸¡ì •

**ëª©í‘œ**: ìºì‹œ hit rate 60% â†’ 85%

#### P2 (Part 2): ëª¨ë“ˆ ë¶„ë¦¬ ì™„ë£Œ

**2.2 Web UI ì¬êµ¬ì¡°í™”**
- [ ] ì„œë¹„ìŠ¤ ë ˆì´ì–´ ìƒì„±
- [ ] ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë¶„ë¦¬
- [ ] UI ì»´í¬ë„ŒíŠ¸ ìŠ¬ë¦¼í™”

**2.3 Domain Services ë¶„ë¦¬**
- [ ] ë‹¨ì¼ ì±…ì„ ì›ì¹™ ì ìš©
- [ ] ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ ë¶„ë¦¬

---

### 2026 Q3 (7-9ì›”): RAGAS ë˜í¼ íƒˆí”¼ - ê³ ìœ  ê°€ì¹˜ ê°•í™”

> **Goal**: EvalVaultë§Œì˜ ì°¨ë³„í™”ëœ ê°€ì¹˜ ì œê³µ
>
> **ì „ëµì  ë°©í–¥**: ë‹¨ìˆœ RAGAS ë˜í¼ë¥¼ ë„˜ì–´ì„œëŠ” í‰ê°€ OSë¡œ ì§„í™”
> - ë©”íŠ¸ë¦­ ì—”ì§„ ë…ë¦½ì„± í™•ë³´
> - ì§€ì‹/ë°ì´í„° ë ˆì´ì–´ ë‚´ì¬í™”
> - ìš´ì˜ ìë™í™”ì™€ í”¼ë“œë°± ë£¨í”„ êµ¬ì¶•

#### Phase 15: Custom Metric Framework

**ëª©í‘œ**: ì‚¬ìš©ìê°€ ì‰½ê²Œ ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ì„ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬

**êµ¬í˜„ ë‚´ìš©**:
```python
# ì‚¬ìš©ì ì •ì˜ ë©”íŠ¸ë¦­
from evalvault.domain.metrics import BaseMetric

class MyCustomMetric(BaseMetric):
    name = "my_custom_metric"
    description = "My custom evaluation metric"

    def score(self, test_case: TestCase) -> float:
        # ì»¤ìŠ¤í…€ ë¡œì§
        return 0.85

# ë“±ë¡
evalvault.register_metric(MyCustomMetric())

# ì‚¬ìš©
evalvault run data.csv --metrics my_custom_metric
```

**ì‘ì—… í•­ëª©**:
- [ ] `BaseMetric` ì¶”ìƒ í´ë˜ìŠ¤ ì„¤ê³„
- [ ] Metric Registry êµ¬í˜„
- [ ] CLI í†µí•©
- [ ] ë©”íŠ¸ë¦­ í”ŒëŸ¬ê·¸ì¸ ë¡œë”
- [ ] ì˜ˆì œ ë©”íŠ¸ë¦­ 5ê°œ ì‘ì„±

**ì˜ˆìƒ ê¸°ê°„**: 2ì£¼

#### Phase 16: Auto-Prompting System

**ëª©í‘œ**: LLM í‰ê°€ ì‹œ ìë™ìœ¼ë¡œ ìµœì ì˜ í”„ë¡¬í”„íŠ¸ ìƒì„±

**êµ¬í˜„ ë‚´ìš©**:
```python
class AutoPrompter:
    """ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„±"""

    def generate_prompt(
        self,
        metric: str,
        test_case: TestCase,
        domain: str = "general",
    ) -> str:
        """ë©”íŠ¸ë¦­ë³„ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # ë„ë©”ì¸ ì§€ì‹ í™œìš©
        domain_context = self.domain_memory.get_context(domain)

        # ë©”íŠ¸ë¦­ë³„ í…œí”Œë¦¿
        template = METRIC_TEMPLATES[metric]

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = template.format(
            question=test_case.question,
            answer=test_case.answer,
            context=test_case.contexts,
            domain_context=domain_context,
        )

        return prompt
```

**ì‘ì—… í•­ëª©**:
- [ ] ë©”íŠ¸ë¦­ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìˆ˜ì§‘
- [ ] ë„ë©”ì¸ë³„ í”„ë¡¬í”„íŠ¸ ìµœì í™”
- [ ] A/B í…ŒìŠ¤íŠ¸ë¡œ í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ë¹„êµ
- [ ] í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬

**ì˜ˆìƒ ê¸°ê°„**: 3ì£¼

#### Phase 17: Improvement Suggestion Engine

**ëª©í‘œ**: í‰ê°€ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ ì œê³µ

**í˜„ì¬ ìƒíƒœ**:
- Phase 3 Causal Analysisë¡œ ê·¼ë³¸ ì›ì¸ íŒŒì•…
- í•˜ì§€ë§Œ ì œì•ˆì´ ì¼ë°˜ì ì´ê³  êµ¬ì²´ì„± ë¶€ì¡±

**ê°œì„  ë°©í–¥**:
```python
class ImprovementEngine:
    """ê°œì„  ì œì•ˆ ì—”ì§„"""

    def generate_suggestions(
        self,
        run: EvaluationRun,
        use_llm: bool = True,
    ) -> list[ImprovementSuggestion]:
        """êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ ìƒì„±"""
        # 1. íŒ¨í„´ ë¶„ì„
        patterns = self.pattern_detector.detect(run)

        # 2. ê·¼ë³¸ ì›ì¸ ë¶„ì„ (ê¸°ì¡´ Causal Analysis í™œìš©)
        root_causes = self.causal_analyzer.analyze(run)

        # 3. í”Œë ˆì´ë¶ ê¸°ë°˜ ì œì•ˆ ìƒì„±
        suggestions = []
        for pattern in patterns:
            playbook = self.playbook_registry.get(pattern.type)
            suggestion = playbook.generate_suggestion(
                pattern=pattern,
                root_cause=root_causes.get(pattern.metric),
                domain=run.domain,
            )
            suggestions.append(suggestion)

        # 4. LLM ê¸°ë°˜ ì œì•ˆ (ì„ íƒì )
        if use_llm:
            enriched = self.llm_enricher.enrich(suggestions, run)
            suggestions = enriched

        return suggestions
```

**Playbook ì˜ˆì‹œ**:
```yaml
# config/playbooks/faithfulness_playbook.yaml
patterns:
  - name: long_context_low_faithfulness
    conditions:
      - metric: faithfulness
        threshold: 0.7
      - feature: context_length
        operator: ">"
        value: 500
    suggestions:
      - action: chunk_context
        priority: high
        rationale: "ê¸´ ì»¨í…ìŠ¤íŠ¸ëŠ” LLMì´ ì¶©ì‹¤í•˜ê²Œ ë”°ë¥´ê¸° ì–´ë µìŠµë‹ˆë‹¤"
        implementation:
          - "DocumentChunkerë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ 500ì ì´í•˜ë¡œ ë¶„í• "
          - "chunk_size=500, overlap=50 ê¶Œì¥"
        expected_improvement: "+15% faithfulness"
        verification:
          command: "evalvault run data.csv --chunk-size 500"
```

**ì‘ì—… í•­ëª©**:
- [ ] Pattern Detector êµ¬í˜„
- [ ] Playbook YAML í¬ë§· ì„¤ê³„
- [ ] ê¸°ë³¸ Playbook ì‘ì„± (10ê°œ íŒ¨í„´)
- [ ] LLM ê¸°ë°˜ ì œì•ˆ enrichment
- [ ] CLI í†µí•© (`evalvault suggest <run_id>`)

**ì˜ˆìƒ ê¸°ê°„**: 3ì£¼

---

### 2026 Q4 (10-12ì›”): ê³ ê¸‰ ê¸°ëŠ¥ ë° ìƒíƒœê³„ í™•ì¥

#### Phase 18: RAG Pipeline Integration

**ëª©í‘œ**: RAG íŒŒì´í”„ë¼ì¸ì„ ì§ì ‘ EvalVaultì—ì„œ ì‹¤í–‰í•˜ê³  í‰ê°€

**í˜„ì¬ í•œê³„**:
- ì‚¬ìš©ìê°€ ì™¸ë¶€ì—ì„œ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ â†’ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥ â†’ EvalVaultë¡œ í‰ê°€
- ë²ˆê±°ë¡­ê³  ì‹¤ìˆ˜í•˜ê¸° ì‰¬ì›€

**ê°œì„  ë°©í–¥**:
```python
# RAG íŒŒì´í”„ë¼ì¸ ì •ì˜
from evalvault.pipeline import RAGPipeline

pipeline = RAGPipeline(
    retriever=BM25Retriever(documents),
    llm=OpenAI(model="gpt-4"),
    prompt_template="...",
)

# í‰ê°€ + íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ í•œ ë²ˆì—
result = evalvault.evaluate(
    questions=["ì§ˆë¬¸1", "ì§ˆë¬¸2", ...],
    pipeline=pipeline,
    metrics=["faithfulness", "answer_relevancy"],
)

# ë˜ëŠ” CLIë¡œ
evalvault run-pipeline config.yaml \
  --questions questions.csv \
  --metrics faithfulness
```

**ì‘ì—… í•­ëª©**:
- [ ] `RAGPipeline` ì¶”ìƒ í´ë˜ìŠ¤ ì„¤ê³„
- [ ] Retriever í†µí•© (BM25, Dense, Hybrid)
- [ ] LLM í†µí•© (ê¸°ì¡´ LLMPort í™œìš©)
- [ ] íŒŒì´í”„ë¼ì¸ ì„¤ì • íŒŒì¼ í¬ë§· (YAML)
- [ ] CLI í†µí•©
- [ ] LangChain/LlamaIndex í˜¸í™˜ì„±

**ì˜ˆìƒ ê¸°ê°„**: 4ì£¼

#### Phase 19: Knowledge Graph ê³ ë„í™”

**ëª©í‘œ**: NetworkX ê¸°ë°˜ ê³ ê¸‰ KG ê¸°ëŠ¥ ë° KG ê¸°ë°˜ í‰ê°€

**í˜„ì¬ ìƒíƒœ**:
- Phase 6ì—ì„œ ê¸°ë³¸ KG ìƒì„± ë° í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì™„ë£Œ
- í•˜ì§€ë§Œ KG ë¶„ì„, ì‹œê°í™”, KG ê¸°ë°˜ ë©”íŠ¸ë¦­ ë¶€ì¡±

**ê°œì„  ë°©í–¥**:

**19.1 NetworkX ë§ˆì´ê·¸ë ˆì´ì…˜**
```python
# í˜„ì¬: ë‹¨ìˆœ dict ê¸°ë°˜ ê·¸ë˜í”„
class KnowledgeGraph:
    nodes: dict[str, Entity]
    edges: list[Relation]

# ê°œì„ : NetworkX ê¸°ë°˜
import networkx as nx

class KnowledgeGraph:
    def __init__(self):
        self.graph = nx.MultiDiGraph()

    def add_entity(self, entity: Entity):
        self.graph.add_node(
            entity.id,
            type=entity.type,
            **entity.attributes
        )

    def add_relation(self, relation: Relation):
        self.graph.add_edge(
            relation.source,
            relation.target,
            type=relation.type,
            **relation.attributes
        )

    # NetworkX ê¸°ëŠ¥ í™œìš©
    def shortest_path(self, source, target):
        return nx.shortest_path(self.graph, source, target)

    def centrality(self):
        return nx.betweenness_centrality(self.graph)
```

**19.2 KG ê¸°ë°˜ í‰ê°€ ë©”íŠ¸ë¦­**
```python
class KGCoverageMetric(BaseMetric):
    """KG ì»¤ë²„ë¦¬ì§€ ë©”íŠ¸ë¦­"""

    def score(self, test_case: TestCase, kg: KnowledgeGraph) -> float:
        """ë‹µë³€ì´ KGì˜ ì—”í‹°í‹°/ê´€ê³„ë¥¼ ì–¼ë§ˆë‚˜ ì»¤ë²„í•˜ëŠ”ì§€"""
        answer_entities = self.extract_entities(test_case.answer)
        kg_entities = kg.get_entities()

        coverage = len(answer_entities & kg_entities) / len(kg_entities)
        return coverage

class KGConsistencyMetric(BaseMetric):
    """KG ì¼ê´€ì„± ë©”íŠ¸ë¦­"""

    def score(self, test_case: TestCase, kg: KnowledgeGraph) -> float:
        """ë‹µë³€ì´ KGì˜ ê´€ê³„ì™€ ì¼ì¹˜í•˜ëŠ”ì§€"""
        claims = self.extract_claims(test_case.answer)

        consistent_claims = 0
        for claim in claims:
            if self.verify_with_kg(claim, kg):
                consistent_claims += 1

        return consistent_claims / len(claims)
```

**19.3 KG í†µê³„ ë° ë¶„ì„**
```python
class KGAnalyzer:
    """KG ë¶„ì„ê¸°"""

    def analyze(self, kg: KnowledgeGraph) -> KGStats:
        """KG í†µê³„ ë¶„ì„"""
        return KGStats(
            num_entities=kg.graph.number_of_nodes(),
            num_relations=kg.graph.number_of_edges(),
            entity_types=self._count_entity_types(kg),
            relation_types=self._count_relation_types(kg),
            centrality=self._calculate_centrality(kg),
            clusters=self._detect_clusters(kg),
            density=nx.density(kg.graph),
        )

    def visualize(self, kg: KnowledgeGraph, output: str):
        """KG ì‹œê°í™” (Plotly/Graphviz)"""
        ...
```

**19.4 CLI í†µí•©**
```bash
# KG ìƒì„±
evalvault kg build documents.md -o knowledge_graph.json

# KG ë¶„ì„
evalvault kg analyze knowledge_graph.json

# KG ì‹œê°í™”
evalvault kg visualize knowledge_graph.json -o graph.html

# KG ê¸°ë°˜ í‰ê°€
evalvault run data.csv \
  --kg knowledge_graph.json \
  --metrics kg_coverage kg_consistency
```

**ì‘ì—… í•­ëª©**:
- [ ] NetworkX ë§ˆì´ê·¸ë ˆì´ì…˜
- [ ] KG ê¸°ë°˜ ë©”íŠ¸ë¦­ êµ¬í˜„
- [ ] KG ë¶„ì„ ê¸°ëŠ¥
- [ ] KG ì‹œê°í™” (Plotly)
- [ ] CLI í†µí•©

**ì˜ˆìƒ ê¸°ê°„**: 4-5ì£¼

---

## Enterprise Track

> **ëª©í‘œ**: ë©€í‹°í…Œë„ŒíŠ¸, ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬, RBAC ê¸°ë°˜ ì—”í„°í”„ë¼ì´ì¦ˆ ìš´ì˜ í™˜ê²½ êµ¬ì¶•
>
> **ìƒì„¸ ê³„íš**: [enterprise/IMPLEMENTATION_PLAN.md](./enterprise/IMPLEMENTATION_PLAN.md)

### Enterprise Phases

| Phase | ë²”ìœ„ | ì„¤ëª… | ì„ í–‰ ì¡°ê±´ |
|-------|------|------|-----------|
| **E1** | Job + Queue | Job ì—”í‹°í‹°, JobQueuePort (Celery+Redis), ë¹„ë™ê¸° ì œì¶œ/ìƒíƒœ ì¡°íšŒ | - |
| **E2** | Idempotency + Store | JobStorePort, IdempotencyPort, ì¤‘ë³µ ì œì¶œ ë°©ì§€, DLQ | E1 |
| **E3** | Multi-tenancy | Tenant/Project/User ê³„ì¸µ, DB ìŠ¤í‚¤ë§ˆ í™•ì¥, Row-Level Security | E2 |
| **E4** | Auth/RBAC | AuthPort, OIDC/JWT, RBAC ìŠ¤ì½”í”„ (admin/write/read) | E3 |
| **E5** | API Server | FastAPI ì„œë²„, REST ì—”ë“œí¬ì¸íŠ¸, ì¸ì¦ ë¯¸ë“¤ì›¨ì–´ | E4 |
| **E6** | Observability | Prometheus ë©”íŠ¸ë¦­, Grafana ëŒ€ì‹œë³´ë“œ, SLO ì•ŒëŸ¿ | E5 |
| **E7** | Operations | Alembic ë§ˆì´ê·¸ë ˆì´ì…˜, Helm ì°¨íŠ¸, Terraform ëª¨ë“ˆ | E6 |

### í•µì‹¬ ì•„í‚¤í…ì²˜ ê²°ì •

#### Job vs EvaluationRun ë¶„ë¦¬

```
Job (ìš´ì˜ ë‹¨ìœ„)              EvaluationRun (ê²°ê³¼)
â”œâ”€â”€ job_id                   â”œâ”€â”€ run_id
â”œâ”€â”€ tenant_id / project_id   â”œâ”€â”€ dataset_name
â”œâ”€â”€ status (QUEUEDâ†’RUNNINGâ†’â€¦)â”œâ”€â”€ metrics / scores
â”œâ”€â”€ idempotency_key          â””â”€â”€ tracker_metadata
â””â”€â”€ result_ref â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ (1:1 ì—°ê²°)
```

- **Job**: ì‘ì—… ìƒíƒœ ì¶”ì , ì¬ì‹œë„/ì·¨ì†Œ ê´€ë¦¬ (ìš´ì˜ ê´€ì )
- **EvaluationRun**: í‰ê°€ ê²°ê³¼ ì €ì¥, ë¶„ì„ (ë°ì´í„° ê´€ì )

#### ì‹ ê·œ Port ì¸í„°í˜ì´ìŠ¤

```
Outbound Ports                 Inbound Ports
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JobQueuePort        â”‚       â”‚ AuthPort            â”‚
â”‚ JobStorePort        â”‚       â”‚ RunSubmissionPort   â”‚
â”‚ IdempotencyPort     â”‚       â”‚ JobQueryPort        â”‚
â”‚ AuditPort           â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ RegistryPort        â”‚
â”‚ ObjectStoragePort   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### êµ¬í˜„ ì˜ì¡´ì„± ê·¸ë˜í”„

```mermaid
graph TD
    E1[E1: Job + Queue] --> E2[E2: Idempotency]
    E2 --> E3[E3: Multi-tenancy]
    E3 --> E4[E4: Auth/RBAC]
    E4 --> E5[E5: API Server]
    E5 --> E6[E6: Observability]
    E6 --> E7[E7: Operations]

    subgraph ë…ë¦½ ê°€ëŠ¥
        P3[P3: ì„±ëŠ¥ ìµœì í™”]
        P5[P5: í…ŒìŠ¤íŠ¸ ê°œì„ ]
    end

    E2 -.-> P3
    E5 -.-> P5
```

### Operations Checklist

#### ì‹ ë¢°ì„± / ìš´ì˜
- [ ] Job retry policy (transient vs deterministic error êµ¬ë¶„)
- [ ] Dead Letter Queue êµ¬í˜„
- [ ] Graceful shutdown (SIGTERM ì²˜ë¦¬)
- [ ] Health check ì—”ë“œí¬ì¸íŠ¸ (`/health/live`, `/health/ready`)

#### ë³´ì•ˆ / ì ‘ê·¼ ì œì–´
- [ ] OIDC/JWT ì¸ì¦ íë¦„
- [ ] RBAC ìŠ¤ì½”í”„ ì •ì˜ (`tenant:admin`, `project:write`, `project:read`)
- [ ] Audit ë¡œê·¸ (ëˆ„ê°€, ì–¸ì œ, ë¬´ì—‡ì„)
- [ ] Secret ê´€ë¦¬ (Vault ì—°ë™ ë˜ëŠ” K8s Secret)

#### ë°ì´í„° / ìŠ¤í† ë¦¬ì§€
- [ ] Alembic ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
- [ ] Row-Level Security (PostgreSQL)
- [ ] Object Storage ì—°ë™ (S3/MinIO)
- [ ] ë°ì´í„° ë³´ì¡´ ì •ì±…

#### Observability
- [ ] Phoenix: LLM traces (í’ˆì§ˆ ë””ë²„ê¹…)
- [ ] Prometheus: ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ (SLO ëª¨ë‹ˆí„°ë§)
- [ ] Grafana: ëŒ€ì‹œë³´ë“œ í…œí”Œë¦¿
- [ ] Alert rules ì •ì˜

### CLI ì¸ì¦ ì˜µì…˜ ë¶„ë¦¬

```bash
# ëª¨ë¸ í”„ë¡œíŒŒì¼ (ê¸°ì¡´)
evalvault run data.csv --profile azure-gpt4

# ì¸ì¦ í”„ë¡œíŒŒì¼ (ì‹ ê·œ, E4 ì´í›„)
evalvault run data.csv --auth-profile production

# API ì„œë²„ ëª¨ë“œ (E5 ì´í›„)
evalvault run data.csv --endpoint https://api.company.com
```

### Quick Wins (Enterprise ì¤€ë¹„)

| í•­ëª© | ì„¤ëª… | ë‚œì´ë„ |
|------|------|--------|
| Job ID í•„ë“œ ì¶”ê°€ | EvaluationRunì— `job_id: str | None` ì¶”ê°€ | â­ |
| Celery task ìŠ¤ì¼ˆë ˆí†¤ | `tasks/evaluation.py` ë¹ˆ êµ¬ì¡° ìƒì„± | â­ |
| DB ìŠ¤í‚¤ë§ˆ ì„¤ê³„ | `jobs` í…Œì´ë¸” DDL ì‘ì„± | â­â­ |
| RBAC ìŠ¤ì½”í”„ enum | `RBACScope` enum ì •ì˜ | â­ |

---

## ë¯¸ë˜ ì—°êµ¬ (2027+)

> **Note**: ì•„ë˜ ê¸°ëŠ¥ë“¤ì€ ì¥ê¸° ì—°êµ¬ ì£¼ì œì´ë©°, ì‹¤ì œ í•„ìš”ì„±ì´ ê²€ì¦ëœ í›„ êµ¬í˜„í•©ë‹ˆë‹¤.

### Agent System Integration

**ì „ì œ ì¡°ê±´**: ë©€í‹°ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ ë„ì…

**í˜„ì¬ êµ¬ì¡°**:
```
Dataset â†’ RagasEvaluator â†’ Results (ìˆœì°¨ íŒŒì´í”„ë¼ì¸)
```

**ë¯¸ë˜ êµ¬ì¡°**:
```
Dataset â†’ [Planner Agent] â†’ [Metric Agents] â†’ [Insight Agent] â†’ Results
              â†‘                    â†‘                â†‘
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      Agent Coordination
```

#### Coordination Profiler

**ëª©í‘œ**: Scaling Agent Systems ë…¼ë¬¸ ê¸°ë°˜, ë©€í‹°ì—ì´ì „íŠ¸ ì˜¤ë²„í—¤ë“œ ì •ëŸ‰í™”

**CLI ìŠ¤í™** (ë¯¸ë˜):
```bash
evalvault profile <dataset_path> \
  --agents single|centralized|decentralized \
  --max-calls 1000 \
  --emit-policy
```

**ìš°ì„ ìˆœìœ„**: Agent Architecture ë„ì… í›„

#### Latent Evidence Bus

**ëª©í‘œ**: LatentMAS ìŠ¤íƒ€ì¼ KV cache / hidden state ê³µìœ 

**ì œì•½**:
- OpenAI/Anthropic API: hidden state ë¯¸ë…¸ì¶œ â†’ ë¶ˆê°€ëŠ¥
- HuggingFace/vLLM ë¡œì»¬ ëª¨ë¸: ê°€ëŠ¥ (ë³„ë„ ì–´ëŒ‘í„° í•„ìš”)

**í˜„ì‹¤ì  ë²”ìœ„**:
- Q1: Anthropic Extended Thinking ìº¡ì²˜ (API ê¸°ë°˜)
- ì´í›„: HuggingFace/vLLM ì§ì ‘ í†µí•© ì—°êµ¬

**ìš°ì„ ìˆœìœ„**: Agent Architecture + ë¡œì»¬ ëª¨ë¸ ì¸í”„ë¼ í™•ë³´ í›„

---

## ì‹¤í–‰ ë¡œë“œë§µ ìš”ì•½

### 2026 Q1 (1-3ì›”): ì½”ë“œ í’ˆì§ˆ ê°œì„ 

- Week 1-2: P1 ì½”ë“œ í†µí•©
- Week 3-4: P2 ëª¨ë“ˆ ë¶„ë¦¬ (Part 1)
- Week 5-6: P4 ì‚¬ìš©ì„± ê°œì„ 

### 2026 Q2 (4-6ì›”): ì„±ëŠ¥ ìµœì í™”

- Week 7-8: P2 ëª¨ë“ˆ ë¶„ë¦¬ (Part 2)
- Week 9-10: P3 ì„±ëŠ¥ ìµœì í™”
- Week 11-12: P5 & P6 í…ŒìŠ¤íŠ¸/ë¬¸ì„œí™”

### 2026 Q3 (7-9ì›”): ê³ ìœ  ê°€ì¹˜ ê°•í™”

- Week 13-14: Phase 15 Custom Metric Framework
- Week 15-17: Phase 16 Auto-Prompting System
- Week 18-20: Phase 17 Improvement Suggestion Engine

### 2026 Q4 (10-12ì›”): ìƒíƒœê³„ í™•ì¥

- Week 21-24: Phase 18 RAG Pipeline Integration
- Week 25-29: Phase 19 Knowledge Graph ê³ ë„í™”

### 2027+: ë¯¸ë˜ ì—°êµ¬

- Agent System Integration
- Coordination Profiler
- Latent Evidence Bus

---

## ì„±ê³µ ì§€í‘œ

### ì½”ë“œ í’ˆì§ˆ (2026 Q1-Q2)

| ì§€í‘œ | Baseline | ëª©í‘œ |
|------|----------|------|
| ì½”ë“œ ì¤‘ë³µë¥  | 15% | 10% |
| í‰ê·  ëª¨ë“ˆ í¬ê¸° | 300 LOC | 150 LOC |
| í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œê°„ | 14ë¶„ | 7ë¶„ |
| ì‹ ê·œ ì‚¬ìš©ì ì˜¨ë³´ë”© | 30ë¶„ | 15ë¶„ |

### ì„±ëŠ¥ (2026 Q2)

| ì§€í‘œ | Baseline | ëª©í‘œ |
|------|----------|------|
| 1000 TC í‰ê°€ ì‹œê°„ | 30ë¶„ | 10ë¶„ |
| ìºì‹œ hit rate | 60% | 85% |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (10MB íŒŒì¼) | 100MB | 10MB |

### ê³ ìœ  ê°€ì¹˜ (2026 Q3-Q4)

| ì§€í‘œ | Baseline | ëª©í‘œ |
|------|----------|------|
| ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì¶”ê°€ ì‹œê°„ | N/A | 30ë¶„ |
| ê°œì„  ì œì•ˆ êµ¬ì²´ì„± | Low | High |
| RAG íŒŒì´í”„ë¼ì¸ í†µí•© | None | Full |

---

## ì°¸ê³  ë¬¸ì„œ

- [README.md](./README.md): ì „ì²´ ë¬¸ì„œ ì¸ë±ìŠ¤
- [STATUS.md](./STATUS.md): í˜„ì¬ ìƒíƒœ ìš”ì•½
- [USER_GUIDE.md](./USER_GUIDE.md): ì‚¬ìš©ì ê°€ì´ë“œ
- [ARCHITECTURE.md](./ARCHITECTURE.md): ì•„í‚¤í…ì²˜ ë¬¸ì„œ
- [internal/DEVELOPMENT_GUIDE.md](./internal/DEVELOPMENT_GUIDE.md): ê°œë°œ ê°€ì´ë“œ (ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° í¬í•¨)
- [agent/README.md](../agent/README.md): ììœ¨ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì‚¬ìš© ê°€ì´ë“œ

---

## ê¸°ì—¬ ë°©ë²•

EvalVaultëŠ” ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤!

1. Issueì—ì„œ ì‘ì—…í•  í•­ëª© ì„ íƒ ë˜ëŠ” ìƒˆ Issue ìƒì„±
2. Fork & Branch ìƒì„±
3. ì½”ë“œ ì‘ì„± + í…ŒìŠ¤íŠ¸ ì‘ì„±
4. PR ìƒì„±
5. Code Review ë° Merge

**ê¸°ì—¬ ê°€ì´ë“œ**: [CONTRIBUTING.md](../CONTRIBUTING.md)

---

## ë¼ì´ì„ ìŠ¤

EvalVaultëŠ” [Apache 2.0](../LICENSE.md) ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤.

---

**Last Updated**: 2026-01-03
