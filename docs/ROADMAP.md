# EvalVault Development Roadmap

> Last Updated: 2025-12-29
> Current Version: 1.1.0
> Status: Analysis Features Complete (Phase 2 NLP + Phase 3 Causal)

---

## Overview

EvalVaultì˜ ê°œë°œ ë¡œë“œë§µì…ë‹ˆë‹¤. Phase 1-7 Core System ë° Analysis ê¸°ëŠ¥(Phase 2 NLP, Phase 3 Causal)ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

### Progress Summary

| Phase | Description | Status | Tests |
|-------|-------------|--------|-------|
| Phase 1-3 | Core System | âœ… Complete | 118 |
| Phase 4 | Foundation Enhancement | âœ… Complete | +60 |
| Phase 5 | Storage & Domain | âœ… Complete | +42 |
| Phase 6 | Advanced Features | âœ… Complete | +160 |
| Phase 7 | Production Ready | âœ… Complete | +10 |
| **Phase 2 NLP** | NLP Analysis | âœ… Complete | +97 |
| **Phase 3 Causal** | Causal Analysis | âœ… Complete | +27 |
| **Total** | | | **778** |

---

## Phase 2: NLP Analysis âœ…

> **Status**: Complete (2025-12-29)
> **Tests**: +97

í‰ê°€ ê²°ê³¼ì— ëŒ€í•œ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì„ ê¸°ëŠ¥ì…ë‹ˆë‹¤.

### êµ¬í˜„ëœ ê¸°ëŠ¥

| Sub-Phase | Description | Status |
|-----------|-------------|--------|
| Phase 2.3 | NLP Adapter (Hybrid: Rule + ML + LLM) | âœ… Complete |
| Phase 2.4 | AnalysisService Integration | âœ… Complete |
| Phase 2.5 | CLI Integration (`--nlp`, `--profile`) | âœ… Complete |
| Phase 2.6 | Database Storage for NLP Analysis | âœ… Complete |
| Phase 2.7 | Topic Clustering (K-Means + Embeddings) | âœ… Complete |
| Phase 2.8 | Report Generation (Markdown/HTML) | âœ… Complete |

### ì£¼ìš” íŒŒì¼

```
src/evalvault/
â”œâ”€â”€ adapters/outbound/analysis/
â”‚   â””â”€â”€ nlp_adapter.py          # NLP ë¶„ì„ ì–´ëŒ‘í„°
â”œâ”€â”€ adapters/outbound/report/
â”‚   â””â”€â”€ markdown_adapter.py     # Markdown/HTML ë³´ê³ ì„œ ìƒì„±
â”œâ”€â”€ ports/outbound/
â”‚   â”œâ”€â”€ nlp_analysis_port.py    # NLP ë¶„ì„ í¬íŠ¸
â”‚   â””â”€â”€ report_port.py          # ë³´ê³ ì„œ ìƒì„± í¬íŠ¸
â””â”€â”€ domain/entities/
    â””â”€â”€ analysis.py             # NLPAnalysis, TextStats, TopicCluster ë“±
```

### CLI ì‚¬ìš©ë²•

```bash
# NLP ë¶„ì„ ì‹¤í–‰
evalvault analyze <run_id> --nlp --profile dev

# ë³´ê³ ì„œ ìƒì„±
evalvault analyze <run_id> --nlp --report report.md
evalvault analyze <run_id> --nlp --report report.html
```

---

## Phase 3: Causal Analysis âœ…

> **Status**: Complete (2025-12-29)
> **Tests**: +27

í‰ê°€ ê²°ê³¼ì—ì„œ ì¸ê³¼ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ê·¼ë³¸ ì›ì¸ì„ íŒŒì•…í•˜ê³  ê°œì„  ì œì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤.

### êµ¬í˜„ëœ ê¸°ëŠ¥

| Feature | Description |
|---------|-------------|
| Factor Extraction | ì§ˆë¬¸ ê¸¸ì´, ì»¨í…ìŠ¤íŠ¸ ìˆ˜, í‚¤ì›Œë“œ ê²¹ì¹¨ ë“± ì¸ê³¼ ìš”ì¸ ì¶”ì¶œ |
| Factor-Metric Impact | ê° ìš”ì¸ì´ ë©”íŠ¸ë¦­ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„ (ìƒê´€ë¶„ì„) |
| Causal Relationships | ìœ ì˜ë¯¸í•œ ì¸ê³¼ ê´€ê³„ ì‹ë³„ |
| Root Cause Analysis | ë©”íŠ¸ë¦­ë³„ ê·¼ë³¸ ì›ì¸ ë¶„ì„ |
| Intervention Suggestions | ê°œì„  ì œì•ˆ ìƒì„± |
| Stratified Analysis | ìš”ì¸ê°’ë³„ ê³„ì¸µí™” ë¶„ì„ (low/medium/high) |

### ì£¼ìš” íŒŒì¼

```
src/evalvault/
â”œâ”€â”€ adapters/outbound/analysis/
â”‚   â””â”€â”€ causal_adapter.py       # ì¸ê³¼ ë¶„ì„ ì–´ëŒ‘í„°
â”œâ”€â”€ ports/outbound/
â”‚   â””â”€â”€ causal_analysis_port.py # ì¸ê³¼ ë¶„ì„ í¬íŠ¸
â””â”€â”€ domain/entities/
    â””â”€â”€ analysis.py             # CausalAnalysis, FactorImpact, RootCause ë“±
```

### CLI ì‚¬ìš©ë²•

```bash
# ì¸ê³¼ ë¶„ì„ ì‹¤í–‰
evalvault analyze <run_id> --causal

# NLP + ì¸ê³¼ ë¶„ì„ í•¨ê»˜ ì‹¤í–‰
evalvault analyze <run_id> --nlp --causal --report report.html
```

### ì¸ê³¼ ìš”ì¸ (Causal Factors)

| Factor | Description |
|--------|-------------|
| `question_length` | ì§ˆë¬¸ ê¸¸ì´ (ë‹¨ì–´ ìˆ˜) |
| `answer_length` | ë‹µë³€ ê¸¸ì´ (ë‹¨ì–´ ìˆ˜) |
| `context_count` | ì»¨í…ìŠ¤íŠ¸ ìˆ˜ |
| `context_length` | ì»¨í…ìŠ¤íŠ¸ ì´ ê¸¸ì´ |
| `question_complexity` | ì§ˆë¬¸ ë³µì¡ë„ |
| `has_ground_truth` | ground_truth ì¡´ì¬ ì—¬ë¶€ |
| `keyword_overlap` | ì§ˆë¬¸-ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ê²¹ì¹¨ |

---

## Phase 8: Domain Memory Layering (Target: 2026 Q1)

> **Status**: Planning
> **Priority**: ğŸ”¥ High
> **Effort**: ~50h / 4 weeks

EvalVaultì˜ í˜„ì¬ ì•„í‚¤í…ì²˜(ìˆœì°¨ì  í‰ê°€ íŒŒì´í”„ë¼ì¸)ì— ë§ëŠ” ì‹¤ì§ˆì ì¸ ê°œì„  ì‚¬í•­ì…ë‹ˆë‹¤.

### ëª©í‘œ

í‰ê°€ ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ì—¬ ì—”í‹°í‹° ì¶”ì¶œê³¼ ì§€ì‹ ê·¸ë˜í”„ ìƒì„±ì˜ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

### í•µì‹¬ ê°œë…

Agent Memory Surveyì˜ FormsÃ—Functions ê°€ì´ë“œë¼ì¸ì„ ë„ì…í•´ ë„ë©”ì¸ ì§€ì‹ì„ ì„¸ ê³„ì¸µìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤:

| ê³„ì¸µ | ëª©ì  | ì˜ˆì‹œ |
|------|------|------|
| **Factual** | ê²€ì¦ëœ ì •ì  ì‚¬ì‹¤ | ìš©ì–´ ì‚¬ì „, ê·œì • ë¬¸ì„œ |
| **Experiential** | í‰ê°€ì—ì„œ í•™ìŠµí•œ íŒ¨í„´ | ì—”í‹°í‹° íƒ€ì…ë³„ ì‹ ë¢°ë„, ì‹¤íŒ¨ íŒ¨í„´ |
| **Working** | í˜„ì¬ ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ | ì„¸ì…˜ ìºì‹œ, í™œì„± KG ë°”ì¸ë”© |

### êµ¬í˜„ ê³„íš

#### Phase 8.1: Factual Memory Store (Week 1-2)

```
src/evalvault/domain/entities/memory.py
â”œâ”€â”€ FactualFact (ê²€ì¦ëœ ì‚¬ì‹¤ ì—”í‹°í‹°)
â”œâ”€â”€ LearningMemory (í•™ìŠµëœ íŒ¨í„´)
â””â”€â”€ DomainMemoryContext (ì›Œí‚¹ ë©”ëª¨ë¦¬)

src/evalvault/ports/outbound/domain_memory_port.py
â””â”€â”€ DomainMemoryPort (store_fact, query_facts, record_learning)

src/evalvault/adapters/outbound/domain_memory/
â””â”€â”€ sqlite_adapter.py (SQLite ê¸°ë°˜ ë©”ëª¨ë¦¬ ì €ì¥ì†Œ)
```

#### Phase 8.2: Config Extension (Week 2-3)

```yaml
# config/domains/insurance/memory.yaml
factual:
  glossary: terms_dictionary.json
  regulatory_rules: rules.md
  languages: ["ko", "en"]  # ë‹¤êµ­ì–´ ì§€ì›
experiential:
  reliability_scores: reliability.json
  failure_modes: failures.json
working:
  run_cache: ${RUN_DIR}/memory.db
  kg_binding: kg://insurance
```

**CLI í™•ì¥:**
```bash
evalvault domain init <domain>      # ë„ë©”ì¸ ì„¤ì • ì´ˆê¸°í™”
evalvault domain list               # ë“±ë¡ëœ ë„ë©”ì¸ ëª©ë¡
evalvault run ... --memory-layer working  # íŠ¹ì • ê³„ì¸µë§Œ ë¡œë“œ
```

#### Phase 8.3: Learning Integration (Week 3-4)

**DomainLearningHook í”„ë¡œí† ì½œ** (ê²°í•©ë„ ìµœì†Œí™”):
```python
class DomainLearningHook(Protocol):
    """í‰ê°€ ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ëŠ” í›… ì¸í„°í˜ì´ìŠ¤"""
    def on_evaluation_complete(self, run: EvaluationRun) -> LearningMemory:
        """í‰ê°€ ì™„ë£Œ ì‹œ íŒ¨í„´ í•™ìŠµ"""
        ...

    def apply_learning(self, extractor: EntityExtractor) -> None:
        """í•™ìŠµëœ íŒ¨í„´ì„ ì¶”ì¶œê¸°ì— ì ìš©"""
        ...
```

### ì„±ê³µ ì§€í‘œ

| ì§€í‘œ | Baseline | ëª©í‘œ |
|------|----------|------|
| Entity Extraction Accuracy | í˜„ì¬ ì¸¡ì • í•„ìš” | +10% |
| ë„ë©”ì¸ ì˜¨ë³´ë”© ì‹œê°„ | ìˆ˜ë™ ì„¤ì • | CLI ìë™í™” |
| ë°˜ë³µ ì‹¤ìˆ˜ìœ¨ | ì¸¡ì • í•„ìš” | -30% |

---

## Future: Agent System Integration

> **Status**: Research / Deferred
> **Prerequisite**: ë©€í‹°ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ ë„ì…

í˜„ì¬ EvalVaultëŠ” **ìˆœì°¨ì  í‰ê°€ íŒŒì´í”„ë¼ì¸**ì…ë‹ˆë‹¤. ì•„ë˜ ê¸°ëŠ¥ë“¤ì€ **ì§„ì •í•œ ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ** ë„ì… í›„ì— ì˜ë¯¸ê°€ ìˆìŠµë‹ˆë‹¤.

### ì „ì œ ì¡°ê±´: Agent Architecture

```
í˜„ì¬ êµ¬ì¡° (ì—ì´ì „íŠ¸ ì—†ìŒ):
  Dataset â†’ RagasEvaluator â†’ Results

ë¯¸ë˜ êµ¬ì¡° (ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ):
  Dataset â†’ [Planner Agent] â†’ [Metric Agents] â†’ [Insight Agent] â†’ Results
                  â†‘                    â†‘                â†‘
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           Agent Coordination
```

### Coordination Profiler & Policy Guard

**ì „ì œ**: í”„ë¡œíŒŒì¼ë§í•  ì—ì´ì „íŠ¸ ê°„ ì¡°ìœ¨ì´ ì¡´ì¬í•´ì•¼ í•¨

- **ëª©í‘œ**: Scaling Agent Systems ë…¼ë¬¸ ê¸°ë°˜, ë©€í‹°ì—ì´ì „íŠ¸ ì˜¤ë²„í—¤ë“œ ì •ëŸ‰í™”
- **CLI ìŠ¤í™** (ë¯¸ë˜):
  ```bash
  evalvault profile <dataset_path> \
    --agents single|centralized|decentralized \
    --max-calls 1000 \
    --emit-policy
  ```
- **baseline_score ì •ì˜**: ë™ì¼ ë°ì´í„°ì…‹ì— ëŒ€í•´ ë‹¨ì¼ ì—ì´ì „íŠ¸ ì¬ì‹¤í–‰ ê²°ê³¼
- **ìš°ì„ ìˆœìœ„**: Agent Architecture ë„ì… í›„ 1.5 ìŠ¤í”„ë¦°íŠ¸

### Latent Evidence Bus

**ì „ì œ**: ì—ì´ì „íŠ¸ ê°„ hidden state ê³µìœ ê°€ í•„ìš”í•´ì•¼ í•¨

- **ëª©í‘œ**: LatentMAS ìŠ¤íƒ€ì¼ KV cache / hidden state ê³µìœ 
- **API ì œì•½**:
  - OpenAI/Anthropic/Azure API: hidden state ë¯¸ë…¸ì¶œ â†’ **ë¶ˆê°€ëŠ¥**
  - HuggingFace/vLLM ë¡œì»¬ ëª¨ë¸: **ê°€ëŠ¥** (ë³„ë„ ì–´ëŒ‘í„° í•„ìš”)
- **í˜„ì‹¤ì  ë²”ìœ„**:
  - Q1: Anthropic Extended Thinking ìº¡ì²˜ë§Œ (API ê¸°ë°˜)
  - ì´í›„: HuggingFace/vLLM ì§ì ‘ í†µí•© ì—°êµ¬
- **ìš°ì„ ìˆœìœ„**: Agent Architecture + ë¡œì»¬ ëª¨ë¸ ì¸í”„ë¼ í™•ë³´ í›„

### ë¡œë“œë§µ

```
2026 Q1: Domain Memory Layering (í˜„ì¬ ì‹œìŠ¤í…œì— ì ìš©)
2026 Q2: Agent Architecture ì„¤ê³„ ë° í”„ë¡œí† íƒ€ì…
2026 Q3: Coordination Profiler (ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì— ì ìš©)
2026 Q4: Latent Evidence Bus ì—°êµ¬ (ë¡œì»¬ ëª¨ë¸ ê¸°ë°˜)
```

---

## Completed Phases

### Phase 1-3: Core System âœ…

**Status**: Complete (2024-12-24)

| Component | Status | Description |
|-----------|--------|-------------|
| Domain Entities | âœ… | TestCase, Dataset, EvaluationRun, MetricScore |
| Port Interfaces | âœ… | LLMPort, DatasetPort, StoragePort, TrackerPort, EvaluatorPort |
| Data Loaders | âœ… | CSV, Excel, JSON loaders |
| RagasEvaluator | âœ… | Async evaluation with 4 core metrics |
| OpenAI Adapter | âœ… | LangChain integration with token tracking |
| Langfuse Adapter | âœ… | Trace/score logging, SDK v3 support |
| CLI Interface | âœ… | run, metrics, config commands |

---

### Phase 4: Foundation Enhancement âœ…

**Status**: Complete (2024-12-24)

| Task | Description | Status | Files |
|------|-------------|--------|-------|
| TASK-4.3 | FactualCorrectness Metric | âœ… DONE | `evaluator.py`, `settings.py` |
| TASK-4.4 | SemanticSimilarity Metric | âœ… DONE | `evaluator.py`, `settings.py` |
| TASK-4.5a | Azure OpenAI Adapter | âœ… DONE | `src/evalvault/adapters/outbound/llm/azure_adapter.py` |
| TASK-4.5b | Anthropic Claude Adapter | âœ… DONE | `src/evalvault/adapters/outbound/llm/anthropic_adapter.py` |

#### Implemented Features

**New Metrics**:
- `factual_correctness` - ground_truth ëŒ€ë¹„ ì‚¬ì‹¤ì  ì •í™•ì„±
- `semantic_similarity` - ë‹µë³€ê³¼ ground_truth ê°„ ì˜ë¯¸ì  ìœ ì‚¬ë„

---

### Phase 5: Storage & Domain âœ…

**Status**: Complete (2024-12-24)

| Task | Description | Status | Files |
|------|-------------|--------|-------|
| TASK-5.1 | SQLite Storage Adapter | âœ… DONE | `sqlite_adapter.py`, `schema.sql` |
| TASK-5.2 | History CLI Commands | âœ… DONE | `cli.py` (history, compare, export) |
| TASK-5.3 | InsuranceTermAccuracy Metric | âœ… DONE | `src/evalvault/domain/metrics/insurance.py` |
| TASK-5.4 | Basic Testset Generation | âœ… DONE | `testset_generator.py`, `document_chunker.py` |

#### Implemented Features

**SQLite Storage** (`src/evalvault/adapters/outbound/storage/sqlite_adapter.py`):
- `save_run(run)` - í‰ê°€ ê²°ê³¼ ì €ì¥
- `get_run(run_id)` - ë‹¨ì¼ ê²°ê³¼ ì¡°íšŒ
- `list_runs(limit, dataset_name, model_name)` - í•„í„°ë§ëœ ëª©ë¡ ì¡°íšŒ
- `delete_run(run_id)` - ê²°ê³¼ ì‚­ì œ

**CLI Commands**:
- `evalvault history` - í‰ê°€ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
- `evalvault compare <run_id1> <run_id2>` - ë‘ í‰ê°€ ê²°ê³¼ ë¹„êµ
- `evalvault export <run_id> -o <file>` - ê²°ê³¼ JSON ë‚´ë³´ë‚´ê¸°
- `evalvault generate <documents> -n <num>` - í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±

**InsuranceTermAccuracy** (`src/evalvault/domain/metrics/insurance.py`):
- ë³´í—˜ ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ ì •í™•ë„ í‰ê°€
- ìš©ì–´ ì‚¬ì „ ê¸°ë°˜ ë§¤ì¹­ (`terms_dictionary.json`)
- Ragas Metric ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜

**Testset Generation** (`src/evalvault/domain/services/testset_generator.py`):
- `BasicTestsetGenerator` - LLM ì—†ì´ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±
- `DocumentChunker` - ë¬¸ì„œ ì²­í‚¹ ìœ í‹¸ë¦¬í‹°
- factual/reasoning ì§ˆë¬¸ ìœ í˜• ì§€ì›

---

### Phase 6: Advanced Features âœ…

**Status**: Complete (2025-12-24)

| Task | Description | Status | Files |
|------|-------------|--------|-------|
| TASK-6.1 | Knowledge Graph Testset Generation | âœ… DONE | `kg_generator.py`, `entity_extractor.py` |
| TASK-6.2 | Experiment Management System | âœ… DONE | `experiment.py`, `experiment_manager.py` |
| TASK-6.4 | PostgreSQL Storage Adapter | âœ… DONE | `postgres_adapter.py` |
| TASK-6.5 | MLflow Tracker Adapter | âœ… DONE | `mlflow_adapter.py` |
| TASK-6.6 | Azure OpenAI Adapter | âœ… DONE | `azure_adapter.py` |
| TASK-6.7 | Anthropic Claude Adapter | âœ… DONE | `anthropic_adapter.py` |

---

#### Implemented Features

**Knowledge Graph Generator** (`src/evalvault/domain/services/kg_generator.py`):
- `KnowledgeGraph` - ì§€ì‹ ê·¸ë˜í”„ ë°ì´í„° êµ¬ì¡°
- `KnowledgeGraphGenerator` - ë¬¸ì„œ ê¸°ë°˜ ê·¸ë˜í”„ ìƒì„±
- Multi-hop ì§ˆë¬¸ ìƒì„± ì§€ì›
- Entity íƒ€ì…ë³„ ì§ˆë¬¸ ìƒì„±

**Entity Extractor** (`src/evalvault/domain/services/entity_extractor.py`):
- ë³´í—˜ ë„ë©”ì¸ ì—”í‹°í‹° ì¶”ì¶œ (íšŒì‚¬, ìƒí’ˆ, ê¸ˆì•¡, ê¸°ê°„, ë³´ì¥)
- ê´€ê³„ ì¶”ì¶œ (PROVIDES, COVERS, HAS_AMOUNT ë“±)

**Experiment Management** (`src/evalvault/domain/services/experiment_manager.py`):
- `Experiment`, `ExperimentGroup` ì—”í‹°í‹°
- A/B í…ŒìŠ¤íŠ¸ ê·¸ë£¹ ë¹„êµ
- ë©”íŠ¸ë¦­ í†µê³„ ë¶„ì„ ë° ê²°ê³¼ ìš”ì•½

**PostgreSQL Adapter** (`src/evalvault/adapters/outbound/storage/postgres_adapter.py`):
- asyncpg ê¸°ë°˜ ë¹„ë™ê¸° PostgreSQL ì§€ì›
- StoragePort ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜

**MLflow Adapter** (`src/evalvault/adapters/outbound/tracker/mlflow_adapter.py`):
- MLflow ì‹¤í—˜ ì¶”ì  ì—°ë™
- TrackerPort ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜

**Azure OpenAI Adapter** (`src/evalvault/adapters/outbound/llm/azure_adapter.py`):
- Azure OpenAI Service ì—°ë™
- LLMPort ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜

**Anthropic Adapter** (`src/evalvault/adapters/outbound/llm/anthropic_adapter.py`):
- Anthropic Claude API ì—°ë™
- OpenAI embeddings fallback ì§€ì›
- LLMPort ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜

---

### Phase 7: Production Ready âœ…

**Status**: Complete (2025-12-28)

| Task | Description | Status | Files |
|------|-------------|--------|-------|
| TASK-7.1 | Performance Optimization | âœ… DONE | `evaluator.py` (parallel, batch_size) |
| TASK-7.2 | Docker Containerization | âœ… DONE | `Dockerfile`, `docker-compose.yml` |

#### Implemented Features

**Performance Optimization**:
- `--parallel` CLI ì˜µì…˜ìœ¼ë¡œ ë³‘ë ¬ í‰ê°€ í™œì„±í™”
- `--batch-size` ì˜µì…˜ìœ¼ë¡œ ë°°ì¹˜ í¬ê¸° ì¡°ì ˆ
- ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ í‰ê°€ ì„±ëŠ¥ í–¥ìƒ

**Docker Support**:
- Multi-stage buildë¡œ ìµœì í™”ëœ ì´ë¯¸ì§€
- `docker-compose.yml`ë¡œ PostgreSQL + EvalVault ìŠ¤íƒ êµ¬ì„±
- ë¹„root ì‚¬ìš©ìë¡œ ë³´ì•ˆ ê°•í™”

---

## Future Enhancements

> YAGNI ì›ì¹™ì— ë”°ë¼, ì•„ë˜ ê¸°ëŠ¥ì€ ì‹¤ì œ ì‚¬ìš©ì ìš”êµ¬ê°€ ìˆì„ ë•Œ êµ¬í˜„í•©ë‹ˆë‹¤.
> í˜„ì¬ëŠ” CLI + Langfuse/MLflow UI ì¡°í•©ìœ¼ë¡œ ëŒ€ë¶€ë¶„ì˜ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì¶©ì¡±í•©ë‹ˆë‹¤.

| Feature | Description | Status |
|---------|-------------|--------|
| API Server (FastAPI) | HTTP API ë…¸ì¶œ | â¸ï¸ Deferred (Langfuse/MLflow UI í™œìš©) |
| Dashboard Web UI | í‰ê°€ ê²°ê³¼ ì‹œê°í™” | â¸ï¸ Deferred (Langfuse/MLflow UI í™œìš©) |
| Kubernetes Deployment | K8s ë°°í¬ ì§€ì› | â¸ï¸ Deferred (Dockerë¡œ ì¶©ë¶„) |

---

## Supported Metrics (Current)

| Metric | Type | Ground Truth | Embeddings | Status |
|--------|------|--------------|------------|--------|
| `faithfulness` | Ragas | No | No | âœ… |
| `answer_relevancy` | Ragas | No | Yes | âœ… |
| `context_precision` | Ragas | Yes | No | âœ… |
| `context_recall` | Ragas | Yes | No | âœ… |
| `factual_correctness` | Ragas | Yes | No | âœ… |
| `semantic_similarity` | Ragas | Yes | Yes | âœ… |
| `insurance_term_accuracy` | Custom | Yes | No | âœ… |

---

## CLI Commands (Current)

```bash
# Core Commands
evalvault run <dataset> --metrics <metrics> [--langfuse]
evalvault metrics
evalvault config

# History Commands
evalvault history [--limit N] [--dataset NAME] [--model NAME]
evalvault compare <run_id1> <run_id2>
evalvault export <run_id> -o <file>

# Generation Commands
evalvault generate <documents> -n <num> -o <output>
```

---

## Test Summary

| Category | Count | Description |
|----------|-------|-------------|
| Unit Tests | 431 | Domain, ports, adapters, services |
| Integration Tests | 26 | End-to-end flows |
| **Total** | **457** | All passing |

### Test Files
```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_entities.py          # 19 tests
â”‚   â”œâ”€â”€ test_data_loaders.py      # 21 tests
â”‚   â”œâ”€â”€ test_evaluator.py         # 13 tests (including parallel)
â”‚   â”œâ”€â”€ test_langfuse_tracker.py  # 18 tests
â”‚   â”œâ”€â”€ test_openai_adapter.py    # 4 tests
â”‚   â”œâ”€â”€ test_ports.py             # 24 tests
â”‚   â”œâ”€â”€ test_cli.py               # 58 tests
â”‚   â”œâ”€â”€ test_insurance_metric.py  # 18 tests
â”‚   â”œâ”€â”€ test_sqlite_storage.py    # 18 tests
â”‚   â”œâ”€â”€ test_testset_generator.py # 16 tests
â”‚   â”œâ”€â”€ test_kg_generator.py      # 27 tests (Phase 6)
â”‚   â”œâ”€â”€ test_entity_extractor.py  # 20 tests (Phase 6)
â”‚   â”œâ”€â”€ test_experiment.py        # 21 tests (Phase 6)
â”‚   â”œâ”€â”€ test_postgres_storage.py  # 19 tests (Phase 6)
â”‚   â”œâ”€â”€ test_mlflow_tracker.py    # 17 tests (Phase 6)
â”‚   â”œâ”€â”€ test_azure_adapter.py     # 18 tests (Phase 6)
â”‚   â””â”€â”€ test_anthropic_adapter.py # 19 tests (Phase 6)
â””â”€â”€ integration/
    â”œâ”€â”€ test_evaluation_flow.py   # 6 tests
    â”œâ”€â”€ test_data_flow.py         # 8 tests
    â”œâ”€â”€ test_langfuse_flow.py     # 5 tests
    â””â”€â”€ test_storage_flow.py      # 7 tests
```

---

## Version History

| Version | Date | Description |
|---------|------|-------------|
| 0.1.0 | 2024-12-24 | Phase 3 Complete - Core System |
| 0.2.0 | 2024-12-24 | Phase 5 Complete - Storage & Domain |
| 0.3.0 | 2025-12-24 | Phase 6 Complete - Advanced Features |
| 1.0.0 | 2025-12-28 | OSS Release - PyPI ë°°í¬, CI/CD ìë™í™” |

---

## CI/CD & Release

### Cross-Platform CI

| Platform | Python | Status |
|----------|--------|--------|
| Ubuntu | 3.12, 3.13 | âœ… |
| macOS | 3.12 | âœ… |
| Windows | 3.12 | âœ… |

### Automatic Versioning (python-semantic-release)

main ë¸Œëœì¹˜ì— ë¨¸ì§€ë˜ë©´ Conventional Commits ê·œì¹™ì— ë”°ë¼ ìë™ìœ¼ë¡œ ë²„ì „ì´ ê²°ì •ë˜ê³  PyPIì— ë°°í¬ë©ë‹ˆë‹¤:

| Commit Type | Version Bump | Example |
|-------------|--------------|---------|
| `feat:` | Minor (0.x.0) | `feat: Add new metric` |
| `fix:`, `perf:` | Patch (0.0.x) | `fix: Correct calculation` |
| Other | No release | `docs:`, `chore:`, `ci:`, etc. |

### Release Workflow

1. PR ìƒì„± â†’ CI í…ŒìŠ¤íŠ¸ (Ubuntu, macOS, Windows)
2. PR ë¨¸ì§€ â†’ main ë¸Œëœì¹˜ í‘¸ì‹œ
3. Release ì›Œí¬í”Œë¡œìš° ì‹¤í–‰:
   - Conventional Commits ë¶„ì„
   - ë²„ì „ íƒœê·¸ ìƒì„± (ì˜ˆ: v1.0.1)
   - PyPI ë°°í¬
   - GitHub Release ìƒì„±

---

## Architecture

```
src/evalvault/
â”œâ”€â”€ domain/
â”‚   â”œâ”€â”€ entities/         # TestCase, Dataset, EvaluationRun, MetricScore, Experiment
â”‚   â”œâ”€â”€ services/         # RagasEvaluator, TestsetGenerator, KGGenerator, ExperimentManager
â”‚   â””â”€â”€ metrics/          # InsuranceTermAccuracy (custom metrics)
â”œâ”€â”€ ports/
â”‚   â”œâ”€â”€ inbound/          # EvaluatorPort
â”‚   â””â”€â”€ outbound/         # LLMPort, DatasetPort, StoragePort, TrackerPort
â”œâ”€â”€ adapters/
â”‚   â”œâ”€â”€ inbound/          # CLI (Typer)
â”‚   â””â”€â”€ outbound/
â”‚       â”œâ”€â”€ dataset/      # CSV, Excel, JSON loaders
â”‚       â”œâ”€â”€ llm/          # OpenAI, Azure OpenAI, Anthropic adapters
â”‚       â”œâ”€â”€ storage/      # SQLite, PostgreSQL adapters
â”‚       â””â”€â”€ tracker/      # Langfuse, MLflow adapters
â””â”€â”€ config/               # Settings (pydantic-settings)
```

### Port/Adapter Implementation Status

| Port | Adapter | Status |
|------|---------|--------|
| LLMPort | OpenAIAdapter | âœ… Complete |
| LLMPort | AzureOpenAIAdapter | âœ… Complete |
| LLMPort | AnthropicAdapter | âœ… Complete |
| DatasetPort | CSV/Excel/JSON Loaders | âœ… Complete |
| TrackerPort | LangfuseAdapter | âœ… Complete |
| TrackerPort | MLflowAdapter | âœ… Complete |
| StoragePort | SQLiteAdapter | âœ… Complete |
| StoragePort | PostgreSQLAdapter | âœ… Complete |
| EvaluatorPort | RagasEvaluator | âœ… Complete |

---

## Quality Standards (SLA)

### Metric Thresholds

| Metric | Minimum | Target | Excellent |
|--------|---------|--------|-----------|
| Faithfulness | 0.60 | 0.80 | 0.90 |
| Answer Relevancy | 0.65 | 0.80 | 0.90 |
| Context Precision | 0.60 | 0.75 | 0.85 |
| Context Recall | 0.60 | 0.80 | 0.90 |
| Factual Correctness | 0.70 | 0.85 | 0.95 |
| Semantic Similarity | 0.70 | 0.85 | 0.95 |

### System Requirements

- **Throughput**: 100 test cases / 5 minutes
- **Result Storage**: Dual storage (SQLite + Langfuse)
- **Reproducibility**: Deterministic results (temperature=0)

---

## References

- [Ragas Documentation](https://docs.ragas.io/)
- [Langfuse Documentation](https://langfuse.com/docs)
