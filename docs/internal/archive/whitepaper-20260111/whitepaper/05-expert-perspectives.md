## ì œ5ë¶€: ì „ë¬¸ê°€ ê´€ì  í†µí•© ì„¤ê³„

### 5.1 ì¸ì§€ì‹¬ë¦¬í•™ì ê´€ì  (Cognitive Psychologist Perspective)

### 5.1.1 ì¸ì§€ ë¶€í•˜ ìµœì†Œí™” (Minimizing Cognitive Load)

**ì¸ì§€ì‹¬ë¦¬í•™ì  ê·¼ê±°**:
- ì¸ê°„ì˜ ì‘ì—… ê¸°ì–µ ìš©ëŸ‰ì€ ì œí•œì  (7Â±2 ì²­í¬)
- ê³¼ë„í•œ ì •ë³´ëŠ” ì¸ì§€ ë¶€í•˜ ì¦ê°€ â†’ ì˜¤ë¥˜ìœ¨ ì¦ê°€
- ì²­í¬ ë‹¨ìœ„ë¡œ ì •ë³´ë¥¼ ë‚˜ëˆ„ì–´ ì²˜ë¦¬í•˜ë©´ ê¸°ì–µ ë¶€ë‹´ ê°ì†Œ

**EvalVault ì ìš©**:

#### 5.1.1.1 ì ì§„ì  ì •ë³´ ê³µê°œ (Progressive Disclosure)

**ì›ì¹™**: ê¸°ë³¸ ì •ë³´ì—ì„œ ì‹œì‘í•˜ì—¬ í•„ìš”í•  ë•Œë§Œ ìƒì„¸ ì •ë³´ë¥¼ ê³µê°œ

**êµ¬í˜„ ë°©ë²•**:

1. **ìš”ì•½(Summary) â†’ ìƒì„¸(Detail) â†’ ì‹¬í™”(Deep) 3ë‹¨ê³„ êµ¬ì¡°**

```python
# ë°±ì„œ êµ¬ì¡° ì˜ˆì‹œ
## ì œ1ë¶€: í”„ë¡œì íŠ¸ ê°œìš”
### 1.1 ë¹„ì „ê³¼ ë¯¸ì…˜
# [ê¸°ë³¸ ì •ë³´: 3~5ê°œ í•µì‹¬ í¬ì¸íŠ¸]

## ì œ4ë¶€: ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ìƒì„¸
### 4.1 ë„ë©”ì¸ ì—”í‹°í‹°
# [ìƒì„¸ ì •ë³´: ì—”í‹°í‹° ì •ì˜, ë©”ì„œë“œ, ì½”ë“œ ì˜ˆì‹œ]
```

2. **UIì—ì„œì˜ ê³„ì¸µì  ë…¸ì¶œ (Layered Disclosure)**

```python
# Web UI êµ¬í˜„ ì˜ˆì‹œ
class EvaluationStudio:
    """í‰ê°€ ìŠ¤íŠœë””ì˜¤"""

    def __init__(self):
        self._view_state = "summary"  # summary, detail, deep

    def render_summary(self):
        """ìš”ì•½ ë·°: ê¸°ë³¸ ì •ë³´ë§Œ í‘œì‹œ"""
        return {
            "title": "í‰ê°€ ìš”ì•½",
            "widgets": [
                {"type": "pass_rate_card", "show_all": False},
                {"type": "metric_chart", "show_all": False},
            ]
        }

    def render_detail(self):
        """ìƒì„¸ ë·°: ëª¨ë“  ë©”íŠ¸ë¦­ ì •ë³´ í‘œì‹œ"""
        return {
            "title": "í‰ê°€ ìƒì„¸",
            "widgets": [
                {"type": "pass_rate_card", "show_all": True},
                {"type": "metric_chart", "show_all": True},
                {"type": "test_case_table", "show_all": True},
            ]
        }

    def render_deep(self):
        """ì‹¬í™” ë·°: Phoenix ì—°ë™, Stage ë©”íŠ¸ë¦­"""
        return {
            "title": "ì‹¬í™” ë¶„ì„",
            "widgets": [
                {"type": "pass_rate_card", "show_all": True},
                {"type": "metric_chart", "show_all": True},
                {"type": "test_case_table", "show_all": True},
                {"type": "stage_metrics", "show_all": True},
                {"type": "phoenix_link", "show_all": True},
            ]
        }
```

3. **ì•„ì½”ë””ì–¸ ì ‘í˜ (Accordion) íŒ¨í„´**

```html
<!-- ì•„ì½”ë””ì–¸ íŒ¨í„´ìœ¼ë¡œ ì •ë³´ë¥¼ ê·¸ë£¹í™” -->
<details class="accordion-item" data-expanded="false">
  <summary class="accordion-header">
    <span class="icon">ğŸ“Š</span>
    <span class="title">ë©”íŠ¸ë¦­ ìƒì„¸</span>
  </summary>
  <div class="accordion-content">
    <table class="metrics-table">
      <!-- ë©”íŠ¸ë¦­ í…Œì´ë¸” -->
    </table>
  </div>
</details>
```

**ì¸ì§€ íš¨ê³¼**:
- ì‚¬ìš©ìëŠ” ì²˜ìŒì— 3~5ê°œ í•µì‹¬ ì •ë³´ë§Œ ë´„ â†’ ì¸ì§€ ë¶€í•˜ ìµœì†Œí™”
- í•„ìš”í•  ë•Œë§Œ ì•„ì½”ë””ì–¸ì„ í¼ï¿½ì„œ ìƒì„¸ ì •ë³´ í™•ì¸
- ì •ë³´ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ê¸°ì–µ ë¶€ë‹´ ê°ì†Œ

#### 5.1.1.2 ì‹œê°ì  ê·¸ë£¹í•‘ (Visual Grouping)

**ì›ì¹™**: ìœ ì‚¬í•œ íŒ¨í„´ì„ ì‹œê°ì ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ íŒ¨í„´ ì¸ì‹ ì´‰ì§„

**êµ¬í˜„ ë°©ë²•**:

1. **ì„±ê³µ/ì‹¤íŒ¨ ì¼€ì´ìŠ¤ë¥¼ ìƒ‰ìƒìœ¼ë¡œ ì¦‰ì‹œ êµ¬ë¶„**

```css
/* ìƒ‰ìƒ ì¸ì½”ë”© ì²´ê³„ */
.test-case {
    --success-primary: #22c55e;  /* Green 500 */
    --success-hover: #16a34a;   /* Green 600 */
    --success-text: #ffffff;

    --failure-primary: #ef4444;  /* Red 500 */
    --failure-hover: #dc2626;   /* Red 600 */
    --failure-text: #ffffff;

    --warning-primary: #f59e0b;  /* Yellow 400 */
    --warning-hover: #d97706;   /* Yellow 500 */
    --warning-text: #000000;
}

/* ì„±ê³µ ì¼€ì´ìŠ¤ */
.test-case.success {
    border-left: 4px solid var(--success-primary);
    background-color: var(--success-primary);
    color: var(--success-text);
}

/* ì‹¤íŒ¨ ì¼€ì´ìŠ¤ */
.test-case.failure {
    border-left: 4px solid var(--failure-primary);
    background-color: var(--failure-primary);
    color: var(--failure-text);
}
```

2. **ë©”íŠ¸ë¦­ ê·¸ë£¹ì„ ê³µê°„ì ìœ¼ë¡œ ë°°ì¹˜**

```python
# ë©”íŠ¸ë¦­ ê·¸ë£¹ ì˜ˆì‹œ
METRIC_GROUPS = {
    "faithfulness": {
        "name": "ì¶©ì‹¤ë„ (Faithfulness)",
        "description": "ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì— ì–¼ë§ˆë‚˜ ì¶©ì‹¤í•œì§€",
        "icon": "âœ“",
        "color": "blue",
    },
    "answer_relevancy": {
        "name": "ë‹µë³€ ê´€ë ¨ì„± (Answer Relevancy)",
        "description": "ë‹µë³€ì´ ì§ˆë¬¸ì˜ë„ì™€ ì–¼ë§ˆë‚˜ ê´€ë ¨ìˆëŠ”ì§€",
        "icon": "ğŸ’¬",
        "color": "purple",
    },
    "context_precision": {
        "name": "ì»¨í…ìŠ¤íŠ¸ ì •ë°€ë„ (Context Precision)",
        "description": "ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ê°€ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„± ìˆëŠ”ì§€",
        "icon": "ğŸ¯",
        "color": "orange",
    },
}
```

**ì¸ì§€ íš¨ê³¼**:
- ìƒ‰ìƒìœ¼ë¡œ ì„±ê³µ/ì‹¤íŒ¨ë¥¼ ì¦‰ì‹œ ì¸ì§€ â†’ íŒì • ì‹œê°„ ë‹¨ì¶•
- ê·¸ë£¹ë³„ ì•„ì´ì½˜ìœ¼ë¡œ ë©”íŠ¸ë¦­ ìœ í˜• ì‹ë³„ â†’ ì¹´í…Œê³ ë¦¬ ê¸°ì–µ ë¶€ë‹´ ê°ì†Œ
- ì‹œê°ì  ê·¸ë£¹í•‘ìœ¼ë¡œ íŒ¨í„´ ì¸ì‹ ì´‰ì§„

#### 5.1.1.3 ë‹¨ê³„ë³„ ì‹œê°ì  êµ¬ë¶„ (Stage-level Visual Separation)

**ì›ì¹™**: Retrieval â†’ Rerank â†’ Generation ë‹¨ê³„ë¥¼ ì‹œê°ì ìœ¼ë¡œ êµ¬ë¶„

**êµ¬í˜„ ë°©ë²•**:

```css
/* Stageë³„ ìƒ‰ìƒ êµ¬ë¶„ */
.stage-badge {
    /* Input Stage */
    &.input {
        background-color: #9ca3af;  /* Gray */
        color: #ffffff;
        border: 2px solid #6b7280;
    }

    /* Retrieval Stage */
    &.retrieval {
        background-color: #3b82f6;  /* Blue */
        color: #ffffff;
        border: 2px solid #2563eb;
    }

    /* Rerank Stage */
    &.rerank {
        background-color: #f59e0b;  /* Yellow */
        color: #000000;
        border: 2px solid #d97706;
    }

    /* Output Stage */
    &.output {
        background-color: #10b981;  /* Green */
        color: #ffffff;
        border: 2px solid #059669;
    }
}
```

**ì¸ì§€ íš¨ê³¼**:
- ê° ë‹¨ê³„ë¥¼ ìƒ‰ìƒìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ë³‘ëª© ì§€ì ì„ ë¹ ë¥´ê²Œ ì‹ë³„
- ë‹¨ê³„ë³„ ì„±ëŠ¥ì„ í•œëˆˆì— ë¹„êµ ê°€ëŠ¥ â†’ íŒ¨í„´ ì¸ì‹ ì´‰ì§„
- ì‹œê°ì  êµ¬ë¶„ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ íë¦„ ì§ê´€ì  ì´í•´

---

### 5.2 UI/UX ì „ë¬¸ê°€ ê´€ì  (UI/UX Perspective)

### 5.2.1 ì›Œí¬í”Œë¡œìš° ìµœì í™” (Workflow Optimization)

**UI/UX ì›ì¹™**:
- ìì£¼ í•˜ëŠ” ì‘ì—…ì„ ë¹ ë¥´ê²Œ (ìˆ˜ìš©ì ì‹œë‚˜ë¦¬ì˜¤ ìµœì í™”)
- ëª…í™•í•œ ì‚¬ìš©ì ê²½ë¡œ (Clear User Path) ì œê³µ
- ì˜¤ë¥˜ ë°©ì§€ (Error Prevention)ì— ì§‘ì¤‘

**EvalVault ì ìš©**:

#### 5.2.1.1 í‰ê°€ ì‹¤í–‰ ì›Œí¬í”Œë¡œìš° (Evaluation Workflow)

**ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤**:
1. ë°ì´í„°ì…‹ ì—…ë¡œë“œ â†’ 2. ë©”íŠ¸ë¦­ ì„ íƒ â†’ 3. ëª¨ë¸ í”„ë¡œí•„ ì„ íƒ â†’ 4. ê³ ê¸‰ ì„¤ì • â†’ 5. ì‹¤í–‰

**ìµœì í™” ì „ëµ**:

1. **ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸° (Dataset Preview)**

```python
# ë°ì´í„°ì…‹ ì—…ë¡œë“œ ì‹œ ìë™ ê²€ì¦
class DatasetUploader:
    """ë°ì´í„°ì…‹ ì—…ë¡œë”"""

    async def upload(self, file: UploadFile) -> DatasetPreview:
        """ë°ì´í„°ì…‹ ì—…ë¡œë“œ ë° ë¯¸ë¦¬ë³´ê¸°"""
        # 1. íŒŒì¼ í˜•ì‹ ìë™ ê°ì§€
        file_type = detect_file_type(file.filename)

        # 2. íŒŒì¼ íŒŒì‹±
        data = await parse_file(file, file_type)

        # 3. ë°ì´í„° ê²€ì¦
        validation_result = validate_dataset(data)

        if not validation_result.is_valid:
            raise HTTPException(
                status_code=400,
                detail=f"ë°ì´í„°ì…‹ ê²€ì¦ ì‹¤íŒ¨: {validation_result.errors}",
            )

        # 4. ë¯¸ë¦¬ë³´ê¸° ìƒì„±
        preview = DatasetPreview(
            total_cases=len(data.test_cases),
            sample_cases=data.test_cases[:5],  # ì²˜ìŒ 5ê°œ ìƒ˜í”Œ
            columns=list(data.test_cases[0].keys()),
        )

        return preview

# ë¯¸ë¦¬ë³´ê¸° UI í‘œì‹œ
<div class="dataset-preview">
  <h3>ğŸ“‹ ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸°</h3>
  <div class="preview-stats">
    <span class="stat-item">
      <span class="value">150</span>
      <span class="label">ì „ì²´ ì¼€ì´ìŠ¤</span>
    </span>
    <span class="stat-item">
      <span class="value">3</span>
      <span class="label">ì»¬ëŸ¼</span>
    </span>
  </div>
  <div class="sample-table">
    <h4>ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ)</h4>
    <table class="preview-table">
      <!-- ìƒ˜í”Œ ë°ì´í„° -->
    </table>
  </div>
</div>
```

2. **ë¹ ë¥¸ ë©”íŠ¸ë¦­ ì„ íƒ (Quick Metric Selection)**

```html
<!-- ìì£¼ ì“°ëŠ” ë©”íŠ¸ë¦­ ìƒë‹¨ í‘œì‹œ -->
<div class="quick-metrics">
  <h3>ğŸ¯ ìì£¼ ì“°ëŠ” ë©”íŠ¸ë¦­</h3>
  <div class="metric-chips">
    <button class="metric-chip selected" data-metric="faithfulness">
      âœ“ Faithfulness
    </button>
    <button class="metric-chip selected" data-metric="answer_relevancy">
      âœ“ Answer Relevancy
    </button>
    <button class="metric-chip" data-metric="context_precision">
      Context Precision
    </button>
  </div>

  <div class="advanced-metrics">
    <details>
      <summary>ê³ ê¸‰ ë©”íŠ¸ë¦­ ì„¤ì •</summary>
      <div class="advanced-list">
        <label class="metric-checkbox">
          <input type="checkbox" checked>
          Context Recall
        </label>
        <label class="metric-checkbox">
          <input type="checkbox">
          Factual Correctness
        </label>
      </div>
    </details>
  </div>
</div>
```

3. **í•œ í™”ë©´ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥ (Single-page Evaluation)**

```python
# í‰ê°€ ì‹¤í–‰ í˜ì´ì§€ êµ¬ì¡°
class EvaluationStudioPage:
    """í‰ê°€ ìŠ¤íŠœë””ì˜¤ í˜ì´ì§€"""

    def render(self):
        """í‰ê°€ ì‹¤í–‰ í•œ í™”ë©´ ë Œë”ë§"""
        return {
            "title": "í‰ê°€ ì‹¤í–‰",
            "sections": [
                {
                    "id": "dataset",
                    "title": "ğŸ“Š 1. ë°ì´í„°ì…‹ ì„ íƒ",
                    "component": DatasetUploader,
                    "collapsible": False,
                },
                {
                    "id": "metrics",
                    "title": "ğŸ¯ 2. ë©”íŠ¸ë¦­ ì„ íƒ",
                    "component": MetricSelector,
                    "collapsible": False,
                },
                {
                    "id": "model",
                    "title": "ğŸ¤– 3. ëª¨ë¸ ì„ íƒ",
                    "component": ModelProfileSelector,
                    "collapsible": False,
                },
                {
                    "id": "advanced",
                    "title": "âš™ï¸ 4. ê³ ê¸‰ ì„¤ì •",
                    "component": AdvancedSettings,
                    "collapsible": True,  # ê¸°ë³¸ ì ‘í˜
                    "default_expanded": False,
                },
            ],
            "actions": [
                {
                    "type": "primary",
                    "label": "ğŸš€ í‰ê°€ ì‹¤í–‰",
                    "loading_text": "í‰ê°€ ì¤‘...",
                    "success_text": "í‰ê°€ ì™„ë£Œ!",
                },
                {
                    "type": "secondary",
                    "label": "ğŸ’¾ ì €ì¥ í›„ ì‹¤í–‰",
                },
            ],
        }
```

**ì¸ì§€ íš¨ê³¼**:
- ë‹¨ì¼ í™”ë©´ì—ì„œ ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ â†’ í˜ì´ì§€ ì „í™˜ ìµœì†Œí™”
- ì§„í–‰ ìƒíƒœ í•­ìƒ í‘œì‹œ â†’ ì‚¬ìš©ì ë¶ˆì•ˆê° ê°ì†Œ
- ê²€ì¦ëœ ë°ì´í„°ë§Œ ì‹¤í–‰ ê°€ëŠ¥ â†’ ì—ëŸ¬ ë°©ì§€

#### 5.2.1.2 ì¸í„°ë™ì…˜ ë””ìì¸ (Interaction Design)

**UI/UX ì›ì¹™**:
- ëª¨ë“  ì•¡ì…˜ì— ì¦‰ê°ì  í”¼ë“œë°± ì œê³µ
- í˜¸ë²„(Hover)ì™€ í´ë¦­(Click)ìœ¼ë¡œ ë‹¨ê³„ì  ì •ë³´ ê³µê°œ

**EvalVault ì ìš©**:

```html
<!-- í˜¸ë²„: ìƒì„¸ ì •ë³´ ë¯¸ë¦¬ë³´ê¸° -->
<div class="test-case-card" data-test-id="tc-001">
  <div class="card-header">
    <span class="badge success">âœ“ PASS</span>
    <span class="question">ë³´ì¥ê¸ˆì•¡ì€ ì–¼ë§ˆì¸ê°€ìš”?</span>
  </div>

  <div class="card-body">
    <div class="answer">
      <strong>ë‹µë³€:</strong>
      <span>ë³´ì¥ê¸ˆì•¡ì€ 1ì–µì›ì…ë‹ˆë‹¤.</span>
    </div>

    <!-- í˜¸ë²„ ì‹œ ìƒì„¸ ë©”íŠ¸ë¦­ í‘œì‹œ -->
    <div class="hover-metrics">
      <h4>ğŸ“Š ë©”íŠ¸ë¦­ ìƒì„¸</h4>
      <div class="metric-row">
        <span class="metric-name">Faithfulness:</span>
        <span class="metric-score">0.90</span>
        <span class="metric-bar">
          <div class="bar-fill" style="width: 90%"></div>
        </span>
      </div>
      <div class="metric-row">
        <span class="metric-name">Answer Relevancy:</span>
        <span class="metric-score">0.85</span>
        <span class="metric-bar">
          <div class="bar-fill warning" style="width: 85%"></div>
        </span>
      </div>
    </div>
  </div>

  <!-- í´ë¦­ ì‹œ ìƒì„¸ í˜ì´ì§€ë¡œ ì´ë™ -->
  <div class="card-footer">
    <a href="/evaluations/run-abc123/test-cases/tc-001" class="detail-link">
      ìƒì„¸ ë³´ê¸° â†’
    </a>
  </div>
</div>

<style>
.hover-metrics {
  display: none;
  position: absolute;
  z-index: 100;
  background: white;
  border: 1px solid #e5e7eb;
  border-radius: 8px;
  padding: 16px;
  box-shadow: 0 4px 12px rgba(0,0,0,0.1);
}

.test-case-card:hover .hover-metrics {
  display: block;
}

.metric-bar {
  width: 100px;
  height: 8px;
  background: #f3f4f6;
  border-radius: 4px;
  overflow: hidden;
}

.bar-fill {
  height: 100%;
  background: #22c55e;
  transition: width 0.3s ease;
}

.bar-fill.warning {
  background: #f59e0b;
}
</style>
```

**ì¸ì§€ íš¨ê³¼**:
- í˜¸ë²„ë¡œ ë¹ ë¥´ê²Œ ìƒíƒœ í™•ì¸ â†’ ë§ˆìš°ìŠ¤ ì´ë™ ìµœì†Œí™”
- í´ë¦­ìœ¼ë¡œ ìƒì„¸ í˜ì´ì§€ ì´ë™ â†’ ì˜ë„ì  íƒìƒ‰ ê°€ëŠ¥
- ì‹œê°ì  í”¼ë“œë°±ìœ¼ë¡œ ì‚¬ìš©ì í–‰ë™ í™•ì‹ 

---

### 5.3 ì •ë³´ê³µí•™ ì „ë¬¸ê°€ ê´€ì  (Information Engineering Perspective)

### 5.3.1 ì •ë³´ ì•„í‚¤í…ì²˜ (Information Architecture)

**ì •ë³´ê³µí•™ ì›ì¹™**:
- ë…¼ë¦¬ì  ê·¸ë£¹í•‘ê³¼ ê³„ì¸µ êµ¬ì¡° (Logical Grouping & Hierarchical Structure)
- ëª…í™•í•œ ë ˆì´ë¸”ë§ê³¼ ë¶„ë¥˜ (Clear Labeling & Categorization)
- ê²€ìƒ‰ ê°€ëŠ¥í•œ ë©”íƒ€ë°ì´í„° (Searchable Metadata)

**EvalVault ì ìš©**:

#### 5.3.1.1 ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ (Metadata Schema)

```python
# í‰ê°€ ê²°ê³¼ ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ
@dataclass
class EvaluationMetadata:
    """í‰ê°€ ê²°ê³¼ ë©”íƒ€ë°ì´í„°"""

    # ì‹ë³„ì (Identifier)
    run_id: str
    dataset_name: str
    model_name: str

    # ì»¨í…ì¸  (Content)
    dataset_version: str
    metrics_evaluated: list[str]
    test_cases_count: int

    # ì»¨í…ìŠ¤íŠ¸ (Context)
    created_at: datetime.datetime
    updated_at: datetime.datetime

    # êµ¬ì¡° (Structure)
    tags: list[str]
    categories: dict[str, str]

    # ì‹œìŠ¤í…œ (System)
    profile: str
    environment: str
    tracker_type: str | None

# ì‚¬ìš© ì˜ˆì‹œ
metadata = EvaluationMetadata(
    run_id="run-abc123",
    dataset_name="insurance-qa",
    model_name="gpt-4o-mini",
    dataset_version="1.0.0",
    metrics_evaluated=["faithfulness", "answer_relevancy"],
    test_cases_count=150,
    created_at=datetime.now(),
    tags=["insurance", "qa", "prod"],
    categories={"domain": "insurance", "environment": "prod"},
    profile="prod",
    environment="production",
    tracker_type="phoenix",
)
```

#### 5.3.1.2 ì •ë³´ ê³„ì¸µ êµ¬ì¡° (Information Hierarchy)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ì •ë³´ ê³„ì¸µ êµ¬ì¡° (Information Hierarchy)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  [ë ˆë²¨ 1: í”„ë¡œì íŠ¸ (Project)]                                            â”‚
â”‚      â”œâ”€ EvalVault                                                           â”‚
â”‚      â”œâ”€ ê°œë°œì ê°€ì´ë“œ (Developer Guide)                                      â”‚
â”‚      â””â”€ ì‚¬ìš©ì ê°€ì´ë“œ (User Guide)                                        â”‚
â”‚          â†“                                                                    â”‚
â”‚  [ë ˆë²¨ 2: ì¹´í…Œê³ ë¦¬ (Category)]                                         â”‚
â”‚      â”œâ”€ í‰ê°€ (Evaluation)                                                  â”‚
â”‚      â”‚   â”œâ”€ ë°ì´í„°ì…‹ (Dataset)                                              â”‚
â”‚      â”‚   â”œâ”€ ë©”íŠ¸ë¦­ (Metrics)                                                 â”‚
â”‚      â”‚   â”œâ”€ ì‹¤í–‰ (Execution)                                                  â”‚
â”‚      â”‚   â””â”€ ê²°ê³¼ (Results)                                                  â”‚
â”‚      â”œâ”€ ë¶„ì„ (Analysis)                                                     â”‚
â”‚      â”‚   â”œâ”€ í†µê³„ ë¶„ì„ (Statistical Analysis)                                  â”‚
â”‚      â”‚   â”œâ”€ NLP ë¶„ì„ (NLP Analysis)                                          â”‚
â”‚      â”‚   â”œâ”€ ì¸ê³¼ ë¶„ì„ (Causal Analysis)                                      â”‚
â”‚      â”‚   â””â”€ ë¹„êµ ë¶„ì„ (Comparison Analysis)                                    â”‚
â”‚      â”œâ”€ ìš´ì˜ (Operations)                                                    â”‚
â”‚      â”‚   â”œâ”€ ëª¨ë‹ˆí„°ë§ (Monitoring)                                            â”‚
â”‚      â”‚   â””â”€ ë¬¸ì œ í•´ê²° (Troubleshooting)                                    â”‚
â”‚          â†“                                                                    â”‚
â”‚  [ë ˆë²¨ 3: ì„¹ì…˜ (Section)]                                              â”‚
â”‚      â”œâ”€ README.md                                                             â”‚
â”‚      â”œâ”€ ARCHITECTURE.md                                                       â”‚
â”‚      â”œâ”€ USER_GUIDE.md                                                        â”‚
â”‚      â”œâ”€ CHANGELOG.md                                                          â”‚
â”‚      â””â”€ API Reference                                                        â”‚
â”‚          â†“                                                                    â”‚
â”‚  [ë ˆë²¨ 4: ê°œë… (Concept)]                                               â”‚
â”‚      â”œâ”€ RAG (Retrieval-Augmented Generation)                                     â”‚
â”‚      â”œâ”€ í‰ê°€ (Evaluation)                                                     â”‚
â”‚      â”œâ”€ ë©”íŠ¸ë¦­ (Metrics)                                                        â”‚
â”‚      â””â”€ íŠ¸ë ˆì´ì‹± (Tracing)                                                    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5.3.1.3 ê²€ìƒ‰ ê°€ëŠ¥í•œ ë©”íƒ€ë°ì´í„° (Searchable Metadata)

```python
# ê²€ìƒ‰ ë©”íƒ€ë°ì´í„° ìƒì„±
def generate_search_metadata(run: EvaluationRun) -> dict[str, Any]:
    """ê²€ìƒ‰ ê°€ëŠ¥í•œ ë©”íƒ€ë°ì´í„° ìƒì„±"""
    return {
        "id": run.run_id,
        "title": f"{run.dataset_name} - {run.model_name}",
        "content": f"í‰ê°€ ê²°ê³¼: {run.pass_rate:.1%} í†µê³¼ìœ¨",
        "metadata": {
            "dataset": run.dataset_name,
            "model": run.model_name,
            "metrics": ",".join(run.metrics_evaluated),
            "pass_rate": run.pass_rate,
            "tags": ["evaluation", "rag"],
            "created_at": run.created_at.isoformat(),
        },
        "categories": [
            run.dataset_name,
            run.model_name,
        ],
    }

# ê²€ìƒ‰ ì¸ë±ìŠ¤ ìƒì„± (MeiliSearch ë“±)
def index_run(run: EvaluationRun):
    """ê²€ìƒ‰ ì¸ë±ìŠ¤ ìƒì„±"""
    metadata = generate_search_metadata(run)

    # MeiliSearchì— ì¸ë±ì‹±
    index.add_documents([{
        "id": metadata["id"],
        "title": metadata["title"],
        "content": metadata["content"],
        "metadata": metadata["metadata"],
    }])
```

### 5.4 ì•„í‚¤í…íŠ¸ ê´€ì  (Architect Perspective)

### 5.4.1 í™•ì¥ì„± ì„¤ê³„ (Scalability Architecture)

**ì•„í‚¤í…íŠ¸ ì›ì¹™**:
- í¬íŠ¸ ê¸°ë°˜ ì„¤ê³„ë¡œ ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ìš©ì´
- ëª¨ë“ˆí™”(Modularization)ìœ¼ë¡œ ì»´í¬ë„ŒíŠ¸ ì¬ì‚¬ìš©ì„± í–¥ìƒ
- ëŠìŠ¨í•œ ê²°í•©(Loose Coupling)ìœ¼ë¡œ ì‹œìŠ¤í…œ ë¶€í•˜ ë¶„ì‚°

**EvalVault ì ìš©**:

#### 5.4.1.1 í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜ (Plugin Architecture)

```python
# í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ ì¸í„°í˜ì´ìŠ¤
@dataclass
class MetricPlugin:
    """ë©”íŠ¸ë¦­ í”ŒëŸ¬ê·¸ì¸ ì¸í„°í˜ì´ìŠ¤"""
    plugin_id: str
    name: str
    version: str
    description: str
    author: str

    def execute(
        self,
        question: str,
        answer: str,
        contexts: list[str],
        ground_truth: str | None = None,
    ) -> float:
        """ë©”íŠ¸ë¦­ ê³„ì‚°"""
        pass

    def get_metadata(self) -> dict[str, Any]:
        """í”ŒëŸ¬ê·¸ì¸ ë©”íƒ€ë°ì´í„°"""
        return {
            "plugin_id": self.plugin_id,
            "name": self.name,
            "version": self.version,
            "description": self.description,
            "author": self.author,
        }

# ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ í”ŒëŸ¬ê·¸ì¸ êµ¬í˜„
@dataclass
class CustomMetricPlugin(MetricPlugin):
    """ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ í”ŒëŸ¬ê·¸ì¸"""

    plugin_id: "insurance-term-accuracy"
    name: "ë³´í—˜ ìš©ì–´ ì •í™•ë„"
    version: "1.0.0"
    description: "ë³´í—˜ ë„ë©”ì¸ ìš©ì–´ ì •í™•ë„ ê³„ì‚°"
    author: "EvalVault Team"

    def execute(
        self,
        question: str,
        answer: str,
        contexts: list[str],
        ground_truth: str | None = None,
    ) -> float:
        """ë©”íŠ¸ë¦­ ê³„ì‚°"""
        # ë³´í—˜ ìš©ì–´ ì¶”ì¶œ
        terms = extract_insurance_terms(answer)

        # ì»¨í…ìŠ¤íŠ¸ì—ì„œ ìš©ì–´ ê²€ì¦
        grounded_terms = []
        for term in terms:
            if is_term_in_contexts(term, contexts):
                grounded_terms.append(term)

        # ì •í™•ë„ ê³„ì‚°
        if not terms:
            return 1.0  # ìš©ì–´ê°€ ì—†ìœ¼ë©´ ì™„ë²½

        return len(grounded_terms) / len(terms)

    def get_metadata(self) -> dict[str, Any]:
        return super().get_metadata()

# í”ŒëŸ¬ê·¸ì¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
class PluginRegistry:
    """í”ŒëŸ¬ê·¸ì¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬"""

    def __init__(self):
        self._plugins: dict[str, MetricPlugin] = {}
        self._load_plugins()

    def _load_plugins(self):
        """í”ŒëŸ¬ê·¸ì¸ ë¡œë“œ"""
        # ë‚´ì¥ í”ŒëŸ¬ê·¸ì¸ ë“±ë¡
        self.register_plugin(InsuranceTermAccuracy())

        # ì™¸ë¶€ í”ŒëŸ¬ê·¸ì¸ ë¡œë“œ (plugins/ ë””ë ‰í„°ë¦¬)
        import importlib
        for plugin_path in Path("plugins/").glob("*.py"):
            module = importlib.import_module(f"plugins.{plugin_path.stem}")
            plugin_class = getattr(module, "Plugin")
            self.register_plugin(plugin_class())

    def register_plugin(self, plugin: MetricPlugin):
        """í”ŒëŸ¬ê·¸ì¸ ë“±ë¡"""
        self._plugins[plugin.plugin_id] = plugin
        print(f"âœ… í”ŒëŸ¬ê·¸ì¸ ë“±ë¡: {plugin.name} v{plugin.version}")

    def get_plugin(self, plugin_id: str) -> MetricPlugin:
        """í”ŒëŸ¬ê·¸ì¸ ì¡°íšŒ"""
        return self._plugins.get(plugin_id)

    def list_plugins(self) -> list[MetricPlugin]:
        """í”ŒëŸ¬ê·¸ì¸ ëª©ë¡"""
        return list(self._plugins.values())
```

#### 5.4.1.2 ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ (Microservices Architecture)

```python
# ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë¶„ë¦¬
# ê° ì„œë¹„ìŠ¤ë¥¼ ë…ë¦½ì ì¸ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ë¡œ ë¶„ë¦¬í•˜ì—¬ í™•ì¥ì„± í–¥ìƒ

class EvaluationMicroservice:
    """í‰ê°€ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤"""

    def __init__(
        self,
        dataset_service: DatasetService,
        metrics_service: MetricsService,
        storage_service: StorageService,
    ):
        self.dataset_service = dataset_service
        self.metrics_service = metrics_service
        self.storage_service = storage_service

    async def evaluate(
        self,
        request: EvaluationRequest,
    ) -> EvaluationResult:
        """í‰ê°€ ì‹¤í–‰"""
        # 1. ë°ì´í„°ì…‹ ë¡œë“œ
        dataset = await self.dataset_service.load_dataset(request.dataset_id)

        # 2. ë©”íŠ¸ë¦­ ê³„ì‚° (ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥)
        metrics = await asyncio.gather([
            self.metrics_service.calculate_faithfulness(dataset),
            self.metrics_service.calculate_answer_relevancy(dataset),
            self.metrics_service.calculate_context_precision(dataset),
        ])

        # 3. ê²°ê³¼ ì €ì¥
        await self.storage_service.save_result(EvaluationResult(
            run_id=request.run_id,
            metrics=metrics,
        ))

        return EvaluationResult(
            run_id=request.run_id,
            metrics=metrics,
        )

# API Gatewayë¡œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë¼ìš°íŒ…
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
)

@app.post("/api/v1/evaluate")
async def evaluate(request: EvaluationRequest):
    """í‰ê°€ API ì—”ë“œí¬ì¸íŠ¸"""
    microservice = EvaluationMicroservice(
        dataset_service=DatasetService(),
        metrics_service=MetricsService(),
        storage_service=StorageService(),
    )

    result = await microservice.evaluate(request)
    return result
```

---

## ì—…ë°ì´íŠ¸ ì´ë ¥

| ë²„ì „ | ë‚ ì§œ | ë³€ê²½ ì‚¬í•­ | ë‹´ë‹¹ |
|------|------|----------|------|
| 1.0.0 | 2026-01-10 | ì´ˆê¸° ì‘ì„± | EvalVault Team |

## ê´€ë ¨ ì„¹ì…˜

- ì„¹ì…˜ 1: í”„ë¡œì íŠ¸ ê°œìš”
- ì„¹ì…˜ 2: ì•„í‚¤í…ì²˜ ì„¤ê³„
- ì„¹ì…˜ 4: ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ìƒì„¸
- ì„¹ì…˜ 6: êµ¬í˜„ ìƒì„¸
