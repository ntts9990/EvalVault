# Phase 9: Korean RAG Optimization

> **Status**: 9.1 âœ… | 9.2 âœ… | 9.3 âœ… | 9.4 âœ… | 9.5 âœ… **Complete**
> **Priority**: âœ… Complete
> **Goal**: í•œêµ­ì–´ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ì‹¤ì§ˆì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ëŠ” ë„êµ¬ì™€ ê°€ì´ë“œ ì œê³µ
> **ë¬¸ì„œ ë²„ì „**: 4.0.0
> **ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-12-30

---

## ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ê¸°ìˆ  ìŠ¤íƒ ì„ ì •](#ê¸°ìˆ -ìŠ¤íƒ-ì„ ì •)
3. [êµ¬í˜„ ê³„íš](#êµ¬í˜„-ê³„íš)
4. [íš¨ìš© ë¶„ì„](#íš¨ìš©-ë¶„ì„)
5. [EvalVault í†µí•© ì „ëµ](#evalvault-í†µí•©-ì „ëµ)
6. [íƒ€ì„ë¼ì¸ ë° ì„±ê³µ ì§€í‘œ](#íƒ€ì„ë¼ì¸-ë°-ì„±ê³µ-ì§€í‘œ)

---

## ê°œìš”

í•œêµ­ì–´ RAG ìµœì í™” ê¸°ëŠ¥ë“¤ì€ **í•œêµ­ì–´ì˜ êµì°©ì–´ íŠ¹ì„±**ì„ ê³ ë ¤í•˜ì—¬ RAG ì‹œìŠ¤í…œì˜ ê²€ìƒ‰ ë° í‰ê°€ í’ˆì§ˆì„ ì‹¤ì§ˆì ìœ¼ë¡œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

### í•µì‹¬ ë¬¸ì œ

- ê¸°ì¡´ ê³µë°± ê¸°ë°˜ í† í°í™”ëŠ” í•œêµ­ì–´ì— ë¶€ì í•©
- ì¡°ì‚¬/ì–´ë¯¸ ë³€í˜•ìœ¼ë¡œ ì¸í•œ ê²€ìƒ‰ ì‹¤íŒ¨
- ì˜ë¯¸ ë‹¨ìœ„ ì²­í‚¹ ë¶€ì¬ë¡œ ì¸í•œ ì»¨í…ìŠ¤íŠ¸ ì†ì‹¤

### í•´ê²°ì±…

- í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í† í°í™” (Kiwi)
- ì˜ë¯¸ ë‹¨ìœ„ ì²­í‚¹ (ë¬¸ì¥ ê²½ê³„ ì¡´ì¤‘)
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + Dense)

### í•µì‹¬ ê°€ì¹˜ ì¬ì •ì˜

**EvalVaultëŠ” RAG í‰ê°€ ë„êµ¬ì´ì§€, ì‹¤ì œ RAG ì‹œìŠ¤í…œì´ ì•„ë‹™ë‹ˆë‹¤.**
í•˜ì§€ë§Œ í‰ê°€ë¥¼ ìœ„í•´ **í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±**, **ê²°ê³¼ ë¶„ì„**, **íŒ¨í„´ í•™ìŠµ**ì´ í•„ìš”í•˜ë©°, ì´ ê³¼ì •ì—ì„œ í•œêµ­ì–´ ìµœì í™” ê¸°ëŠ¥ë“¤ì´ í•µì‹¬ ì—­í• ì„ í•©ë‹ˆë‹¤.

- âŒ "ê²€ìƒ‰ ê¸°ëŠ¥" (EvalVaultì—ëŠ” ë¶ˆí•„ìš”)
- âœ… **"í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì „ì²˜ë¦¬"** (ëª¨ë“  í…ìŠ¤íŠ¸ ì²˜ë¦¬ì— í™œìš©)
- âœ… **"ì˜ë¯¸ ë‹¨ìœ„ ì²­í‚¹"** (í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± í’ˆì§ˆ í–¥ìƒ)
- âœ… **"ì •í™•í•œ ì—”í‹°í‹°/í‚¤ì›Œë“œ ì¶”ì¶œ"** (KG ìƒì„±, NLP ë¶„ì„ ê°œì„ )

---

## ê¸°ìˆ  ìŠ¤íƒ ì„ ì •

### í˜•íƒœì†Œ ë¶„ì„ê¸° ë¹„êµ

| ë¶„ì„ê¸° | ì–¸ì–´ | ì„¤ì¹˜ ìš©ì´ì„± | ì„±ëŠ¥ | ì„ íƒ |
|--------|------|-------------|------|------|
| **Kiwi** | Pure Python | âœ… pip install | ë¹ ë¦„, ì •í™• | âœ… **ì„ íƒ** |
| Mecab-ko | C++ (Python wrapper) | âŒ ë³„ë„ ì„¤ì¹˜ í•„ìš” | ë§¤ìš° ë¹ ë¦„ | âŒ |
| Komoran | Java | âŒ JVM í•„ìš” | ë³´í†µ | âŒ |
| Okt (KoNLPy) | Java | âŒ JVM í•„ìš” | ë³´í†µ | âŒ |
| soynlp | Pure Python | âœ… pip install | ë¹„ì§€ë„í•™ìŠµ | ğŸ”„ ë³´ì¡° |

**ê²°ì •**: **Kiwi** (kiwipiepy)
- Pure Python, pip installë§Œìœ¼ë¡œ ì„¤ì¹˜
- ë¹ ë¥¸ ì†ë„ (100ë§Œ ë¬¸ì/ì´ˆ)
- ë†’ì€ ì •í™•ë„ (ì„¸ì¢… ì½”í¼ìŠ¤ ê¸°ì¤€ 97%+)
- ì‚¬ìš©ì ì‚¬ì „ ì§€ì›

### í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¹„êµ (2024-2025)

> ì°¸ê³ : [dragonkue/BGE-m3-ko](https://huggingface.co/dragonkue/BGE-m3-ko), [upskyy/bge-m3-korean](https://huggingface.co/upskyy/bge-m3-korean)

| ëª¨ë¸ | ì°¨ì› | Max Tokens | AutoRAG Top-k 1 | íŠ¹ì§• | ì„ íƒ |
|------|------|------------|-----------------|------|------|
| **dragonkue/BGE-m3-ko** | 1024 | 8192 | **0.7456** | í•œêµ­ì–´ SOTA, Apache 2.0 | âœ… **1ìˆœìœ„** |
| upskyy/bge-m3-korean | 1024 | 8192 | 0.5351 | BGE-M3 íŒŒì¸íŠœë‹ | ğŸ”„ 2ìˆœìœ„ |
| BAAI/bge-m3 | 1024 | 8192 | 0.6578 | 100+ ì–¸ì–´, Dense+Sparse+Multi-vec | ğŸ”„ Fallback |
| intfloat/multilingual-e5-large | 1024 | 512 | - | ë‹¤êµ­ì–´, ì•ˆì •ì  | ğŸ”„ ëŒ€ì•ˆ |
| jhgan/ko-sroberta-multitask | 768 | 512 | - | í•œêµ­ì–´ íŠ¹í™”, ì‘ì€ í¬ê¸° | ğŸ”„ ê²½ëŸ‰ |

**ê²°ì •**: **dragonkue/BGE-m3-ko** (1ìˆœìœ„)
- AutoRAG ë²¤ì¹˜ë§ˆí¬ì—ì„œ **+39.4% ì„±ëŠ¥ í–¥ìƒ** (0.7456 vs 0.5351)
- MIRACL ë²¤ì¹˜ë§ˆí¬ cosine_ndcg@10: 0.6833
- 8192 í† í° ì§€ì› (ê¸´ ë¬¸ì„œ ì²˜ë¦¬ ê°€ëŠ¥)
- Apache 2.0 ë¼ì´ì„ ìŠ¤ (ìƒì—…ì  ì‚¬ìš© ê°€ëŠ¥)
- SentenceTransformer í˜¸í™˜

### SPLADE for Korean: íš¨ê³¼ ë¶„ì„

> ì°¸ê³ : [Naver SPLADE GitHub](https://github.com/naver/splade), [Korean SPLADE ì—°êµ¬](https://arxiv.org/html/2511.22263v1)

#### SPLADE í•œêµ­ì–´ ì ìš© ê°€ëŠ¥ì„±

| í•­ëª© | í‰ê°€ | ìƒì„¸ |
|------|------|------|
| **íš¨ê³¼** | âœ… ë†’ìŒ | 2.6ì–µ í•œêµ­ì–´ query-document í˜ì–´ë¡œ ê²€ì¦ë¨ |
| **BM25 ëŒ€ë¹„** | âœ… ìš°ìˆ˜ | ë³µì¡í•œ ì¿¼ë¦¬ì—ì„œ íŠ¹íˆ ì¢‹ì€ ì„±ëŠ¥ |
| **í•µì‹¬ ì¡°ê±´** | âš ï¸ ì–´íœ˜ ì„ íƒ | í•œêµ­ì–´ vocabì´ ì˜ ë§ëŠ” ëª¨ë¸ í•„ìˆ˜ |

#### í•œêµ­ì–´ SPLADE ê¶Œì¥ ë°±ë³¸

```
âœ… ê¶Œì¥ (í•œêµ­ì–´ vocab ìš°ìˆ˜):
- klue/roberta-base
- skt/A.X-Encoder-base
- monologg/koelectra-base-v3

âŒ ë¹„ê¶Œì¥ (vocab ë¶ˆì¼ì¹˜):
- jhu-clsp/mmBERT-base â†’ í•œêµ­ì–´ í‘œí˜„ ë¶•ê´´ (all-zero)
- ì˜ì–´ ì¤‘ì‹¬ ëª¨ë¸ â†’ í† í° ê³¼ë¶„ì ˆí™”
```

#### í•µì‹¬ ì¸ì‚¬ì´íŠ¸

> "Before asking 'Which backbone should I use?', ask 'Can this model's vocabulary properly express the language in my data?'"
> â€” [HuggingFace Blog: Vocabulary in Sparse Retrieval](https://huggingface.co/blog/yjoonjang/vocabulary-is-the-most-important-element-in-splade)

í•œêµ­ì–´ì—ì„œ ì–´íœ˜ê°€ ë§ì§€ ì•ŠëŠ” í† í¬ë‚˜ì´ì €ëŠ”:
- í† í° ê³¼ë¶„ì ˆí™” (ë³´í—˜ â†’ â–ë³´, ##í—˜)
- í¬ê·€ ì„œë¸Œì›Œë“œ ë§¤í•‘
- í¬ì†Œì„± ì••ë ¥ í•˜ì—ì„œ all-zero ì¶œë ¥ í•™ìŠµ

### í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì „ëµ (ê¶Œì¥)

BGE-M3 ëª¨ë¸ì€ **Dense + Sparse + ColBERT**ë¥¼ ë™ì‹œ ì§€ì›í•˜ë¯€ë¡œ, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì´ ìµœì :

```python
from FlagEmbedding import BGEM3FlagModel

model = BGEM3FlagModel('upskyy/bge-m3-korean', use_fp16=True)

# Dense, Sparse, ColBERT ì„ë² ë”© ë™ì‹œ ìƒì„±
embeddings = model.encode(
    sentences,
    return_dense=True,
    return_sparse=True,
    return_colbert_vecs=True
)

# í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ ê³„ì‚°
dense_score = dense_similarity(query_embed, doc_embed)
sparse_score = sparse_dot_product(query_sparse, doc_sparse)  # SPLADE ìŠ¤íƒ€ì¼
colbert_score = colbert_score(query_vecs, doc_vecs)

# ê°€ì¤‘ì¹˜ ì¡°í•© (Reciprocal Rank Fusion)
final_score = rrf(dense_rank, sparse_rank, colbert_rank)
```

#### ê²€ìƒ‰ ëª¨ë“œë³„ íŠ¹ì„±

| ëª¨ë“œ | ì¥ì  | ë‹¨ì  | ë³´í—˜ ë„ë©”ì¸ ì í•©ì„± |
|------|------|------|------------------|
| Dense | ì˜ë¯¸ ìœ ì‚¬ë„ | ì •í™•í•œ ìš©ì–´ ë§¤ì¹­ ì•½í•¨ | ğŸ”„ ë³´í†µ |
| Sparse (SPLADE) | ì •í™•í•œ ìš©ì–´ ë§¤ì¹­ | ì˜ë¯¸ í™•ì¥ í•œê³„ | âœ… ë†’ìŒ (ë³´í—˜ ìš©ì–´) |
| ColBERT | í† í° ë ˆë²¨ ë§¤ì¹­ | ê³„ì‚° ë¹„ìš© | âœ… ë†’ìŒ |
| **Hybrid** | ëª¨ë“  ì¥ì  í†µí•© | ë³µì¡ë„ | âœ…âœ… ìµœì  |

---

## êµ¬í˜„ ê³„íš

### Phase 9.1: Korean NLP Foundation âœ…

> **Status**: Complete
> **ëª©í‘œ**: Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° í†µí•© ë° ê¸°ë³¸ í•œêµ­ì–´ ì²˜ë¦¬ ì¸í”„ë¼

#### êµ¬í˜„ëœ ê¸°ëŠ¥

- âœ… KiwiTokenizer êµ¬í˜„
- âœ… í•œêµ­ì–´ ë¶ˆìš©ì–´ ì‚¬ì „
- âœ… ì‚¬ìš©ì ì‚¬ì „ ì§€ì›

#### íŒŒì¼ êµ¬ì¡°

```
src/evalvault/
â”œâ”€â”€ adapters/outbound/nlp/
â”‚   â””â”€â”€ korean/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ kiwi_tokenizer.py      # Kiwi ê¸°ë°˜ í† í¬ë‚˜ì´ì €
â”‚       â”œâ”€â”€ korean_stopwords.py    # í•œêµ­ì–´ ë¶ˆìš©ì–´ ì‚¬ì „
â”‚       â””â”€â”€ korean_utils.py        # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ ports/outbound/
â”‚   â””â”€â”€ korean_nlp_port.py         # í•œêµ­ì–´ NLP í¬íŠ¸
```

#### KiwiTokenizer ì„¤ê³„

```python
from kiwipiepy import Kiwi

class KiwiTokenizer:
    """Kiwi ê¸°ë°˜ í•œêµ­ì–´ í† í¬ë‚˜ì´ì €.

    í˜•íƒœì†Œ ë¶„ì„ì„ í†µí•´ ì˜ë¯¸ìˆëŠ” í† í°ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        remove_particles: bool = True,      # ì¡°ì‚¬ ì œê±°
        remove_endings: bool = True,        # ì–´ë¯¸ ì œê±°
        use_lemma: bool = True,             # ì›í˜• ì‚¬ìš©
        user_dict_path: str | None = None,  # ì‚¬ìš©ì ì‚¬ì „
    ):
        self.kiwi = Kiwi()
        self.remove_particles = remove_particles
        self.remove_endings = remove_endings
        self.use_lemma = use_lemma

        if user_dict_path:
            self._load_user_dict(user_dict_path)

    def tokenize(self, text: str) -> list[str]:
        """í…ìŠ¤íŠ¸ë¥¼ í˜•íƒœì†Œ ë¶„ì„í•˜ì—¬ í† í° ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
        tokens = []
        for token in self.kiwi.tokenize(text):
            # ì¡°ì‚¬(J*), ì–´ë¯¸(E*), ê¸°í˜¸(S*) ì œì™¸
            if self.remove_particles and token.tag.startswith('J'):
                continue
            if self.remove_endings and token.tag.startswith('E'):
                continue
            if token.tag.startswith('S'):
                continue

            # ì›í˜• ì‚¬ìš© ë˜ëŠ” í‘œë©´í˜• ì‚¬ìš©
            form = token.lemma if self.use_lemma else token.form
            tokens.append(form)

        return tokens

    def extract_nouns(self, text: str) -> list[str]:
        """ëª…ì‚¬ë§Œ ì¶”ì¶œ."""
        nouns = []
        for token in self.kiwi.tokenize(text):
            if token.tag.startswith('N'):  # NNG, NNP, NNB, ...
                nouns.append(token.lemma)
        return nouns

    def extract_keywords(
        self,
        text: str,
        pos_tags: list[str] = ['NNG', 'NNP', 'VV', 'VA']
    ) -> list[str]:
        """í‚¤ì›Œë“œ í’ˆì‚¬ë§Œ ì¶”ì¶œ (ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬)."""
        keywords = []
        for token in self.kiwi.tokenize(text):
            if token.tag in pos_tags:
                keywords.append(token.lemma)
        return keywords
```

---

### Phase 9.2: Korean Keyword Extraction âœ…

> **Status**: Complete
> **ëª©í‘œ**: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œë¡œ NLP ë¶„ì„ í’ˆì§ˆ í–¥ìƒ

#### êµ¬í˜„ëœ ê¸°ëŠ¥

- âœ… NLPAnalysisAdapterì— KiwiTokenizer í†µí•©
- âœ… í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ TF-IDF í‚¤ì›Œë“œ ì¶”ì¶œ
- âœ… í‚¤ì›Œë“œ ì •í™•ë„ í–¥ìƒ (60% â†’ 85%+)

#### ê°œì„  íš¨ê³¼

```
Before (ê³µë°± ê¸°ë°˜):
  í‚¤ì›Œë“œ: ['ë³´í—˜ë£Œê°€', 'ì–¼ë§ˆì¸ê°€ìš”', 'ë¬´ì—‡ì¸ê°€ìš”', 'ê°€ëŠ¥í•©ë‹ˆë‹¤', 'ìˆìŠµë‹ˆë‹¤']

After (í˜•íƒœì†Œ ë¶„ì„):
  í‚¤ì›Œë“œ: ['ë³´í—˜ë£Œ', 'ë³´ì¥', 'ê°€ì…', 'ë³´í—˜', 'ë‚©ì…', 'ì‚¬ë§', 'ë§Œê¸°', 'ì—°ê¸ˆ']
```

---

### Phase 9.3: Korean Chunking & Retrieval âœ…

> **Status**: Complete
> **ëª©í‘œ**: ì˜ë¯¸ ë‹¨ìœ„ ì²­í‚¹ ë° í•œêµ­ì–´ ê²€ìƒ‰ ìµœì í™”

#### êµ¬í˜„ëœ ê¸°ëŠ¥

- âœ… KoreanDocumentChunker (ë¬¸ì¥ ê¸°ë°˜ ì²­í‚¹)
- âœ… KoreanBM25Retriever (í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ BM25)
- âœ… KoreanHybridRetriever (BM25 + Dense)
- âœ… KoreanDenseRetriever (BGE-m3-ko ì§€ì›)

#### KoreanDocumentChunker

```python
class KoreanDocumentChunker:
    """í•œêµ­ì–´ íŠ¹í™” ë¬¸ì„œ ì²­í‚¹.

    í˜•íƒœì†Œ ë¶„ì„ì„ í™œìš©í•˜ì—¬ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ì²­í‚¹í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        tokenizer: KiwiTokenizer,
        chunk_size: int = 500,       # í† í° ìˆ˜ ê¸°ì¤€
        overlap_tokens: int = 50,    # í† í° ì˜¤ë²„ë©
        split_by: str = 'sentence',  # sentence | paragraph
    ):
        self.tokenizer = tokenizer
        self.kiwi = tokenizer.kiwi
        self.chunk_size = chunk_size
        self.overlap_tokens = overlap_tokens
        self.split_by = split_by

    def _split_sentences(self, text: str) -> list[str]:
        """Kiwiì˜ ë¬¸ì¥ ë¶„ë¦¬ ì‚¬ìš©."""
        return [sent.text for sent in self.kiwi.split_into_sents(text)]

    def chunk(self, document: str) -> list[str]:
        """ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¬¸ì„œ ì²­í‚¹."""
        sentences = self._split_sentences(document)

        chunks = []
        current_chunk = []
        current_token_count = 0

        for sentence in sentences:
            sentence_tokens = len(self.tokenizer.tokenize(sentence))

            if current_token_count + sentence_tokens <= self.chunk_size:
                current_chunk.append(sentence)
                current_token_count += sentence_tokens
            else:
                # í˜„ì¬ ì²­í¬ ì €ì¥
                if current_chunk:
                    chunks.append(' '.join(current_chunk))

                # ì˜¤ë²„ë© ì²˜ë¦¬
                overlap_sents = self._get_overlap_sentences(
                    current_chunk, self.overlap_tokens
                )
                current_chunk = overlap_sents + [sentence]
                current_token_count = sum(
                    len(self.tokenizer.tokenize(s)) for s in current_chunk
                )

        if current_chunk:
            chunks.append(' '.join(current_chunk))

        return chunks
```

#### Korean BM25 Retriever

```python
class KoreanBM25Retriever:
    """í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ BM25 ê²€ìƒ‰.

    í•œêµ­ì–´ í…ìŠ¤íŠ¸ì— ìµœì í™”ëœ BM25 ê²€ìƒ‰ì„ ì œê³µí•©ë‹ˆë‹¤.
    """

    def __init__(self, tokenizer: KiwiTokenizer):
        self.tokenizer = tokenizer
        self.bm25 = None
        self.documents = []

    def index(self, documents: list[str]) -> None:
        """ë¬¸ì„œ ì¸ë±ì‹±."""
        from rank_bm25 import BM25Okapi

        self.documents = documents
        tokenized_docs = [
            self.tokenizer.tokenize(doc) for doc in documents
        ]
        self.bm25 = BM25Okapi(tokenized_docs)

    def search(self, query: str, top_k: int = 5) -> list[tuple[str, float]]:
        """ì¿¼ë¦¬ë¡œ ê²€ìƒ‰."""
        tokenized_query = self.tokenizer.tokenize(query)
        scores = self.bm25.get_scores(tokenized_query)

        # ìƒìœ„ kê°œ ë°˜í™˜
        top_indices = scores.argsort()[::-1][:top_k]
        return [
            (self.documents[i], scores[i])
            for i in top_indices
        ]
```

---

### Phase 9.4: Korean RAG Evaluation âœ…

> **Status**: Complete
> **ëª©í‘œ**: í•œêµ­ì–´ íŠ¹ì„±ì„ ë°˜ì˜í•œ í‰ê°€ ë©”íŠ¸ë¦­ ê°œì„ 

#### êµ¬í˜„ëœ ê¸°ëŠ¥

- âœ… KoreanFaithfulnessChecker (í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ Faithfulness ê²€ì¦)
- âœ… ì¡°ì‚¬/ì–´ë¯¸ ë³€í˜• ë¬´ì‹œ ë§¤ì¹­
- âœ… í˜•íƒœì†Œ ê¸°ë°˜ í† í° ì˜¤ë²„ë© ê³„ì‚°

#### KoreanFaithfulnessChecker

```python
class KoreanFaithfulnessChecker:
    """í•œêµ­ì–´ Faithfulness ê²€ì¦ ë„êµ¬.

    í˜•íƒœì†Œ ë¶„ì„ì„ í†µí•´ ì¡°ì‚¬/ì–´ë¯¸ ë³€í˜•ì„ ë¬´ì‹œí•˜ê³ 
    ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì— ì¶©ì‹¤í•œì§€ ê²€ì¦í•©ë‹ˆë‹¤.
    """

    def __init__(self, tokenizer: KiwiTokenizer):
        self.tokenizer = tokenizer

    def check_faithfulness(
        self,
        answer: str,
        contexts: list[str]
    ) -> dict[str, float]:
        """ë‹µë³€ì˜ ì»¨í…ìŠ¤íŠ¸ ì¶©ì‹¤ë„ ê²€ì¦."""
        # í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í† í°í™”
        answer_tokens = set(self.tokenizer.tokenize(answer))
        context_tokens = set()
        for ctx in contexts:
            context_tokens.update(self.tokenizer.tokenize(ctx))

        # í† í° ì˜¤ë²„ë© ê³„ì‚°
        overlap = len(answer_tokens & context_tokens)
        coverage = overlap / len(answer_tokens) if answer_tokens else 0

        return {
            "token_overlap": coverage,
            "is_faithful": coverage >= 0.5,
            "matched_tokens": list(answer_tokens & context_tokens),
        }
```

---

### Phase 9.5: Benchmarks & Guidelines âœ…

> **Status**: Complete
> **ëª©í‘œ**: í•œêµ­ì–´ RAG ìµœì í™” íš¨ê³¼ ì¸¡ì • ë° ê°€ì´ë“œ ë¬¸ì„œí™”

#### êµ¬í˜„ëœ ê¸°ëŠ¥

- âœ… KoreanRAGBenchmarkRunner (ë²¤ì¹˜ë§ˆí¬ ëŸ¬ë„ˆ)
- âœ… ë‹¤ì¤‘ í”„ë ˆì„ì›Œí¬ í˜¸í™˜ ê²°ê³¼ í˜•ì‹ (MTEB, lm-harness, DeepEval)
- âœ… pytest í†µí•© í…ŒìŠ¤íŠ¸ (24ê°œ í…ŒìŠ¤íŠ¸)
- âœ… ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ê°€ì´ë“œ ë¬¸ì„œ

#### íŒŒì¼ êµ¬ì¡°

```
src/evalvault/domain/
â”œâ”€â”€ entities/
â”‚   â””â”€â”€ benchmark.py          # RAGTestCase, BenchmarkResult, BenchmarkSuite
â””â”€â”€ services/
    â””â”€â”€ benchmark_runner.py   # KoreanRAGBenchmarkRunner

examples/benchmarks/
â”œâ”€â”€ run_korean_benchmark.py   # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ README.md                 # ë²¤ì¹˜ë§ˆí¬ ê°€ì´ë“œ
â””â”€â”€ korean_rag/
    â”œâ”€â”€ insurance_qa_100.json
    â”œâ”€â”€ faithfulness_test.json
    â”œâ”€â”€ keyword_extraction_test.json
    â””â”€â”€ retrieval_test.json

tests/unit/
â””â”€â”€ test_benchmark_runner.py  # 24ê°œ í…ŒìŠ¤íŠ¸
```

#### ì§€ì› ë²¤ì¹˜ë§ˆí¬ í¬ë§·

| Format | Description | ì§€ì› |
|--------|-------------|------|
| **MTEB** | Massive Text Embedding Benchmark | âœ… |
| **lm-evaluation-harness** | EleutherAI LLM í‰ê°€ | âœ… |
| **DeepEval** | RAG í‰ê°€ í”„ë ˆì„ì›Œí¬ | âœ… |
| **Leaderboard** | ìì²´ ë¦¬ë”ë³´ë“œ | âœ… |

#### ì‹¤í–‰ ë°©ë²•

```bash
# ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
uv run python examples/benchmarks/run_korean_benchmark.py

# ê¸°ì¤€ì„  ë¹„êµ (í˜•íƒœì†Œ ë¶„ì„ vs ê³µë°± ê¸°ë°˜)
uv run python examples/benchmarks/run_korean_benchmark.py --compare
```

ìì„¸í•œ ì‚¬ìš©ë²•ì€ [examples/benchmarks/README.md](../examples/benchmarks/README.md) ì°¸ì¡°.

---

## íš¨ìš© ë¶„ì„

### 1. KoreanBM25Retriever (í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ BM25)

#### í•´ê²°í•˜ëŠ” ë¬¸ì œ

**ë¬¸ì œ 1: ê³µë°± ê¸°ë°˜ í† í°í™”ì˜ í•œê³„**

```
[ê¸°ì¡´ ë°©ì‹ - ê³µë°± ê¸°ë°˜]
ì§ˆë¬¸: "ë³´í—˜ë£Œê°€ ì–¼ë§ˆì¸ê°€ìš”?"
í† í°í™”: ["ë³´í—˜ë£Œê°€", "ì–¼ë§ˆì¸ê°€ìš”?"]
ê²€ìƒ‰ ì‹¤íŒ¨: ë¬¸ì„œì— "ë³´í—˜ë£ŒëŠ”" ë˜ëŠ” "ë³´í—˜ë£Œë¥¼"ë¡œë§Œ ì¡´ì¬

[í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜]
ì§ˆë¬¸: "ë³´í—˜ë£Œê°€ ì–¼ë§ˆì¸ê°€ìš”?"
í˜•íƒœì†Œ ë¶„ì„: ["ë³´í—˜ë£Œ", "ì–¼ë§ˆ", "ì¸ê°€ìš”"] (ì¡°ì‚¬/ì–´ë¯¸ ì œê±°)
ê²€ìƒ‰ ì„±ê³µ: "ë³´í—˜ë£ŒëŠ”", "ë³´í—˜ë£Œë¥¼", "ë³´í—˜ë£Œê°€" ëª¨ë‘ ë§¤ì¹­
```

**ë¬¸ì œ 2: ì¡°ì‚¬/ì–´ë¯¸ ë³€í˜• ë¬´ì‹œ**

í•œêµ­ì–´ëŠ” êµì°©ì–´ íŠ¹ì„±ìƒ ë™ì¼í•œ ì˜ë¯¸ë¼ë„ ì¡°ì‚¬/ì–´ë¯¸ê°€ ë‹¬ë¼ì§‘ë‹ˆë‹¤:

```
ë™ì¼í•œ ì˜ë¯¸, ë‹¤ë¥¸ í‘œë©´í˜•:
- "ë³´í—˜ë£Œê°€ ì¸ìƒë˜ì—ˆìŠµë‹ˆë‹¤"
- "ë³´í—˜ë£Œë¥¼ ë‚©ì…í•©ë‹ˆë‹¤"
- "ë³´í—˜ë£ŒëŠ” 30ë§Œì›ì…ë‹ˆë‹¤"

â†’ í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ "ë³´í—˜ë£Œ"ë§Œ ì¶”ì¶œí•˜ì—¬ ëª¨ë‘ ë§¤ì¹­
```

#### ì œê³µí•˜ëŠ” íš¨ìš©

- âœ… **ê²€ìƒ‰ Recall í–¥ìƒ**: ì¡°ì‚¬/ì–´ë¯¸ ë³€í˜• ë¬´ì‹œí•˜ì—¬ +15-20% ê°œì„ 
- âœ… **ì •í™•í•œ ìš©ì–´ ë§¤ì¹­**: í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ í•µì‹¬ ì˜ë¯¸ë§Œ ì¶”ì¶œ
- âœ… **ë„ë©”ì¸ íŠ¹í™”**: ì‚¬ìš©ì ì‚¬ì „ìœ¼ë¡œ ë³´í—˜ ìš©ì–´ ì •í™•ë„ í–¥ìƒ

---

### 2. KoreanDocumentChunker (ë¬¸ì¥ ê¸°ë°˜ ì²­í‚¹)

#### í•´ê²°í•˜ëŠ” ë¬¸ì œ

**ë¬¸ì œ 1: ë¬¸ì ê¸°ë°˜ ì²­í‚¹ì˜ ì˜ë¯¸ ë‹¨ìœ„ ë¬´ì‹œ**

```
[ê¸°ì¡´ ë°©ì‹ - ë¬¸ì ê¸°ë°˜]
ë¬¸ì„œ: "ë³´í—˜ë£Œ ë‚©ì… ê¸°ê°„ì€ 20ë…„ì…ë‹ˆë‹¤. ë³´í—˜ë£ŒëŠ” ë§¤ì›” ë‚©ì…í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤."
ì²­í¬ í¬ê¸°: 30ì

ì²­í¬ 1: "ë³´í—˜ë£Œ ë‚©ì… ê¸°ê°„ì€ 20ë…„ì…ë‹ˆë‹¤. ë³´í—˜ë£ŒëŠ” ë§¤ì›” ë‚©ì…í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤." (30ì ì´ˆê³¼)
â†’ ì¤‘ê°„ì— ì˜ë¦¼: "ë³´í—˜ë£Œ ë‚©ì… ê¸°ê°„ì€ 20ë…„ì…ë‹ˆë‹¤. ë³´í—˜ë£ŒëŠ” ë§¤ì›” ë‚©ì…í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤"
â†’ ì˜ë¯¸ ì†ì‹¤: ë¬¸ì¥ì´ ì¤‘ê°„ì— ëŠê¹€

[ë¬¸ì¥ ê¸°ë°˜ ì²­í‚¹]
ë¬¸ì„œ: "ë³´í—˜ë£Œ ë‚©ì… ê¸°ê°„ì€ 20ë…„ì…ë‹ˆë‹¤. ë³´í—˜ë£ŒëŠ” ë§¤ì›” ë‚©ì…í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤."
ë¬¸ì¥ ë¶„ë¦¬: ["ë³´í—˜ë£Œ ë‚©ì… ê¸°ê°„ì€ 20ë…„ì…ë‹ˆë‹¤.", "ë³´í—˜ë£ŒëŠ” ë§¤ì›” ë‚©ì…í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤."]

ì²­í¬ 1: "ë³´í—˜ë£Œ ë‚©ì… ê¸°ê°„ì€ 20ë…„ì…ë‹ˆë‹¤." (ì™„ì „í•œ ë¬¸ì¥)
ì²­í¬ 2: "ë³´í—˜ë£ŒëŠ” ë§¤ì›” ë‚©ì…í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤." (ì™„ì „í•œ ë¬¸ì¥)
â†’ ì˜ë¯¸ ë³´ì¡´: ê° ì²­í¬ê°€ ì™„ì „í•œ ë¬¸ì¥ ë‹¨ìœ„
```

**ë¬¸ì œ 2: í† í° ìˆ˜ ê¸°ì¤€ ë¶€ì¬**

í•œêµ­ì–´ëŠ” ê³µë°±ì´ ì ì–´ ë¬¸ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œëŠ” í† í° ìˆ˜ë¥¼ ì •í™•íˆ ì˜ˆì¸¡í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤:

```
[ë¬¸ì ìˆ˜ ê¸°ì¤€]
"ë³´í—˜ë£Œ ë‚©ì… ê¸°ê°„ì€ 20ë…„ì…ë‹ˆë‹¤" (15ì)
â†’ ì‹¤ì œ í† í° ìˆ˜: 6ê°œ (ë³´í—˜ë£Œ, ë‚©ì…, ê¸°ê°„, 20ë…„, ì…ë‹ˆë‹¤)

[í† í° ìˆ˜ ê¸°ì¤€]
ì²­í¬ í¬ê¸°: 500 í† í°
â†’ ì •í™•í•œ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ì²­í‚¹ ê°€ëŠ¥
```

#### ì œê³µí•˜ëŠ” íš¨ìš©

- âœ… **ì»¨í…ìŠ¤íŠ¸ ë¬´ê²°ì„± ë³´ì¥**: ì™„ì „í•œ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì²­í‚¹
- âœ… **í† í° ìˆ˜ ê¸°ë°˜ ì •í™•í•œ ì²­í‚¹**: LLM í† í° ì œí•œ ì¤€ìˆ˜
- âœ… **ì˜¤ë²„ë© ì²˜ë¦¬ë¡œ ê²½ê³„ ì •ë³´ ë³´ì¡´**: ì²­í¬ ê²½ê³„ì—ì„œ ì •ë³´ ì†ì‹¤ ë°©ì§€

---

### 3. KoreanHybridRetriever (BM25 + Dense)

#### í•´ê²°í•˜ëŠ” ë¬¸ì œ

**ë¬¸ì œ 1: BM25ë§Œìœ¼ë¡œëŠ” ì˜ë¯¸ ìœ ì‚¬ë„ ë¶€ì¡±**

```
[BM25ì˜ í•œê³„]
ì§ˆë¬¸: "ë³´í—˜ë£Œë¥¼ ë‚´ì§€ ì•Šìœ¼ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
ë¬¸ì„œ 1: "ë³´í—˜ë£Œ ë¯¸ë‚© ì‹œ ê³„ì•½ì´ í•´ì§€ë©ë‹ˆë‹¤" (ì •í™•í•œ ë‹µë³€)
ë¬¸ì„œ 2: "ë³´í—˜ë£Œ ë‚©ì… ê¸°ê°„ì€ 20ë…„ì…ë‹ˆë‹¤" (ê´€ë ¨ ìˆì§€ë§Œ ì§ì ‘ ë‹µë³€ ì•„ë‹˜)

BM25 ì ìˆ˜:
- ë¬¸ì„œ 1: ë‚®ìŒ (í† í° ê²¹ì¹¨ ì ìŒ: "ë³´í—˜ë£Œ", "ë‚©ì…" vs "ë¯¸ë‚©", "í•´ì§€")
- ë¬¸ì„œ 2: ë†’ìŒ (í† í° ê²¹ì¹¨ ë§ìŒ: "ë³´í—˜ë£Œ", "ë‚©ì…")

â†’ ì˜ëª»ëœ ë¬¸ì„œê°€ ìƒìœ„ì— ë­í‚¹ë¨
```

**ë¬¸ì œ 2: Denseë§Œìœ¼ë¡œëŠ” ì •í™•í•œ ìš©ì–´ ë§¤ì¹­ ë¶€ì¡±**

```
[Denseì˜ í•œê³„]
ì§ˆë¬¸: "ì‚¬ë§ë³´í—˜ê¸ˆì€ ì–¼ë§ˆì¸ê°€ìš”?"
ë¬¸ì„œ 1: "ì‚¬ë§ë³´í—˜ê¸ˆì€ 1ì–µì›ì…ë‹ˆë‹¤" (ì •í™•í•œ ë‹µë³€)
ë¬¸ì„œ 2: "ì¬í•´ì‚¬ë§ë³´í—˜ê¸ˆì€ 2ì–µì›ì…ë‹ˆë‹¤" (ê´€ë ¨ ìˆì§€ë§Œ ë‹¤ë¥¸ ë³´í—˜ê¸ˆ)

Dense ìœ ì‚¬ë„:
- ë¬¸ì„œ 1: ë†’ìŒ (ì˜ë¯¸ ìœ ì‚¬)
- ë¬¸ì„œ 2: ë†’ìŒ (ì˜ë¯¸ ìœ ì‚¬, "ì‚¬ë§ë³´í—˜ê¸ˆ"ê³¼ "ì¬í•´ì‚¬ë§ë³´í—˜ê¸ˆ" ìœ ì‚¬)

â†’ ì •í™•í•œ ìš©ì–´ ë§¤ì¹­ì´ ì–´ë ¤ì›€
```

#### ì œê³µí•˜ëŠ” íš¨ìš©

- âœ… **BM25 + Dense í•˜ì´ë¸Œë¦¬ë“œ**: ì •í™•í•œ ìš©ì–´ ë§¤ì¹­ + ì˜ë¯¸ ìœ ì‚¬ë„
- âœ… **Reciprocal Rank Fusion (RRF)**: ë‘ ë°©ë²•ì˜ ì¥ì  í†µí•©
- âœ… **ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ**: Recall@5 +15-20% ê°œì„  ì˜ˆìƒ

---

## EvalVault í†µí•© ì „ëµ

### í†µí•© ì „ëµ: ì„ ìˆœí™˜ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              í•œêµ­ì–´ ìµœì í™” ê¸°ëŠ¥ (Phase 9)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ KiwiTokenizerâ”‚  â”‚KoreanChunker â”‚  â”‚í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜â”‚    â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚ì—”í‹°í‹° ì¶”ì¶œ     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                 â”‚                 â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                 â”‚
          â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EvalVault í•µì‹¬ ê¸°ëŠ¥ë“¤                           â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±  â”‚  â”‚  NLP Analysis â”‚  â”‚  KG ìƒì„±     â”‚   â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚   â”‚
â”‚  â”‚ âœ… ë” ë‚˜ì€    â”‚  â”‚ âœ… ë” ì •í™•í•œ  â”‚  â”‚ âœ… ë” ì •í™•í•œ  â”‚   â”‚
â”‚  â”‚    ì²­í‚¹      â”‚  â”‚    í‚¤ì›Œë“œ     â”‚  â”‚    ì—”í‹°í‹°     â”‚   â”‚
â”‚  â”‚ âœ… ì˜ë¯¸ ë³´ì¡´  â”‚  â”‚ âœ… ì§ˆë¬¸ ë¶„ë¥˜   â”‚  â”‚ âœ… ê´€ê³„ ì¶”ì¶œ   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                 â”‚                 â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                           â”‚                               â”‚
â”‚                           â–¼                               â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â”‚   í‰ê°€ ì‹¤í–‰ ë° ë¶„ì„   â”‚                    â”‚
â”‚              â”‚   (RagasEvaluator)   â”‚                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                           â”‚                               â”‚
â”‚                           â–¼                               â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â”‚   Domain Memory      â”‚                    â”‚
â”‚              â”‚   (íŒ¨í„´ í•™ìŠµ)         â”‚                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                           â”‚                               â”‚
â”‚                           â–¼                               â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â”‚   ë‹¤ìŒ í‰ê°€ì— ë°˜ì˜    â”‚                    â”‚
â”‚              â”‚   (ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ì…‹)  â”‚                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í†µí•© í¬ì¸íŠ¸ 1: í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±

#### ë°©ì•ˆ: KoreanDocumentChunker í†µí•©

```python
# src/evalvault/domain/services/testset_generator.py

class BasicTestsetGenerator:
    def __init__(
        self,
        use_korean_chunker: bool = False,
        korean_tokenizer: KiwiTokenizer | None = None,
    ):
        self.use_korean_chunker = use_korean_chunker
        self.korean_tokenizer = korean_tokenizer

    def _chunk_documents(
        self,
        documents: list[str],
        config: GenerationConfig
    ) -> list[str]:
        """ë¬¸ì„œ ì²­í‚¹ (í•œêµ­ì–´ ìµœì í™” ì˜µì…˜ í¬í•¨)."""
        if self.use_korean_chunker and self.korean_tokenizer:
            # í•œêµ­ì–´ ìµœì í™” ì²­í‚¹
            chunker = KoreanDocumentChunker(
                tokenizer=self.korean_tokenizer,
                chunk_size=config.chunk_size,  # í† í° ìˆ˜ ê¸°ì¤€
                overlap_tokens=config.chunk_overlap,
            )
            all_chunks = []
            for doc in documents:
                chunks = chunker.chunk(doc)
                all_chunks.extend([c.text for c in chunks])
            return all_chunks
        else:
            # ê¸°ì¡´ ë°©ì‹ (í•˜ìœ„ í˜¸í™˜)
            chunker = DocumentChunker(
                chunk_size=config.chunk_size,
                overlap=config.chunk_overlap,
            )
            all_chunks = []
            for doc in documents:
                chunks = chunker.chunk(doc)
                all_chunks.extend(chunks)
            return all_chunks
```

**íš¨ê³¼:**
- âœ… ì™„ì „í•œ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì²­í‚¹ â†’ ë” ë‚˜ì€ ì»¨í…ìŠ¤íŠ¸
- âœ… í† í° ìˆ˜ ê¸°ì¤€ ì •í™•í•œ ì²­í‚¹ â†’ LLM í† í° ì œí•œ ì¤€ìˆ˜
- âœ… ì˜ë¯¸ ë¬´ê²°ì„± ë³´ì¥ â†’ ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

### í†µí•© í¬ì¸íŠ¸ 2: NLP Analysis

#### ë°©ì•ˆ: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ

```python
# src/evalvault/adapters/outbound/analysis/nlp_adapter.py

class NLPAnalysisAdapter:
    def __init__(
        self,
        llm: LLMPort | None = None,
        korean_tokenizer: KiwiTokenizer | None = None,  # ì¶”ê°€
    ):
        self._llm_adapter = llm
        self.korean_tokenizer = korean_tokenizer

    def _extract_keywords_tfidf(
        self,
        documents: list[str],
        top_k: int
    ) -> list[KeywordInfo]:
        """TF-IDF ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ (í•œêµ­ì–´ ìµœì í™” ì˜µì…˜)."""
        if self.korean_tokenizer:
            # í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
            tokenized_docs = [
                ' '.join(self.korean_tokenizer.extract_keywords(doc))
                for doc in documents
            ]
        else:
            # ê¸°ì¡´ ë°©ì‹ (ê³µë°± ê¸°ë°˜)
            tokenized_docs = documents

        vectorizer = TfidfVectorizer(max_features=100)
        tfidf_matrix = vectorizer.fit_transform(tokenized_docs)
        # ... ë‚˜ë¨¸ì§€ ë¡œì§
```

**íš¨ê³¼:**
- âœ… ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë§Œ ì¶”ì¶œ: "ë³´í—˜ë£Œ", "ë³´ì¥", "ê°€ì…" (ì¡°ì‚¬/ì–´ë¯¸ ì œê±°)
- âœ… í‚¤ì›Œë“œ ì •í™•ë„ 60% â†’ 85%+ í–¥ìƒ
- âœ… ë” ì •í™•í•œ ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜

### í†µí•© í¬ì¸íŠ¸ 3: Knowledge Graph ìƒì„±

#### ë°©ì•ˆ: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œ

```python
# src/evalvault/domain/services/entity_extractor.py

class EntityExtractor:
    def __init__(
        self,
        korean_tokenizer: KiwiTokenizer | None = None,
    ):
        self.korean_tokenizer = korean_tokenizer
        # ê¸°ì¡´ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜)
        self._org_pattern = re.compile("|".join(self.ORGANIZATION_PATTERNS))
        # ...

    def extract_entities(self, text: str) -> list[Entity]:
        """ì—”í‹°í‹° ì¶”ì¶œ (í˜•íƒœì†Œ ë¶„ì„ ë³´ê°•)."""
        entities = []

        # 1. ê¸°ì¡´ ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ ì¶”ì¶œ
        entities.extend(self._extract_by_regex(text))

        # 2. í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ë³´ê°• (í•œêµ­ì–´ì¸ ê²½ìš°)
        if self.korean_tokenizer:
            entities.extend(self._extract_by_morphology(text))

        return self._deduplicate_entities(entities)

    def _extract_by_morphology(self, text: str) -> list[Entity]:
        """í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œ."""
        entities = []

        # ëª…ì‚¬ ì¶”ì¶œ
        nouns = self.korean_tokenizer.extract_nouns(text)

        # ë³´í—˜ ë„ë©”ì¸ íŒ¨í„´ ë§¤ì¹­
        for noun in nouns:
            if self._is_insurance_product(noun):
                entities.append(Entity(
                    name=noun,
                    entity_type="product",
                    confidence=0.9,
                    provenance="morphology"
                ))
            elif self._is_organization(noun):
                entities.append(Entity(
                    name=noun,
                    entity_type="organization",
                    confidence=0.95,
                    provenance="morphology"
                ))

        return entities
```

**íš¨ê³¼:**
- âœ… ì¡°ì‚¬/ì–´ë¯¸ ì œê±° í›„ ì—”í‹°í‹° ì¶”ì¶œ: "ë³´í—˜ë£Œê°€" â†’ "ë³´í—˜ë£Œ"
- âœ… ë³µí•©ëª…ì‚¬ ì •í™• ë¶„í•´: "ì¬í•´ì‚¬ë§ë³´í—˜ê¸ˆ" â†’ ["ì¬í•´", "ì‚¬ë§", "ë³´í—˜ê¸ˆ"]
- âœ… ë” ì •í™•í•œ KG â†’ ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±

### í†µí•© í¬ì¸íŠ¸ 4: Domain Memory

#### ë°©ì•ˆ: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì‚¬ì‹¤ ì •ê·œí™”

```python
# src/evalvault/domain/services/domain_learning_hook.py

class DomainLearningHook:
    def __init__(
        self,
        memory_port: DomainMemoryPort,
        korean_tokenizer: KiwiTokenizer | None = None,
    ):
        self.memory_port = memory_port
        self.korean_tokenizer = korean_tokenizer

    def extract_and_save_facts(
        self,
        run: EvaluationRun,
    ) -> int:
        """ì‚¬ì‹¤ ì¶”ì¶œ ë° ì €ì¥ (í˜•íƒœì†Œ ë¶„ì„ ì •ê·œí™”)."""
        facts = []

        for result in run.results:
            if result.faithfulness_score and result.faithfulness_score >= 0.7:
                # ë‹µë³€ì—ì„œ ì‚¬ì‹¤ ì¶”ì¶œ
                claims = self._extract_claims(result.answer)

                for claim in claims:
                    # í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ ì •ê·œí™”
                    if self.korean_tokenizer:
                        normalized = self._normalize_claim(claim)
                    else:
                        normalized = claim

                    fact = FactualFact(
                        subject=normalized.subject,
                        predicate=normalized.predicate,
                        object=normalized.object,
                        # ...
                    )
                    facts.append(fact)

        # ì¤‘ë³µ ì œê±° (ì •ê·œí™”ëœ ì‚¬ì‹¤ ê¸°ì¤€)
        return self.memory_port.save_facts(facts)

    def _normalize_claim(self, claim: str) -> str:
        """í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ ì‚¬ì‹¤ ì •ê·œí™”."""
        # "ë³´í—˜ë£ŒëŠ” 30ë§Œì›ì…ë‹ˆë‹¤" â†’ "ë³´í—˜ë£Œ 30ë§Œì›"
        tokens = self.korean_tokenizer.extract_keywords(claim)
        return ' '.join(tokens)
```

**íš¨ê³¼:**
- âœ… ì¤‘ë³µ ì‚¬ì‹¤ ì œê±°: "ë³´í—˜ë£ŒëŠ”", "ë³´í—˜ë£Œë¥¼", "ë³´í—˜ë£Œê°€" â†’ "ë³´í—˜ë£Œ"
- âœ… ë” ì •í™•í•œ íŒ¨í„´ í•™ìŠµ
- âœ… ë” ë‚˜ì€ ì‚¬ì‹¤ ê²€ìƒ‰

### í†µí•© í¬ì¸íŠ¸ 5: í‰ê°€ í’ˆì§ˆ ê°œì„  (Faithfulness)

#### ë°©ì•ˆ: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ Faithfulness ê²€ì¦ ë³´ì¡°

```python
# í‰ê°€ í›„ ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ í™œìš©

class KoreanFaithfulnessEnhancer:
    """í•œêµ­ì–´ Faithfulness ê²€ì¦ ë³´ì¡° ë„êµ¬."""

    def __init__(self, tokenizer: KiwiTokenizer):
        self.tokenizer = tokenizer

    def verify_claims_against_context(
        self,
        claims: list[str],
        context: str
    ) -> list[tuple[str, bool, float]]:
        """ì»¨í…ìŠ¤íŠ¸ ëŒ€ë¹„ ì£¼ì¥ ê²€ì¦ (í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜)."""
        context_tokens = set(self.tokenizer.tokenize(context))

        results = []
        for claim in claims:
            claim_tokens = set(self.tokenizer.tokenize(claim))

            # í† í° ê²¹ì¹¨ ê³„ì‚° (ì¡°ì‚¬/ì–´ë¯¸ ë¬´ì‹œ)
            overlap = len(claim_tokens & context_tokens)
            coverage = overlap / len(claim_tokens) if claim_tokens else 0

            is_faithful = coverage >= 0.5
            results.append((claim, is_faithful, coverage))

        return results
```

**íš¨ê³¼:**
- âœ… ì¡°ì‚¬/ì–´ë¯¸ ë³€í˜• ë¬´ì‹œí•˜ì—¬ ë” ì •í™•í•œ ê²€ì¦
- âœ… Faithfulness ì ìˆ˜ í–¥ìƒ (+5-10%)
- âœ… ë” ë‚˜ì€ í‰ê°€ í’ˆì§ˆ

### í†µí•© í¬ì¸íŠ¸ 6: Dense Embedding (Phase 9.3)

#### Dense Embedding ê°œìš”

**ì„ ì • ëª¨ë¸**: `dragonkue/BGE-m3-ko` (AutoRAG ë²¤ì¹˜ë§ˆí¬ 1ìœ„)

| íŠ¹ì„± | ê°’ |
|------|-----|
| ì°¨ì› | 1024 |
| Max Tokens | 8192 |
| AutoRAG Top-k 1 | **0.7456** (+39.4% vs bge-m3-korean) |
| MIRACL NDCG@10 | 0.6833 |
| ë¼ì´ì„ ìŠ¤ | Apache 2.0 |

#### Quantized ëª¨ë¸ ì§€ì›

> **ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­**: "local LLM ëª¨ë¸ì€ ëŒ€ë¶€ë¶„ í€€íƒ€ì´ì¦ˆëœ ëª¨ë¸ì„ ì“¸ ê±°ì•¼"

```python
class KoreanDenseRetriever:
    """í•œêµ­ì–´ Dense ê²€ìƒ‰ê¸° (Quantized ëª¨ë¸ ì§€ì›)."""

    def __init__(
        self,
        model_name: str = "upskyy/bge-m3-korean",
        use_fp16: bool = True,  # ë©”ëª¨ë¦¬ ì ˆì•½ (FP16 ì–‘ìí™”)
        device: str = "auto",   # auto, cuda, cpu, mps
    ):
        self._model = self._load_model(model_name, use_fp16, device)

    def encode(
        self,
        texts: list[str],
        return_dense: bool = True,
        return_sparse: bool = False,
    ) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±."""
        return self._model.encode(
            texts,
            return_dense=return_dense,
            return_sparse=return_sparse,
        )
```

#### HybridRetriever í†µí•©

Phase 9.2ì—ì„œ êµ¬í˜„ëœ `KoreanHybridRetriever`ì— Dense ê²€ìƒ‰ ì—°ê²°:

```python
from evalvault.adapters.outbound.nlp.korean import KoreanHybridRetriever

# Dense ì„ë² ë”© í•¨ìˆ˜ ì£¼ì…
def embedding_func(texts: list[str]) -> list[list[float]]:
    return dense_retriever.encode(texts).tolist()

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„±
retriever = KoreanHybridRetriever(
    tokenizer=tokenizer,
    embedding_func=embedding_func,  # Dense ì—°ê²°
    bm25_weight=0.4,
    dense_weight=0.6,
    fusion_method=FusionMethod.RRF,
)

# ì¸ë±ì‹± (BM25 + Dense ë™ì‹œ)
retriever.index(documents, compute_embeddings=True)

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
results = retriever.search(query, top_k=5)
```

#### í†µí•© í¬ì¸íŠ¸

| í†µí•© ëŒ€ìƒ | í†µí•© ë°©ë²• | íš¨ê³¼ |
|-----------|-----------|------|
| **Context Retrieval** | í‰ê°€ ì „ ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ê°œì„  | Context Precision/Recall í–¥ìƒ |
| **Semantic Similarity** | í˜•íƒœì†Œ ì „ì²˜ë¦¬ + Dense ìœ ì‚¬ë„ | ë” ì •í™•í•œ ì˜ë¯¸ ë¹„êµ |
| **Topic Clustering** | ì„ë² ë”© ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ | ë” ë‚˜ì€ í† í”½ ë¶„ë¦¬ |
| **Domain Memory** | Semantic search ë³´ì¡° | ì˜ë¯¸ ê¸°ë°˜ ì§€ì‹ ê²€ìƒ‰ |

---

## íƒ€ì„ë¼ì¸ ë° ì„±ê³µ ì§€í‘œ

### íƒ€ì„ë¼ì¸

| Week | Phase | ì£¼ìš” ì‘ì—… | Status |
|------|-------|----------|--------|
| 1 | 9.1 | Kiwi í†µí•©, KiwiTokenizer êµ¬í˜„ | âœ… Complete |
| 1-2 | 9.2 | í‚¤ì›Œë“œ ì¶”ì¶œ ê°œì„ , NLP ì–´ëŒ‘í„° ìˆ˜ì •, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ | âœ… Complete |
| 2 | 9.3 | Dense Embedding, BGE-m3-ko í†µí•© | âœ… Complete |
| 2-3 | 9.4 | í•œêµ­ì–´ Faithfulness ê²€ì¦ ë„êµ¬ | âœ… Complete |
| 3 | 9.5 | ë²¤ì¹˜ë§ˆí¬ ëŸ¬ë„ˆ, ê°€ì´ë“œ ë¬¸ì„œí™” | âœ… Complete |

### ì„±ê³µ ì§€í‘œ

| ì§€í‘œ | Before | After | ê°œì„ ìœ¨ | Status |
|------|--------|-------|--------|--------|
| í‚¤ì›Œë“œ ì¶”ì¶œ ì •í™•ë„ | ~60% | 85%+ | **+25%** | âœ… ë‹¬ì„± |
| ê²€ìƒ‰ Recall@5 | Baseline | +15-20% | **+15-20%** | âœ… ì¸¡ì • ê°€ëŠ¥ |
| Faithfulness ì •í™•ë„ | Baseline | +10-25% | **+10-25%** | âœ… ì¸¡ì • ê°€ëŠ¥ |
| ì—”í‹°í‹° ì¶”ì¶œ ì •í™•ë„ | ~70% | 90%+ | **+20%** | âœ… ë‹¬ì„± |
| ë²¤ì¹˜ë§ˆí¬ ì»¤ë²„ë¦¬ì§€ | 0% | 100% | - | âœ… 24 í…ŒìŠ¤íŠ¸ |
| ë‹¤ì¤‘ í¬ë§· ì§€ì› | 0 | 4 | MTEB, lm-harness, DeepEval, Leaderboard | âœ… ì™„ë£Œ |

### ì˜ˆìƒ íš¨ê³¼ (í†µí•© í›„)

| ê¸°ëŠ¥ | Before | After | ê°œì„ ìœ¨ |
|------|--------|-------|--------|
| **í…ŒìŠ¤íŠ¸ì…‹ í’ˆì§ˆ** | Baseline | +15-20% | ì»¨í…ìŠ¤íŠ¸ ë¬´ê²°ì„± |
| **í‚¤ì›Œë“œ ì¶”ì¶œ ì •í™•ë„** | ~60% | 85%+ | **+25%** |
| **ì—”í‹°í‹° ì¶”ì¶œ ì •í™•ë„** | ~70% | 90%+ | **+20%** |
| **KG í’ˆì§ˆ** | Baseline | +20-30% | ë” ì •í™•í•œ ì—”í‹°í‹°/ê´€ê³„ |
| **Domain Memory ì •í™•ë„** | Baseline | +10-15% | ì¤‘ë³µ ì œê±°, ì •ê·œí™” |

---

## ì˜ì¡´ì„± ì¶”ê°€

```toml
# pyproject.toml
[project.optional-dependencies]
korean = [
    # í˜•íƒœì†Œ ë¶„ì„
    "kiwipiepy>=0.18.0",              # í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ (Pure Python)

    # ì„ë² ë”© & ê²€ìƒ‰
    "FlagEmbedding>=1.2.0",           # BGE-M3 ëª¨ë¸ (Dense+Sparse+ColBERT)
    "rank-bm25>=0.2.2",               # BM25 ê²€ìƒ‰

    # Hugging Face
    "transformers>=4.40.0",           # ëª¨ë¸ ë¡œë”©
    "sentence-transformers>=2.7.0",   # ì„ë² ë”© ìœ í‹¸ë¦¬í‹°
]

korean-full = [
    # korean + ì¶”ê°€ ëª¨ë¸
    "evalvault[korean]",
    "torch>=2.0.0",                   # GPU ê°€ì†
    "faiss-cpu>=1.7.4",               # ë²¡í„° ê²€ìƒ‰ (CPU)
    # "faiss-gpu>=1.7.4",             # GPU ë²„ì „ (ì„ íƒ)
]
```

### ì„¤ì¹˜ ë°©ë²•

```bash
# ê¸°ë³¸ í•œêµ­ì–´ ì§€ì›
uv add evalvault[korean]

# ì „ì²´ í•œêµ­ì–´ ê¸°ëŠ¥ (GPU í¬í•¨)
uv add evalvault[korean-full]

# ë˜ëŠ” ê°œë³„ ì„¤ì¹˜
uv add kiwipiepy FlagEmbedding rank-bm25
```

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```python
# ì²« ì‚¬ìš© ì‹œ ìë™ ë‹¤ìš´ë¡œë“œ (~2GB)
from FlagEmbedding import BGEM3FlagModel

model = BGEM3FlagModel(
    'upskyy/bge-m3-korean',
    use_fp16=True,  # GPU ë©”ëª¨ë¦¬ ì ˆì•½
    device='cuda'   # ë˜ëŠ” 'cpu'
)
```

---

## ì°¸ê³  ìë£Œ

- [Kiwi ê³µì‹ ë¬¸ì„œ](https://github.com/bab2min/kiwipiepy)
- [í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° ë¹„êµ](https://konlpy.org/ko/latest/morph/)
- [BM25 ì•Œê³ ë¦¬ì¦˜](https://en.wikipedia.org/wiki/Okapi_BM25)
- [BGE-M3-Korean ëª¨ë¸](https://huggingface.co/dragonkue/BGE-m3-ko)
- [Korean SPLADE ì—°êµ¬](https://arxiv.org/html/2511.22263v1)

---

**ë¬¸ì„œ ë**
